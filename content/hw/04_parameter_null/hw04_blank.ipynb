{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/img/banner.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04 - Parameterized Models and _t_-Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "import shared.src.utils.util as shared_util\n",
    "import utils.bound as bound\n",
    "import utils.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = Notebook(\"ok/config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1. Practice converting descriptions of priors and likelihoods into random variables.\n",
    "2. Apply the (two-sided, unpaired) $t$-test to data and compute an associated $p$ value with both of the main approaches.\n",
    "3. Recognize the similarities and differences between the analytical and sampling approaches to determining null distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Specifying Parameterized Models in pyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will be asked to relate descriptions\n",
    "of the behavior of a random variable\n",
    "to choices for the distribution of that variable.\n",
    "\n",
    "Information about how to relate statements like the ones below\n",
    "to specific distributions appears in the Week 03 lecture on random variables\n",
    "and in the Week 04 lecture on parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priors encode beliefs about the state of the world,\n",
    "and especially about the values of parameters.\n",
    "\n",
    "Read each of the statements below,\n",
    "representing a belief about a parameter.\n",
    "Determine which `pm.Distribution`\n",
    "best encodes each belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"This parameter could be any positive number.\"\n",
    "2. \"This parameter could be any number between X and Y.\"\n",
    "3. \"This parameter could be any number.\"\n",
    "4. \"This parameter could be any integer between X and Y.\"\n",
    "5. \"This parameter could be any number, but is close to a value `mu`, up to a spread of `sd`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary, called `priors`,\n",
    "that contains your answers.\n",
    "\n",
    "The keys should be letters,\n",
    "`1` through `6`,\n",
    "and the values should be functions\n",
    "called to add random variables to models,\n",
    "like `pm.Bernoulli`.\n",
    "\n",
    "For example, for the statement\n",
    "\n",
    "> 7. \"This parameter is a Normal random variable\"\n",
    "\n",
    "the answer is `{7: pm.Normal}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihoods describe the distribution of data,\n",
    "given its parameters.\n",
    "\n",
    "For each description of a data likelihood below,\n",
    "determine which `pm.Distribution` best fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"This data has a distribution subject to the Central Limit Theorem.\"\n",
    "2. \"This data is the number of occurrences of a memoryless process.\"\n",
    "3. \"This data is the timing between occurrences of a memoryless process.\"\n",
    "4. \"This data is the sum of `n` `Bernoulli` variables with the same parameter `p`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format your answers as above,\n",
    "in a dictionary called `likelihoods`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors + Likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full model typically combines a prior over the parameters with a likelihood for the data.\n",
    "\n",
    "Convert the specifications of models below,\n",
    "given in English and in mathematical notation,\n",
    "into pyMC models.\n",
    "\n",
    "Give each variable in the model the name that appears next to the \"distributed as\" sign, $\\sim$.\n",
    "The variable name you should give each model appears just before the description in `fixedwidth` text.\n",
    "\n",
    "Once you have specified the model, draw at least 2000 samples from it,\n",
    "convert the samples into a dataframe with `shared_util.samples_to_dataframe`,\n",
    "and save them to `{model_name}_samples_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear_signal_model`:\n",
    "> The $S$ignal takes on random values around 0 with a typical spread of 1\n",
    "and the $M$easurement of that signal experiences additive noise\n",
    "with magnitude averaging 0 and a typical spread of 0.1.\n",
    "\n",
    "$$\n",
    "S \\sim \\text{Normal}(0, 1) \\\\\n",
    "M \\sim S + \\text{Normal}(0, 0.5)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with pm.Model() as linear_signal_model:\n",
    "    ?\n",
    "    \n",
    "linear_signal_model_samples_df = shared_util.samples_to_dataframe(shared_util.samples_from(\n",
    "    linear_signal_model, draws=500, chains=4))\n",
    "```      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nhst_model`:\n",
    "\n",
    "> The null hypothesis is true with probability $p$=`0.2`.\n",
    "The test has a false positive rate or $\\alpha$ of `0.1`\n",
    "and a power of `0.7`.\n",
    "\n",
    "$$\n",
    "\\text{null_true} \\sim \\text{Bernoulli}(0.2) \\\\\n",
    "\\text{positive_result} \\sim \\text{Bernoulli}(\\texttt{testparameters}[\\text{null_true}])\n",
    "$$\n",
    "\n",
    "with\n",
    "```python\n",
    "testparameters = [0.7, 0.1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`neurotransmitter_model`:\n",
    "\n",
    "[Neurons communicate across synapses](https://www.youtube.com/watch?v=WhowH0kb7n0)\n",
    "by releasing sacs of neurotransmitter (the \"chemistry\" in \"brain chemistry\") called vesicles.\n",
    "In many cases, the neuron receiving the neurotransmitter reacts by moving ions around,\n",
    "changing its voltage.\n",
    "\n",
    "Both the number of vesicles released and the change in voltage in response\n",
    "are random, and described by the following model:\n",
    "\n",
    "> Vesicle release is the result of many independent events,\n",
    "with the $N$umber of vesicles being released averaging `2.25`.\n",
    "Each individual vesicle causes the $V$oltage to change by an amount\n",
    "with mean `0.4` and typical spread `0.0625`.\n",
    "The effects of different vesicles are added together.\n",
    "\n",
    "$$\n",
    "N \\sim \\text{Poisson}(2.25) \\\\\n",
    "V_i \\sim \\text{Normal}(0.4, 0.0625) \\\\\n",
    "V \\sim V_1 + V_2 ... V_N\n",
    "$$\n",
    "\n",
    "Recall from lab03 that simulating events where\n",
    "some random variables don't exist on some samples\n",
    "is not possible in pyMC.\n",
    "You may assume that no more than 10 vesicles are ever released.\n",
    "Note that `pm.math.sum` can be used to add up a list of RVs\n",
    "and slicing, like `X[:ii]`,\n",
    "can be used with random variables in both positions, `X` and/or `ii`.\n",
    "The template below can get you started.\n",
    "\n",
    "See [this blog post](https://charlesfrye.github.io/stats/2017/11/03/quantal-release-probabilistic-models.html)\n",
    "for more on this model.\n",
    "The discovery of this model was good for a\n",
    "[Nobel Prize in 1970](https://www.nobelprize.org/nobel_prizes/medicine/laureates/1970/speedread.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with pm.Model() as neurotransmitter_model:\n",
    "    N = pm.?\n",
    "    voltage_changes_all_possible_vesicles = pm.Normal(\"_V\", mu=?, sd=?, shape=10)\n",
    "    V = pm.Deterministic(\"V\", pm.math.sum(?[:?]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - $t$-Testing Two Ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will revisit the `attention` dataset from `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten_df = sns.load_dataset(\"attention\", data_home=Path(\"..\") / \"..\" / \"shared\" / \"data\", index_col=0)\n",
    "\n",
    "atten_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, participants completed three tasks of varying difficulty,\n",
    "indexed by the number of `solutions` (`1` being hard, `3` being easy)\n",
    "and received a `score` quantifying their performance.\n",
    "\n",
    "In some trials, participants had their `attention` to the task `divided` by a distractor,\n",
    "while in others they were `focused` on the task.\n",
    "\n",
    "It is intuitive to expect that `score`s would be higher when `attention` is `focused`,\n",
    "and perhaps to expect that the degree of this effect is greater for harder tasks.\n",
    "\n",
    "Below, we will test this expectation by checking whether the mean `score`s differ\n",
    "depending on the value of `attention` for the easy task, \n",
    "`solutions == 3`, and for the hard task, `solutions == 1`,\n",
    "according to the $t$-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $t$-statistic for two equal-sized groups $A$ and $B$ is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\mu_A - \\mu_B}{\\sigma\\sqrt{\\frac{2}{n}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu_A$ for a pandas series `A` is `A.mean()`,\n",
    "and $n$ is `len(A)`, which is presumed equal to `len(B)`.\n",
    "The value the denominator, $\\sigma$, is\n",
    "the estimate of the population standard deviation\n",
    "and is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2 = \\frac{\\sigma^2_A + \\sigma^2_B}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\sigma^2_A$ for a pandas Series `A` is `A.var()`.\n",
    "Recall that `.var` has the implicit keyword argument `ddof=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function, `compute_t`, that takes in two `Series` and computes the `t` statistic for those two series.\n",
    "See the template below for hints on how to proceed.\n",
    "\n",
    "As part of the implementation of `compute_t`,\n",
    "write a separate function to compute the pooled estimate of the population standard deviation,\n",
    "as in the template below.\n",
    "It is considered good programming practice to break out separate tasks into separate functions as much as possible,\n",
    "to improve readability and ease the work of bug testing and code updating.\n",
    "\n",
    "You do not need to worry about what happens when either `a` or `b` is not a `Series` or when they are of length `0` or unequal length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def compute_t(a, b):\n",
    "    \"\"\"Compute the t statistic for two pandas Series of equal length\n",
    "    \"\"\"\n",
    "    # compute means, compute n\n",
    "    # use means to compute numerator of t\n",
    "    # compute sd, the \"pooled\" estimate of standard deviation\n",
    "    sd = compute_pooled_sd(a, b)\n",
    "    # compute np.sqrt(2 / n)\n",
    "    # use them compute denominator of t\n",
    "    # compute t from numerator over denominator\n",
    "    return t\n",
    "\n",
    "def compute_pooled_sd(a, b):\n",
    "    pool_sd = np.sqrt((? + ?) / ?)\n",
    "    return pool_sd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function, `compute_t_attention`,\n",
    "that applies `compute_t` to  `atten_df` to compute the $t$ statistic\n",
    "for the scores of participants with different values of `\"attention\"`,\n",
    "but with the same value of `solutions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template below will get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def compute_t_attention(df, num_solutions):\n",
    "    sub_df = ?  # select only rows with the right number of solutions\n",
    "    \n",
    "    # select a, the observations in the group with their attention divided\n",
    "    divided_scores = sub_df[sub_df[\"attention\"] == \"divided\"][\"score\"]\n",
    "    # select b, the observations in the group with their attention focused\n",
    "    focused_scores = ?\n",
    "    \n",
    "    return compute_t(divided_scores, focused_scores)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to compute $t$ for\n",
    "the difference in means between the two different attention groups\n",
    "when working on easy problems (`\"solutions\" == 3`).\n",
    "Save this as `easy_t_byhand`.\n",
    "Then do the same for subjects\n",
    "working on hard problems (`\"solutions\" == 1`)\n",
    "and save it as `hard_t_byhand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(\n",
    "    {\"attention\": [\"divided\", \"divided\", \"focused\", \"focused\"],\n",
    "     \"score\": [3, 5, 2, 4], \"solutions\": [1, 1, 1, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision to reject or fail to reject the null hypothesis\n",
    "can be made directly from $t$,\n",
    "but for a continuous measure of the plausibility of the data under the null,\n",
    "we use the $p$ value,\n",
    "which can also be used to choose whether or not to reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Analytical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_p_from_t` below calculates\n",
    "a $p$ value corresponding to the $t$ statistic.\n",
    "\n",
    "The sampling distribution of $t$ under the null hypothesis\n",
    "has only one parameter:\n",
    "`df`, for `d`egrees of `f`reedom (not `d`ata`f`rame!).\n",
    "It can be calculated from the size of the groups\n",
    "($n$ in the definition above, `n_group` in the function call).\n",
    "\n",
    "The driving force behind the definition of $t$ and similar test statistics\n",
    "in the early days of statistical inference was the need to have\n",
    "only one or a few discrete parameters,\n",
    "so that statistical tables could be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_from_t(t, n_group):\n",
    "    # first, we specify the sampling distribution\n",
    "    # under the null\n",
    "    df = 2 * n_group - 2\n",
    "    t_cdf = scipy.stats.t(df=df).cdf\n",
    "    \n",
    "    # then, we look at the probability of extreme values of the \n",
    "    # test statistic under that distribution\n",
    "    t_magnitude = np.abs(t)\n",
    "    right_tail = 1 - t_cdf(t_magnitude)\n",
    "    left_tail = t_cdf(-t_magnitude)\n",
    "\n",
    "    # for a two-sided test, we add up the chance of\n",
    "    # a positive or a negative value as extreme as we observed\n",
    "    p = left_tail + right_tail\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function, along with `compute_t_attention`\n",
    "to compute `p` values for the null hypothesis\n",
    "that attention state (`divided` vs `focused`) has no effect\n",
    "on the mean of the `score` for the hard problems,\n",
    "`num_solutions=1`.\n",
    "\n",
    "Save the result to `hard_p_byhand`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When possible, we should use highly-vetted code from open source libraries,\n",
    "like `scipy`, rather than our own code.\n",
    "\n",
    "Repeat the computation of `t` and `p` \n",
    "for the `hard` problems done above with the function\n",
    "`scipy.stats.ttest_ind`.\n",
    "It takes two arguments,\n",
    "`a` and `b`, which are the same as the arguments of `compute_t`.\n",
    "It returns two numbers:\n",
    "the first is the value of the $t$ statistic,\n",
    "and the second is the value of the $p$ statistic.\n",
    "Save the results to `hard_t_scipy` and `hard_p_scipy`.\n",
    "\n",
    "Print the values you computed and the values from scipy\n",
    "and observe that they are roughly equal.\n",
    "Their approximate equality will be checked by the autograder,\n",
    "but whether you printed them will not be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done this,\n",
    "compute the same values for the easy problems, `num_solutions=3`,\n",
    "print them,\n",
    "and save them to `easy_t_scipy` and `easy_p_scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run to see documentation\n",
    "# scipy.stats.ttest_ind??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation above relied critically on having\n",
    "a mathematical form for the null distribution of $t$,\n",
    "in this case provided by the methods of the `scipy.stats.t` object.\n",
    "\n",
    "Instead of having a mathematical form of the distribution,\n",
    "we can instead draw samples from it with pyMC.\n",
    "Though this is inefficient for cases like the $t$ statistic,\n",
    "whose sampling distribution under the null is well-known,\n",
    "this method will generalize to other statistics\n",
    "for which the null distribution is not known or not conveniently available.\n",
    "\n",
    "When making null models in pyMC,\n",
    "it's typically easier to create the null distribution of the data,\n",
    "then compute the value of the statistic outside of pyMC,\n",
    "rather than compute the statistic inside pyMC.\n",
    "Most statistics are deterministic transformations of the data,\n",
    "and so it doesn't make much sense to compute them inside pyMC,\n",
    "which is designed to handle relationships that have a random component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function `make_null_model_t`\n",
    "that takes in a value for the shared mean, standard deviation, and size of both groups\n",
    "and returns a pyMC model that samples data values according to the null.\n",
    "Remember that in the null model for the $t$ test,\n",
    "the data is normally-distributed.\n",
    "\n",
    "The template code suggests one way of implementing this null model.\n",
    "You can also look at the lectures from week 05 for alternative inspiration.\n",
    "You might also look to `pm.math.switch` for a third method,\n",
    "and I'm sure there are others.\n",
    "\n",
    "However you implement it,\n",
    "make sure the variable that contains the scores of the participants\n",
    "is called `\"scores\"` and that each sampled value\n",
    "is an array of _all_ of the observations for a single dataset,\n",
    "as in the template code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def make_null_model_t(mean, sd, group_size):\n",
    "    \n",
    "    with pm.Model() as t_model:\n",
    "        scores = pm.?(\"scores\", ... ? ..., shape=(group_size * 2))\n",
    "        \n",
    "    return t_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autograder test will draw samples from this model and check that they are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, draw at least `10000` samples from this null model\n",
    "for the data observed in the case of the easy problem.\n",
    "\n",
    "That is,\n",
    "set the mean equal to the mean of all scores for the easy problem\n",
    "and the standard deviation equal to the pooled standard deviation\n",
    "of the two groups for the easy problem,\n",
    "and provide those values, along with a `group_size=10`,\n",
    "to `make_null_model_t`.\n",
    "\n",
    "Then, draw at least `10000` samples from that model with `shared_util.sample_from`\n",
    "and put them into a dataframe with `shared_util.samples_to_dataframe`.\n",
    "Name that dataframe `null_model_t_easy_samples_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of this dataframe contains an entire dataset's worth of scores,\n",
    "equivalent to all of the elements of the `atten_df[\"scores\"]`\n",
    "that had the same value for `solutions`.\n",
    "Print `null_model_t_easy_samples_df.head()`\n",
    "and `null_model_t_easy_samples_df[\"scores\"].iloc[0]`\n",
    "to take a look at the values.\n",
    "\n",
    "Therefore in order to be able to apply our `compute_t_attention` function,\n",
    "we need to turn each row of the dataframe of pyMC samples\n",
    "into its own separate dataframe,\n",
    "complete with `\"attention\"` and `\"solution\"` columns.\n",
    "\n",
    "The template below will help you get started.\n",
    "The `sample` argument is presumed to be one row\n",
    "of the samples dataframe,\n",
    "e.g. the output of `samples.iloc[0]`.\n",
    "The first line converts the `\"scores\"` in it into a `Series` for you.\n",
    "\n",
    "To check what your function is doing,\n",
    "apply it to the first row of the samples\n",
    "(you can pull that row out with `.iloc[0]`)\n",
    "and print the result.\n",
    "\n",
    "_Hint_: Do the values for `\"attention\"`\n",
    "need to be aligned with the values for `\"score\"`,\n",
    "given that the samples come from the null model?\n",
    "\n",
    "_Hint_: Make sure you can apply `compute_t_attention` to the output of `null_sample_to_dataframe`!\n",
    "This is assumed in the autograder tests.\n",
    "The commented cell below allows you to compare your results\n",
    "to the matching subset of the original dataframe, `atten_df`.\n",
    "The order of the columns doesn't matter,\n",
    "but the two should have the same columns,\n",
    "the same number of observations in each group,\n",
    "and the same unique values for `attention` and `solutions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def null_sample_to_dataframe(sample, solutions):\n",
    "    scores_series = pd.Series(sample[\"scores\"].flatten())\n",
    "    n_group = ?\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {\"score\": ?,\n",
    "         \"attention\": [\"divided\"] * ? + [\"focused\"] * ?,\n",
    "         \"solutions\": ?})\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to view the output of your solution\n",
    "# in comparison to atten_df without the subject column\n",
    "\n",
    "# print(atten_df[atten_df[\"solutions\"] == 3].drop(\"subject\", axis=1))\n",
    "# print(null_sample_to_dataframe(null_model_t_easy_samples_df.iloc[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use that function to make a dataframe for each sample from pyMC,\n",
    "then use `compute_t_attention` on each dataframe.\n",
    "Put the results into a list called `pymc_null_ts_easy`.\n",
    "\n",
    "This list is an estimate of the sampling distribution of the $t$ statistic under the null hypothesis.\n",
    "Use that estimate to compute the $p$ value of the null hypothesis on this data\n",
    "by comparing the value of `t` on the real data to it.\n",
    "Save the result to `easy_p_pymc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the same method to compute the $p$ value for the null hypothesis about the effect of attention state\n",
    "on the harder task, with `solutions == 1`.\n",
    "Save the samples from the null distribution of $t$ to `pymc_null_ts_hard`\n",
    "and the $p$ value to `hard_p_pymc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
