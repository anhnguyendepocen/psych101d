{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/img/banner.svg\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 - Visualize, Munge, Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMEMBER**: if you downloaded this lab to datahub with an interact link,\n",
    "it will be called `lab01_blank.ipynb`.\n",
    "\n",
    "Before doing any work, go to the dropdown menu, `File > Make a Copy`,\n",
    "and then rename that copy to `lab01.ipynb`.\n",
    "Work in the copy, rather than the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import shared.src.utils.util as util\n",
    "import utils.plot\n",
    "\n",
    "sns.set_context(context=\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = Notebook(\"ok/config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1. Get hands-on experience with real data using `pandas`.\n",
    "1. Use `seaborn` to create high-quality visualizations of that data quickly.\n",
    "1. Recognize the difficulties in working with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we've only covered a bit of Python and pandas and no statistics,\n",
    "we're already about half-way to becoming data scientists!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every year, the company Figure Eight produces a\n",
    "[data science report](https://www.figure-eight.com/download-2017-data-scientist-report/),\n",
    "based off of a survey of data scientists\n",
    "(in the case of the numbers below 187 of them, in the year 2017).\n",
    "For the price of your contact information,\n",
    "you can read the report and learn some neat tidbits about the state of data science\n",
    "(within the last few years).\n",
    "\n",
    "One headline-grabber was their note that\n",
    "the process of \"collecting, labeling, cleaning, and organizing data\",\n",
    "commonly known as _data mungeing_, took up on average 53% of the respondents' time.\n",
    "Note that only around 15% of them listed this activity as one of their three favorites,\n",
    "among competitors like \"building and modeling data\" and \"refining algorithms\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does mungeing take up so much time?\n",
    "\n",
    "For one, the manner in which data is collected often dictates its form,\n",
    "rather than what would be convenient for downstream programmers.\n",
    "Things like units, data types, and conventions need careful attention.\n",
    "\n",
    "For another, real data is often far more complicated than what we work with in classes,\n",
    "especially math classes and especially data \"in the wild\",\n",
    "as opposed to data collected in a controlled research experiment.\n",
    "Measurements can be subject to outliers, missing values, and other complexities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will get some raw data and use our Python and visualization skills to munge it as best we can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Viewing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the lab this week is a collection of water temperature and quality measurements\n",
    "from a number of beaches in Chicago during the summer for a few recent years.\n",
    "It was downloaded from\n",
    "[data.world](https://data.world),\n",
    "a repository of publicly-available datasets,\n",
    "and is originally from the\n",
    "[City of Chicago's Open Data Portal](https://data.cityofchicago.org/).\n",
    "\n",
    "More information about the data is\n",
    "[here](https://data.cityofchicago.org/Parks-Recreation/Beach-Water-Quality-Automated-Sensors/qmqz-2xku)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will load the data in from its `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_raw = pd.read_csv(Path(\"data\") / \"beach-water-quality-automated-sensors-1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the raw data. As much as possible, we want to keep this entirely pristine, rather than editing it directly.\n",
    "\n",
    "We'll instead work primarily in a different dataframe, `beach`, that we'll build up programmatically through the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a `name` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do with any new dataframe is to look at the columns and the first few entries, with `.head()`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our observations seems to come from a different beach, given by the column `Beach Name`.\n",
    "Whatever downstream analysis we do, we'll want to compare across beaches.\n",
    "\n",
    "Notice that every beach name ends in `\"Beach\"`.\n",
    "This is redundant information, so let's remove it for the version in the `beach` dataframe.\n",
    "\n",
    "In a cell below, create a column in `beach` called `name` (no caps)\n",
    "that has the contents of `Beach Name`,\n",
    "but without that pesky `\" Beach\"` at the end.\n",
    "You can either do this with indexing (how many letters does `\" Beach\"` have?) or with string tools,\n",
    "if you're familiar with them.\n",
    "Don't forget to remove the space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Missing Values: Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the `head` to see the columns and a few of their values,\n",
    "it's a good idea to use `.sample()` to take a look at some random values of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_raw.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One striking fact about most samples is that the `Transducer Depth` variable has a large number of `N`ot `a` `N`umber, or `NaN` values.\n",
    "This value, `np.nan`, is used, along with a few others, to represent missing data in pandas.\n",
    "You can check if a value is a \"missing data\" value\n",
    "with the function `pd.isnull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pd.isnull(np.nan), pd.isnull(None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pd.isnull(0), pd.isnull(False), pd.isnull(-99), pd.isnull(-np.inf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `.sample` repeatedly would give us a sense for how common `NaN` values are,\n",
    "but there's a better way:\n",
    "we can use `.apply` with the function `pd.isnull`,\n",
    "then compute the average with `.mean`.\n",
    "`True` becomes `1` and `False` becomes `0`,\n",
    "so the result is the fraction of values that are null and therefore missing.\n",
    "\n",
    "In a cell below,\n",
    "compute the fraction of rows in the `Transducer Depth` column that contain null values,\n",
    "then print your result.\n",
    "The code snippet below might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "depth_null_frac = ?[?].apply(pd.isnull).mean()\n",
    "print(depth_null_frac)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a high fraction!\n",
    "If this were one of the variables we really wanted to use in our analysis,\n",
    "we'd be in trouble.\n",
    "We'd need to find a new source of data.\n",
    "\n",
    "Let's presume this column isn't important to us, and just not include it in `beach`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values: Non-Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just because data is not null according to pandas doesn't mean it's not missing.\n",
    "Depending on the context, other data values can mean \"missing\", like:\n",
    "- `\"Null\"` (the string)\n",
    "- the number `0`\n",
    "- `\"N/A\"`\n",
    "- the number `-99`, for some reason\n",
    "\n",
    "But pandas doesn't want to presume any of that context, so we have to search for that sort of thing ourselves.\n",
    "\n",
    "These values will often show up as \"outliers\", or strange values,\n",
    "if we try to visualize our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code snippet below to make a plot\n",
    "of the `Water Temperature` variable on the y-axis,\n",
    "versus the `Beach Name` on the x-axis.\n",
    "These are columns in the `beach_raw` dataframe.\n",
    "\n",
    "A set of values should jump out at you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "f, ax = plt.subplots(figsize=(16, 4))\n",
    "sns.stripplot(x=?, y=?, data=?, jitter=True);\n",
    "# plt.xticks(rotation=15);  # uncomment this line if the labels are smushed together\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the `\"Water Temperature\"` column are the measured temperatures of the water at the beach, in Celsius.\n",
    "Zero Celsius is the freezing point of water, and is a quite unlikely number for the temperature at a beach during a Chicago summer.\n",
    "This must be either a sensor failure or other kind of missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cells below, make a \"cleaned\" version of the `Water Temperature` column by applying the function below, `zero_to_nan`, that takes `0` values and turns them into `np.nan`s.\n",
    "Add it to the `beach` dataframe as the column `water_temp`.\n",
    "\n",
    "Then, recreate the `stripplot` from above, but using the `water_temp` and `name` columns from `beach` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_nan(value):\n",
    "    if value == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data is measured in a form that's not very suitable for statistical analysis.\n",
    "\n",
    "The information in the `Turbidity` column represents the \"cloudiness\" of the water,\n",
    "measured in\n",
    "[Nephelometric Turbidity Units](https://en.wikipedia.org/wiki/Turbidity#Measurement).\n",
    "\n",
    "Run the cell below to\n",
    "create a `distplot` (histogram + smoothed histogram)\n",
    "of the `Turbidity` column of `beach_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(beach_raw[\"Turbidity\"].dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of the points have very low turbidity:\n",
    "the water is very clear.\n",
    "\n",
    "But a few points have very high turbidity:\n",
    "perhaps a solid object was sucked into the nephelometer.\n",
    "\n",
    "It will be difficult to work with data that varies over this many orders of magnitude.\n",
    "\n",
    "The usual \"trick\" is to apply a _logarithm_ function,\n",
    "`np.log10` in this case.\n",
    "Logarithms turn orders of magnitude into something more like normal numbers:\n",
    "if a value `a` is 10 times bigger than a value `b`,\n",
    "`np.log10(a) - np.log10(b)` is `1`\n",
    "(try it!).\n",
    "The resulting data usually looks \"nicer\",\n",
    "as you'll see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, apply `zero_to_nan` to `beach_raw[\"Turbidity\"]` and make that a column in `beach` called `turbidity`.\n",
    "Zeros would represent infinitely clear water, so we'll treat that as missing.\n",
    "\n",
    "Then, apply `np.log10` to that column, making a new column called `log10_turbidity`.\n",
    "Finally, again make a `distplot` (refer to the code cell above if you need a template)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the transformation, the data is more evenly spread across its possible values,\n",
    "which no longer cross such a wide range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Continuous Relationships Between Numerical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to try one of our first really interesting visualizations:\n",
    "is there a relationship betwen the temperature and the (log-transformed) turbidity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code snippet below to compare the `water_temp` and `log10_turbidity` columns of `beach`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sns.jointplot(?, ?, data=?, alpha=0.01, stat_func=None, size=8);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing immediately interesting jumps out of this plot to me. Maybe if we split the data up more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring in our `.name` column, and plot the scatterplot in the middle on a per-beach basis using `lmplot`,\n",
    "based on the code snippet below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sns.lmplot(?, ?, data=?, fit_reg=False,\n",
    "           hue=\"name\", col=\"name\", col_wrap=3,\n",
    "           scatter_kws={\"alpha\": 0.05});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some interesting patterns are appearing:\n",
    "something irregular is happening at Montrose Beach,\n",
    "which has abnormally low turbidities,\n",
    "and at Ohio Street Beach, which has abormally high _and_ low turbidites, but only for one temperature.\n",
    "\n",
    "If we were continuing this analysis,\n",
    "we might want to look deeper:\n",
    "are those abnormal values occurring at specific times,\n",
    "for example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to do that, we'll need to work with the time data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time information in our data is in the column `\"Measurement Timestamp\"`,\n",
    "where it's represented as a string.\n",
    "\n",
    "The pandas function `pd.to_datetime` can convert a string that represents a time into\n",
    "a more manageable Python object, a `DateTime`.\n",
    "\n",
    "In a cell below, use `pd.todatetime` to convert `\"Measurement Timestamp\"` into a column of `DateTime`s,\n",
    "and then add it to `beach` as a column called `\"time\"`.\n",
    "\n",
    "Then, pass `beach` to `utils.plot.temp_over_time` to plot the `water_temp` column over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though time is in general continuous,\n",
    "the plot above makes it clear that the times _in our data_ fall into discrete categories.\n",
    "\n",
    "When that's the case, it's helpful to define those categories as explicit values\n",
    "and put the information in a separate column.\n",
    "\n",
    "In a cell below, apply the function `to_year` to the `\"time\"` column\n",
    "and make it a column of `beach` called `\"year\"`.\n",
    "See how easy it is to get information like the year from a `DateTime`,\n",
    "as opposed to a string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_year(dt):\n",
    "    return dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the code snippet below to make a `barplot`\n",
    "with the `year` on the x-axis and the `water_temp` on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "f, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.barplot(x=?, y=?, hue=\"name\", data=?);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that several beaches don't have any temperature data for 2016 or 2017,\n",
    "and all appear to have only one data point apiece for 2013.\n",
    "\n",
    "For some analyses, it's important to use measurements where you have values\n",
    "for every category.\n",
    "We'll practice working with this case by using a selector,\n",
    "or `Bool`ean `Series`,\n",
    "to select only those rows of `beach`\n",
    "that come from the years 2014 and 2015.\n",
    "\n",
    "We'd like to remove that data but still leave `beach` intact\n",
    "so that our colleagues, using our notebook later,\n",
    "can work with either, depending on their needs.\n",
    "\n",
    "So take the selected rows of `beach` and turn them into a new dataframe,\n",
    "`clean_beach`.\n",
    "This final dataframe\n",
    "should have only rows from 2014 and 2015,\n",
    "but all of the columns from `beach`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Relationships Between Numerical and Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `clean_beach` dataframe is now in the perfect format for visualizing differences across years for each of our beaches.\n",
    "\n",
    "Using the code snippet below,\n",
    "make a `pointplot` of the data in `clean_beach`,\n",
    "again with `year` on the x-axis and\n",
    "`water_temp` on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.pointplot(x=?, y=?, hue=\"name\", data=?);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some interesting patterns are starting to emerge:\n",
    "some of the beaches got colder, while others got warmer, or didn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in this course, we will learn how to analyze the differences in this plot with a traditional stats model,\n",
    "called an _ANOVA_,\n",
    "and with less traditional models, which have no names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
