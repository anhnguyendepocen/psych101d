{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../shared/img/banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes - Sampling and Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap(sampler = np.random.standard_normal, pdf = scipy.stats.norm(loc=0, scale=1).pdf,\n",
    "                   statistic_func = np.mean, num_samples=100,\n",
    "                   plot_samples=True,\n",
    "                  num_bootstraps=10,\n",
    "                  num_alternates=10,):\n",
    "\n",
    "    data = sampler(size=num_samples)\n",
    "    statistic = statistic_func(data)\n",
    "\n",
    "    bootstraps = [np.random.choice(data, size=num_samples) for _ in range(num_bootstraps)]\n",
    "    bootstrap_statistics = [statistic_func(bootstrap) for bootstrap in bootstraps]\n",
    "\n",
    "    alternate_samples = [sampler(size=num_samples) for _ in range(num_alternates)]\n",
    "    alternate_statistics = [statistic_func(alternate_sample) for alternate_sample in alternate_samples]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    if plot_samples:\n",
    "\n",
    "        sns.distplot(data, kde=False,\n",
    "                     hist_kws={'histtype':'step', 'linewidth':6, 'alpha':0.8, 'density':True, 'zorder':6},\n",
    "                     label = 'original data sample');\n",
    "\n",
    "        [sns.distplot(alternate_sample, kde=False, color = 'chartreuse',\n",
    "                    hist_kws={'histtype':'step', 'linewidth':6, 'alpha':0.25, 'density':True},\n",
    "                    label = 'other data samples')\n",
    "                    for alternate_sample in alternate_samples];\n",
    "\n",
    "        [sns.distplot(bootstrap, kde=False, color = 'hotpink',\n",
    "                     hist_kws={'histtype':'step', 'linewidth':6, 'alpha':0.25, 'density':True},\n",
    "                     label = 'bootstrap samples')\n",
    "                     for bootstrap in bootstraps];\n",
    "\n",
    "        xs = np.linspace(-4,4,1000)\n",
    "        plt.plot(xs,pdf(xs), color='black', linewidth=6, zorder=0,\n",
    "                label = 'population distribution');\n",
    "\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        indices = [0, 1, 1+num_bootstraps, 1+num_bootstraps+num_alternates]\n",
    "\n",
    "        handles = [handles[index] for index in indices]\n",
    "        labels = [labels[index] for index in indices]\n",
    "\n",
    "        plt.legend(handles, labels, loc=(1,0.6));\n",
    "\n",
    "    else:\n",
    "        if statistic_func is not np.mean:\n",
    "            raise NotImplementedError(\"statistic_func must be np.mean\")\n",
    "\n",
    "        sns.distplot(alternate_statistics, kde=False, color = 'chartreuse',rug=True,\n",
    "            hist_kws={'histtype':'step', 'linewidth':6, 'alpha':0.5, 'density':True},\n",
    "            label = 'other data sample statistics')\n",
    "\n",
    "        sns.distplot(bootstrap_statistics, kde=False, color = 'hotpink',rug=True,\n",
    "                     hist_kws={'histtype':'step', 'linewidth':6, 'alpha':0.5, 'density':True},\n",
    "                     label = 'bootstrap sample statistics')\n",
    "\n",
    "        scaling_factor = 1/np.sqrt(num_samples)\n",
    "        xs = np.linspace(-4*scaling_factor, 4*scaling_factor, 1000)\n",
    "\n",
    "        plt.plot(xs,scipy.stats.norm(loc=0, scale=scaling_factor).pdf(xs), color='black', linewidth=6, zorder=0,\n",
    "                label = 'sampling distribution');\n",
    "\n",
    "        ylims = plt.gca().get_ylim()\n",
    "        plt.vlines(statistic, *ylims,\n",
    "                   colors='grey', linestyles='--', linewidth=6,\n",
    "                  label = 'value of statistic on data')\n",
    "        plt.gca().set_ylim(ylims)\n",
    "\n",
    "        plt.legend(loc=(1,0.6))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll work through the idea of bootstrapping. We'll first work through some of the fundamental operations behind bootstrapping: working with random numbers on computers, generating random numbers with specific distributions, and resampling.\n",
    "\n",
    "Then, we'll look at the motivation for and definition of bootstrapping, then visualize the bootstrap in action in a case where we can visualize the process. This will help us build intuition for why bootstrapping, which strikes many folks as counterintuitive, actually works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Random Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computers and Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.standard_normal() #magic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a single command above, we are able to ask Python for a number whose exact value we seem to be unable to predict, but whose probability distribution we can describe. If we were really unable to predict that value, we'd say that it is *random*. You can see this for yourself by running the cell above repeatedly. Different numbers come out each time!\n",
    "\n",
    "But computers do not behave randomly -- randomness comes from factors that we do not control, and we have very intentionally designed computers in such a way that their macroscopic behavior is essentially unaffected by the factors that we do not control.\n",
    "\n",
    "Instead, computers behave like functions: if you know their inputs, then you can figure out their outputs. \n",
    "\n",
    "Already in this course, we've need to generate \"random\" outputs -- a random shuffling of the labels of our data for our randomization tests, for instance. Trouble is, if someone knows everything about the state of our computer, then they can perfectly reproduce the so-called \"random\" outputs. For statisticians, this turns out to be a problem that's more philosophical than practical -- if we don't know the exact state of our computer, then it *might as well be random* from our perspective. For cryptography, which relies on randomness, this distinction is critical.\n",
    "\n",
    "This problem is usually solved by measuring something outside of our (easy) control -- the ones digit of the current time in milliseconds or the fifth decimal point of the temperature of the CPU. This number is then used to generate a very long sequence of numbers that have no obvious relationship between them. So long as we don't specifically control the measurement, the resulting output will appear random to us, and all of your statistical operations that rely on randomness will work.\n",
    "\n",
    "The operation described above is called \"seeding\" the random number generator. It normally happens when we start using the random parts of numpy or Python, but we can ask for it to happen at any time by using the function `np.random.seed()` (with no arguments).\n",
    "\n",
    "Run the cell below. Notice that the output is different each time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "np.random.standard_normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to use a measurement as our seed. If we provide a (positive) number, Python will happily use that to seed the random number generator. In contrast to the previous cell, running this cell repeatedly will always generate the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5091991)\n",
    "\n",
    "np.random.standard_normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's ask Python for another random value using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.standard_normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is different from the one generated by the cell with the seed in it, but it's the same if you run the cells one after the other (try it!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The practical upshot of this is that, if you want, you can make all the code you run *reproducible*, so that someone running your code will get the same thing on their computer, even if it includes a \"random\" component. For example, if you perform a randomization-based analysis of your data and then make your code publicly available, seeding will allow others to directly replicate your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Numbers in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy library offers simple random number generation in Python. So we proceed after a quick **WARNING**: numpy is not \"random enough\" to be used in cryptography. If you make a billion-dollar website, don't use numpy for security-critical components.\n",
    "\n",
    "Numpy's random functions are nice because they are designed to produce lots of random numbers at once. We simply tell numpy the dimensions of the array of random numbers that we want, and it returns it to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = np.random.standard_normal((10,1)) # 10 by 1 random vector\n",
    "print(random_vector)\n",
    "print('')\n",
    "\n",
    "random_matrix = np.random.standard_normal((3,3)) # 3 by 3 random matrix\n",
    "print(random_matrix)\n",
    "print('')\n",
    "\n",
    "random_block = np.random.standard_normal((2,2,2)) # 2 by 2 by 2 random block\n",
    "print(random_block)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the distribution of these numbers is, in fact, approximately normal by plotting it.\n",
    "\n",
    "The cell below generates a large number of samples from a random normal distribution\n",
    "and uses seaborn's `distplot` to visualize it.\n",
    "I have a preferred style for plotting distributions that differs\n",
    "slightly from the defaults of `distplot`,\n",
    "so to save myself the trouble of repeatedly calling it with those arguments,\n",
    "I write my own function,\n",
    "`plot_distribution`,\n",
    "that just calls `distplot` with my preferred settings.\n",
    "This is a good trick for reducing the amount you have to repeat yourself when coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = np.random.standard_normal(5000)\n",
    "\n",
    "def plot_distribution(samples,discrete=False):\n",
    "    \n",
    "    hist_kws = {'histtype':'step',\n",
    "            'linewidth':6,\n",
    "               'alpha':0.8}\n",
    "    \n",
    "    if discrete:\n",
    "        mini = min(samples)\n",
    "        maxi = max(samples)\n",
    "        bins = range(mini,maxi+1)\n",
    "        sns.distplot(samples, kde=False,\n",
    "             hist_kws=hist_kws,\n",
    "             bins=bins);\n",
    "    else:\n",
    "        sns.distplot(samples,kde=False,\n",
    "             hist_kws=hist_kws,\n",
    "            );\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_distribution(normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy.random.standard_normal` generates samples from the *standard normal distribution*, the normal (aka Gaussian) distribution with a mean of zero and a standard deviation of 1.\n",
    "\n",
    "If we want normal random variables with a different mean and standard deviation, we simply multiply by the desired standard deviation and then add the desired mean.\n",
    "\n",
    "Below, generate another normally-distributed random vector with a different mean and standard deviation and plot the two on the same plot using `distplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_normal_vector = 2*np.random.standard_normal(5000)+3.2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_distribution(normal_sample)\n",
    "plot_distribution(other_normal_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the traditional statistics, inference is done by formulating a *test statistic*\n",
    "and using knowledge of the *sampling distribution of that statistic*.\n",
    "In many tests,\n",
    "including the $F$-test and the $t$-test,\n",
    "this involves taking advantage of the pre-calculated sampling distributions\n",
    "for cleverly chosen test statistics ($F$ and $t$),\n",
    "provided in Python by libraries like `scipy`.\n",
    "\n",
    "Bootstrap inference is based on approximately drawing samples from the\n",
    "actual sampling distribution of the statistic,\n",
    "using only the data itself.\n",
    "This makes the bootstrap flexible and easy to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we learn how that is done,\n",
    "let's first use sampling to estimate the sampling distribution of some statistics.\n",
    "\n",
    "Recall that a statistic is any function of the data.\n",
    "Useful statistics usually *summarize* the data,\n",
    "meaning that they take in an entire dataset and spit out a much smaller set of numbers.\n",
    "For example, the mean is a single number,\n",
    "while the four quartiles of a dataset are four numbers.\n",
    "\n",
    "To get the sampling distribution of a statistic,\n",
    "we first draw a sample of some size,\n",
    "then we calculate the statistic.\n",
    "This is one sample from the sampling distribution of the statistic.\n",
    "We repeat this many times in order to get a good estimate of the sampling distribution.\n",
    "\n",
    "We can visualize the sampling distribution of one-dimensional statistics using `distplot`,\n",
    "as in the cell below.\n",
    "The first two lines determine how large samples are (`sample_size`)\n",
    "and how many samples we draw (`num_samples`).\n",
    "The next two lines determine which random number generator we choose,\n",
    "the `sampler`,\n",
    "and which function we use to calculate the statistic,\n",
    "the `statistic`.\n",
    "Note that both variables are actually *functions*,\n",
    "so we write, e.g.,\n",
    "\n",
    "```\n",
    "sampler = np.random.standard_normal\n",
    "```\n",
    "\n",
    "which assigns the name `sampler` to the function `np.random.standard_normal`,\n",
    "rather than\n",
    "\n",
    "```\n",
    "sampler = np.random.standard_normal()\n",
    "```\n",
    "\n",
    "which would assign the name `sampler` to *the output of* the function `np.random.standard_normal`.\n",
    "\n",
    "The next two lines first draw the samples\n",
    "and then calculate the statistic for each sample\n",
    "using list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "sample_size = 100\n",
    "\n",
    "sampler = np.random.standard_exponential\n",
    "statistic = np.max\n",
    "\n",
    "samples = [sampler(size=sample_size) for _ in range(num_samples)]\n",
    "statistics = [statistic(sample) for sample in samples]\n",
    "\n",
    "plt.figure(figsize=(10, 10));\n",
    "plot_distribution(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should try a few different samplers,\n",
    "like `np.random.standard_exponential`\n",
    "and `np.random.standard_cauchy`\n",
    "and a few different statistics,\n",
    "like\n",
    "`np.max` and `np.min`,\n",
    "`np.mean`,\n",
    "and\n",
    "`np.prod` (with a small sample size, like 3 or 4).\n",
    "\n",
    "While many of these sampling distributions are simple,\n",
    "even Gaussian,\n",
    "others seem harder to describe.\n",
    "When we get to even more exotic statistics,\n",
    "like the parameters of models fit to large datasets,\n",
    "methods based on being able to calculate the sampling distribution,\n",
    "like $t$-testing and ANOVA,\n",
    "will be few and far between.\n",
    "Bootstrapping and randomization tests will be the only option in many of these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal way to estimate the sampling distribution of a statistic would be to repeat the experiment\n",
    "that generates the statistic over and over again,\n",
    "calculating the statistic anew for each dataset.\n",
    "\n",
    "This isn't a good idea in practice for at least two reasons:\n",
    "first, practically, we usually select our sample sizes because we are limited for \n",
    "financial, computational, or ethical reasons,\n",
    "and collecting many samples of that size would violate those constraints.\n",
    "Second, statistically,\n",
    "we'd like to make our inferences about hypotheses or parameters\n",
    "using as much data as possible,\n",
    "so splitting our sample into many equally sized chunks\n",
    "just in order to be able to build confidence intervals or calcualte $p$ values\n",
    "seems inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea of *bootstrapping* is as follows:\n",
    "\n",
    "<p {style=\"text-align: center\"}> <b>the best generic guess for the true sampling distribution of a statistic is \n",
    "<br>the distribution we get when we calculate the statistic from repeated samples from our data</b></p>\n",
    "\n",
    "That is, if we want to estimate the sampling distribution of some statistic $f$\n",
    "and we know nothing about the true distribution of the data,\n",
    "(e.g. we don't know if it's Gaussian)\n",
    "the best we can do is to repeatedly sample from the data with replacement,\n",
    "recalculating $f$ each time and storing the result.\n",
    "Estimating this sampling distribution then also lets us estimate things like\n",
    "confidence intervals and $p$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure strikes some folks as odd,\n",
    "even counterintuitive:\n",
    "how can I expect to get information about how\n",
    "my statistic would vary if I took different data\n",
    "using only data I've observed?\n",
    "\n",
    "In fact, the name \"bootstrapping\" reflects this very counterintuition:\n",
    "it refers to the idea of\n",
    "[pulling oneself up by one's own bootstraps](https://en.wiktionary.org/wiki/pull_oneself_up_by_one%27s_bootstraps),\n",
    "an 18th century idiom for achieving an impossible task.\n",
    "The bootstraps are the tiny pieces of cloth or leather that stick from the back of some boots,\n",
    "and to pull onself up by one's own bootstraps is to leap over a large obstacle simply by tugging on them,\n",
    "a physical impossibility.\n",
    "\n",
    "Bootstrapping seems similarly impossible:\n",
    "without any external aid save our data,\n",
    "we are attempting to draw inferences about the sampling distribution of a statistic.\n",
    "Put another way,\n",
    "we've only seen one draw from the sampling distribution,\n",
    "namely the statistic we calculated from our data,\n",
    "but we're claiming to be able to infer the structure of the whole distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rigorously proving that bootstrapping works is beyond the scope of this course,\n",
    "so instead let's try and gain some intuition for why it might work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Bootstrapping with Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's visualize the result of bootstrap sampling.\n",
    "Since the goal of bootstrapping is to mimic the result\n",
    "of sampling again from the true, or population, distribution,\n",
    "let's compare the result of repeated bootstrap sampling\n",
    "to the result of repeatedly sampling from the underlying population distribution.\n",
    "\n",
    "The function `plot_bootstrap` will take a `sampler` that samples from some population distribution\n",
    "and a function `pdf` that represents that distribution and,\n",
    "if the argument `plot_samples` is `True`, plot the following:\n",
    "\n",
    "- The probability density function of the population. This is the distribution that our original data sample is drawn from.\n",
    "- A histogram of the original data sample. This is the distribution that our bootstrap samples are drawn from. As `num_samples` gets larger, this should get closer to the population distribution.\n",
    "- Many histograms of other samples from the population. These represent the outcomes of additional identical experiments. We'd like our bootstrap samples to be almost indistinguishable from these samples.\n",
    "- Many histograms of bootstrap samples from the original data sample. If these overlap well with the histograms of the other data samples, then our bootstrap samples look like they are new draws from the population distribution, and we can calculate the statistic from each of those samples to get a good estimate of the sampling distribution.\n",
    "\n",
    "This cell can also be run with `sampler` set to `np.random.standard_exponential`\n",
    "and `pdf` set to `scipy.stats.expon().pdf`\n",
    "or with `sampler` set to `np.random.lognormal`\n",
    "and `pdf` set to `scipy.stats.lognorm(s=1).pdf`,\n",
    "if you'd like to see an example that's not Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below with different choices for `num_samples`.\n",
    "Start with `100`,\n",
    "and ask yourself whether the bootstrap sample histograms look like\n",
    "the other data sample histograms.\n",
    "Increase `num_samples` to `5000`, then decrease it to `10`,\n",
    "and ask whether that's still the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "\n",
    "sampler = np.random.standard_normal\n",
    "pdf = scipy.stats.norm().pdf\n",
    "\n",
    "plot_bootstrap(sampler=sampler, pdf = pdf,\n",
    "              plot_samples=True,\n",
    "              num_samples=num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of the original data sample approximates something called the\n",
    "*empirical distribution* --\n",
    "*empirical* because it is derived directly from the data,\n",
    "with no intermediary assumptions,\n",
    "and *distribution* because it describes the distribution of a random variable.\n",
    "The random variable whose distribution it describes is the random variable\n",
    "we sample when bootstrapping:\n",
    "the distribution for values drawn from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizing the Bootstrapped Sampling Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the output of bootstrapping:\n",
    "the bootstrap-estimated sampling distribution of the statistic.\n",
    "\n",
    "The purpose of generating these new bootstrap samples\n",
    "that look like samples from the population distribution\n",
    "is in order to estimate the sampling distribution.\n",
    "Normally, we do bootstrapping when we don't know this distribution.\n",
    "If we stick to a case where we do --\n",
    "the sampling distribution of the mean of Gaussian data is a Gaussian distribution --\n",
    "we can compare the bootstrap sample means\n",
    "and the sample means of other samples from the population\n",
    "to the ground truth\n",
    "to get a sense of how and when bootstrapping works.\n",
    "\n",
    "If run with arguments as below, `plot_bootstrap` will plot the following:\n",
    "\n",
    "- the mathematically-derived sampling distribution of the mean of the data (a Gaussian).\n",
    "- the mean of a single sample of size `num_samples` from `sampler`, standing in for our experimentally-measured data.\n",
    "- a histogram of the means of `num_alternates` samples taken according to the `sampler`. This is the approximation of the sampling distribution of the mean we'd get if we actually resampled from the population, rather than resampling from our dataset.\n",
    "- a histogram of the means of `num_bootstraps` bootstrap samples from the original data sample. We hope that this histogram looks similar to the histogram of the means of the other data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below and determine whether you think the bootstrap is working well for this example.\n",
    "\n",
    "The true value of the mean is $0$ in this case.\n",
    "We test the inference that it is different from $0$\n",
    "at a confidence level of 95%\n",
    "by asking whether 95% or more of the mass of our bootstrapped distribution\n",
    "is on the same side of $0$ as the center.\n",
    "Does this test appear to correctly infer that the mean could be $0$ most of the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "\n",
    "sampler = np.random.standard_normal\n",
    "pdf = scipy.stats.norm().pdf\n",
    "\n",
    "plot_bootstrap(sampler=sampler, pdf = pdf,\n",
    "               plot_samples=False,\n",
    "              num_samples=num_samples, num_bootstraps=100, num_alternates=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Sampling in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random number generating functions discussed at the beginning of this tutorial will be useful when we want to simulate a data-generating process. For example, I've used them to make the simulated data for the labs in this course.\n",
    "\n",
    "In bootstrapping, however, we don't sample from a parametrized distribution, as we did in the beginning of this tutorial. Instead, we sample from our data directly. If you were to implement this by hand, drawing a single sample might look something like this:\n",
    "\n",
    "1. Write down all of the data values on pieces of paper.\n",
    "1. Put the pieces of paper in a hat.\n",
    "1. Shake the hat up and blindly draw a single slip.\n",
    "1. The value on that slip is the value you sampled.\n",
    "\n",
    "When bootstrapping, we draw our samples \"with replacement\", which is to say that, if we wanted to draw more than one sample, we'd add two more steps. In step 5, we'd put the slip we drew back in, and then in step 6, we'd repeat steps 3-5 until we had enough samples.\n",
    "\n",
    "In pandas, this is done with the `.sample` method of `Series` and `DataFrame`s, with arguments `frac=1` and `replace=True`."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
