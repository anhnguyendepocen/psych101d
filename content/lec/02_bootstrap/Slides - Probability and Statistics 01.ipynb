{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Probability and Statistics 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import utils.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability is a slippery concept, philosophically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The Stanford Encyclopedia of Philosophy\n",
    "[has an entire page devoted to it](https://plato.stanford.edu/entries/probability-interpret/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What does it mean to say 'the chance that I roll a die and it comes up 6 is 1/6'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If I were to prepare a large number of dice identical to this one and roll them all at once, about 1/6 of them would come up 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is the\n",
    "[frequentist](https://en.wikipedia.org/wiki/Frequentist_probability)\n",
    "view, and is associated with, in the 20th century,\n",
    "[Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher),\n",
    "[Jerzy Neyman](https://en.wikipedia.org/wiki/Jerzy_Neyman),\n",
    "and [Egon Pearson](https://en.wikipedia.org/wiki/Egon_Pearson),\n",
    "and earlier with\n",
    "[Simeon Denis Poisson](https://en.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson)\n",
    "and [John Stuart Mill](https://en.wikipedia.org/wiki/John_Stuart_Mill).\n",
    "\n",
    "It is a form of _objective_ probability.\n",
    "In objective proability,\n",
    "probabilities are properties of the world,\n",
    "which we wish to measure and mathematize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If I were to examine all possible futures consistent with my beliefs right now, then 1/6 of them contain me rolling a die that comes up 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is a form of\n",
    "[Bayesianism](https://en.wikipedia.org/wiki/Bayesian_probability),\n",
    "a type of _subjective_ probability.\n",
    "In subjective probability,\n",
    "probability is used to model beliefs and uncertainity.\n",
    "\n",
    "Despite its name, it was primarily developed by\n",
    "[Pierre-Simon Laplace](https://en.wikipedia.org/wiki/Pierre-Simon_Laplace),\n",
    "rather than\n",
    "[Thomas Bayes](https://en.wikipedia.org/wiki/Thomas_Bayes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If I wish to think logically about the statement \"the die comes up 6\", then, given my current knowledge, I should assign the truth value 1/6 (where 1 is definitely true and 0 is definitely false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This view, another flavor of Bayesianism, is due, most prominently, to\n",
    "[Edwin T. Jaynes](https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes),\n",
    "and is expounded in his book\n",
    "[Probability Theory: The Logic of Science](https://bayes.wustl.edu/etj/prob/book.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The mathematical rules that I need to apply to games involving rolling dice in order to avoid being cheated tell me to assign the number 1/6 to the event \"the die comes up 6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is the [\"Dutch Book\"](https://en.wikipedia.org/wiki/Dutch_book) argument,\n",
    "due to [Bruno de Finetti](https://en.wikipedia.org/wiki/Bruno_de_Finetti),\n",
    "in the 20th century.\n",
    "It combines the subjectivity of Bayesianism with an operational definition,\n",
    "which brings many of the benefits of objectivity.\n",
    "\n",
    "If it were discovered today, it might be called the \"Wall Street View\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $\\pi$ makes the differences between these views clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the chance that the first digit of $\\pi$ is odd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the chance that a randomly chosen digit of $\\pi$ is odd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now consider the $2 ^ {2 ^ {100}}$th digit.\n",
    "\n",
    "What is the chance that it is odd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "2 ** 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We'll be as agnostic as we can.\n",
    "\n",
    "Probabilities are the numbers we use to talk about _distributions_ of data,\n",
    "whether those distributions are directly measured from data \n",
    "or are represented mathematically or by the behavior of a computer program.\n",
    "\n",
    "We'll operate, in general, with a subjective definition,\n",
    "a blend of the latter three,\n",
    "but traditional statistics uses the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete or Categorical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Categorical distributions have a finite number of observable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if you were observing on which day of each week\n",
    "the traffic on the Golden Gate Bridge was worst,\n",
    "there would be seven observable values,\n",
    "so you'd be dealing with categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Discrete distributions don't need to have a finite number of observable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if you were observing the number of cars that crossed the Golden Gate Bridge each day,\n",
    "you could see any number of cars greater than or equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Discrete distributions that aren't categorical are easier to define as\n",
    "\"not continuous\", the definition of which we'll see shortly.\n",
    "\n",
    "The possibly observable values are also called the _support_,\n",
    "which you may see while looking through Python documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "dice_rolls = pd.DataFrame([random.randint(1, 6) for _ in range(N)], columns=[\"roll\"])\n",
    "dice_rolls[\"count\"] = 1\n",
    "dice_rolls[\"frac\"] = 1 / N\n",
    "dice_rolls.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dice_rolls.groupby([\"roll\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A `groupby` operation collects up, in groups, all of the rows that share the same value for a given set of columns.\n",
    "The values in the group can then be aggregated by calling a method, like `.sum`,\n",
    "that collapses each group into a single value.\n",
    "\n",
    "Note: pandas does not provide a visual representaiton of the result of a `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "distribution = dice_rolls.groupby(\"roll\").sum()[\"frac\"]\n",
    "ax.bar(distribution.index, distribution);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some points:\n",
    "- Values can't be negative\n",
    "- Values must sum up to 1\n",
    "- Values can't be greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def is_probability_mass_distribution(vals):\n",
    "    if not all(val > 0 for val in vals):\n",
    "        return False\n",
    "    if not all(val < 1 for val in vals):\n",
    "        return False\n",
    "    if not np.isclose(sum(vals), 1):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "is_probability_mass_distribution(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Continuous Distributions from Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The method above doesn't work for constructing distributions for data whose values are _continuous_,\n",
    "which for us means infinite in number, with infinite possibilities between each possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, consider _reaction times_ in response to a stimulus,\n",
    "here measured relative to some baseline value, so some are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "reaction_times = pd.DataFrame([random.gauss(0, 0.1) for _ in range(N)], columns=[\"rt\"])\n",
    "reaction_times[\"count\"] = 1\n",
    "reaction_times[\"frac\"] = 1 / N\n",
    "reaction_times.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reaction_times.groupby(\"rt\").sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Each value appears only once, with over-whelming probability.\n",
    "\n",
    "The result is that, no matter what kind of data goes in,\n",
    "the resulting distribution is _flat_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "distribution = reaction_times.groupby(\"rt\").sum()[\"frac\"]\n",
    "ax.bar(distribution.index, distribution);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we use a rugplot instead,\n",
    "we'll see that there are some places where,\n",
    "within a given length, there are more data points than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.rugplot(reaction_times[\"rt\"], ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This suggests the notion of probability _density_:\n",
    "\"how tightly packed\" are the output values,\n",
    "rather than just \"how many\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(reaction_times[\"rt\"], kde=False, rug=True, bins=25, norm_hist=False, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This can be represented with a histogram,\n",
    "which counts up the number of values in each of a collection of bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This isn't yet a probability distribution, since we no longer guarantee that the heights add up to 1:\n",
    "instead, they add up to the number of observations.\n",
    "\n",
    "The argument `norm_hist=True` resolves this, but with a difference:\n",
    "the _areas of the bars_ add up to 1,\n",
    "rather than their heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "heights, edges = np.histogram(reaction_times[\"rt\"], density=True)\n",
    "\n",
    "print(is_probability_mass_distribution(heights))\n",
    "\n",
    "print(is_probability_mass_distribution(heights * (edges[1:] - edges[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Run the above cell with and without the `density=True` keyword argument in the `np.histogram` call.\n",
    "This argument does the same thing as `norm_hist`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What might happen if we were to gather more and more data and use smaller and smaller bins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "N = 1000; bins = 50\n",
    "vals = pd.DataFrame([random.gauss(0, 0.1) for _ in range(N)], columns=[\"vals\"])\n",
    "f, ax = plt.subplots(figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(vals[\"vals\"], kde=True, bins=bins, norm_hist=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Run the above cell with `N` up to 100000 and `bins` increasing as well,\n",
    "no more than one tenth of `N`\n",
    "(and probably no more than `1000`, unless you're feeling patient).\n",
    "\n",
    "You should notice a shape starting to emerge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If you pass `True` to the `kde` keyword argument,\n",
    "seaborn will also try and estimate the density function,\n",
    "using a method called `k`ernel `d`ensity `e`stimation.\n",
    "\n",
    "Notice one important difference between the estimated density\n",
    "and the histogram:\n",
    "while the latter jumps around,\n",
    "the former varies _smoothly_.\n",
    "It's hard to imagine writing down a simple mathematical function\n",
    "for the behavior of the histogram,\n",
    "but it seems like it might be possible for the density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we talk about the _true distribution_ of something we measure,\n",
    "we mean the mass or density we would see if we measured it infinitely many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics is the art of going from data to probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In real life, we don't get to measure something infinitely many times,\n",
    "so we don't get to ever know the true distribution.\n",
    "\n",
    "And even if we could, we couldn't store or share that information\n",
    "without summarizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Statistics are used primarily for two purposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _description_, or summarization of the data that was observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _inference_, or moving beyond the data to knowledge of what data might be observed in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Today's lecture focuses on descriptive statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The definition of a _statistic_ is:\n",
    "- the output of any function we apply to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What are some statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Examples that might come up:\n",
    "- the smallest and largest value\n",
    "- the \"middle\" value\n",
    "- the first value we observed\n",
    "- any of the statistics we discuss below\n",
    "- all of the data\n",
    "- a histogram\n",
    "- a bootstrap sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive statistics comes from the need to summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Large datasets are unwieldy\n",
    "\n",
    "Luckily, we can often communicate the important information from a dataset using just a few numbers,\n",
    "saving a ton of space and effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(sys.getsizeof(reaction_times), sys.getsizeof(float(reaction_times[\"rt\"].mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`sys.getsizeof` returns the amount of information used to store the argument, in bytes.\n",
    "\n",
    "If this is used on `vals` generated with `N=100000`,\n",
    "the outputs should be around 800,000 and 24.\n",
    "800,000 bytes is about 6.4 million binary values,\n",
    "while 24 is only about 160.\n",
    "\n",
    "Which would you rather copy into a ledger to send someone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Measures of Location: Mean, Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "mean_data = 1 / len(data) * (data[0] + data[1] + ... data[-1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The mean is the sum of the datapoints divided by the number of datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "# for N odd:\n",
    "median_data = sorted_data[N // 2]\n",
    "# for N even:\n",
    "median_data = sum(sorted_data[N // 2 - 1 : N // 2 + 1]) / 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The median is the datapoint \"in the middle\" of all of the others:\n",
    "as many are above it as below it.\n",
    "\n",
    "When the number of datapoints is even,\n",
    "the two numbers on either side are averaged together to get the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The mean and median can be derived as game-winning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imagine we play a game:\n",
    "I pick elements from a dataset at random.\n",
    "The smaller the difference,\n",
    "the higher your score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can score the game two different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def first_game_score(value, guess):\n",
    "    return - (value - guess) ** 2\n",
    "\n",
    "def second_game_score(value, guess):\n",
    "    return - np.abs(value - guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def first_game_score_on_data(data, guess, N):\n",
    "    return np.mean([first_game_score(value, guess) for value in data.sample(n=N, replace=True)])\n",
    "\n",
    "def second_game_score_on_data(data, guess, N):\n",
    "    return np.mean([second_game_score(value, guess) for value in data.sample(n=N, replace=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.Series([np.exp(random.gauss(0, 1.2)) for _ in range(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "guesses = np.linspace(0, 10, 50); N = 500000\n",
    "\n",
    "first_game_scores = [first_game_score_on_data(data, guess, N) for guess in guesses]\n",
    "second_game_scores = [second_game_score_on_data(data, guess, N) for guess in guesses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(8, 8), nrows=3, sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.plot_score_comparison(data, guesses, first_game_scores, second_game_scores, axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The above plot shows the scores, on the first and second game,\n",
    "of guesses between 0 and 10.\n",
    "Notice that the score on the first game is approximately maximized by the mean,\n",
    "while the score on the second game is approximately maximized by the median.\n",
    "\n",
    "This is generally true:\n",
    "the mean minimizes the sum of squared differences,\n",
    "while the median minimizes the sum of absolute differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "More broadly,\n",
    "it will often be useful to think of ideas in statistics and probability in terms of games,\n",
    "with points and sometimes adversaries,\n",
    "and then search for winning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Measures of Scale: Variance, Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "var_data = 1 / N * (\n",
    "    (data[0] - mean) ** 2 + ... (data[-1] - mean) ** 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that the variance is just the mean of the squared differences from the mean,\n",
    "so the variance can also be derived from a game like the mean and median.\n",
    "In that game, you'd aim to guess _how far away the values are from the mean_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "std_data = np.sqrt(var_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "NOTE: `.var` and `.std` compute something slightly different:\n",
    "they use `len(data) - 1`.\n",
    "We'll see talk about why in a later lecture.\n",
    "To calculate the variance in the way we defined it in pandas,\n",
    "you want `.var(ddof=0)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def skew(series):\n",
    "    \"\"\"NOTE: slightly different to pandas' definition of skew\n",
    "    \"\"\"\n",
    "    N, mean, sd = len(series), series.mean(), series.std()\n",
    "    running_skew = 0\n",
    "    for elem in series:\n",
    "        running_skew += ((elem - mean) / sd) ** 3\n",
    "    return running_skew / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Loose definition of skewness: do values tend to be above the mean or below the mean more often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "skewness_df = pd.read_json(Path(\".\") / \"data\" / \"skew_data.json\")\n",
    "skewness_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "skews = skewness_df.groupby([\"dataset\"]).skew()\n",
    "skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(8, 8), nrows=3, sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.skewness_comparison_plot(skewness_df, [\"height\", \"cost of insurance\", \"wealth\"], axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our statistics inherit their distributions from the data collection process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Statistics are functions we apply to our data,\n",
    "and our data will be different from experiment to experiment,\n",
    "so the value of the statistic that we measure will be different from experiment to experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distribution of a statistic, for a given setting of the experimental parameters,\n",
    "is called its _sampling distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Along with the slides this week, there's a demo, called\n",
    "`Demo - Sampling Distributions.ipynb`,\n",
    "that calculates some sampling distributions for a few statistics of a series of coin tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note: we rarely get to actually see the sampling distributions of our statistics in real settings.\n",
    "\n",
    "On Wednesday, we will talk about one way that we can _estimate_ the sampling distribution:\n",
    "**bootstrapping**.\n",
    "\n",
    "We will also talk about how we can use inference to mitigate the uncertainty introduced by the sampling distribution."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
