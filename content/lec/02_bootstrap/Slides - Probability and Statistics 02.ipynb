{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Probability and Statistics 02 - Inferential Statistics and Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import utils.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(context=\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics are used primarily for two purposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _description_, or summarization of the data that was observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- _inference_, or moving beyond the data to knowledge of what data might be observed in the future, including data you would never actually be able to observe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Today's lecture focuses on inferential statistics.\n",
    "\n",
    "It should perhaps be unsurprising, based on that description, that inferential statistics is\n",
    "1) much harder than descriptive statistics and\n",
    "2) philosophically slippery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical terminology reveals the history of statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The term \"Statistics\" comes from a Latin word meaning\n",
    "[\"matters of the state\"](https://en.wiktionary.org/wiki/statistics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While probability was invented in the 16th century by gamblers and mathematicians,\n",
    "statistics was invented in the 18th century by bureaucrats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The motivating problem of early statistics was"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "how do I track the commonwealth of the nation without talking to everybody in the nation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some early work in probability and statistics was done by\n",
    "[J.S. Mill](https://en.wikipedia.org/wiki/John_Stuart_Mill),\n",
    "better known now for his work on\n",
    "[utilitarianism](https://en.wikipedia.org/wiki/Utilitarianism),\n",
    "the ethical theory that says that one should\n",
    "achieve the greatest good for the greatest number.\n",
    "\n",
    "For these classical liberals, many of them economists,\n",
    "this lead to the question:\n",
    "how do you measure that good, when the numbers are too great?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is a total _population_ under the rule of my government."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I would like to know how it's doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Housing Markets of â‰ˆ8000 of the largest cities in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "houses_2010_df = pd.read_csv(\"data/houses_2010.csv\", index_col=0)\n",
    "houses_2017_df = pd.read_csv(\"data/houses_2017.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These two dataframes contain information about the total number of homes for sale\n",
    "in each of the ~8000 largest cities in the United States,\n",
    "one during a week at the end of 2010 and the other at the end of 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It contains the value of the observation \"Total Number of Homes for Sale At This Time\"\n",
    "on every single member of a population, the 8000 largest cities in the US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Taken from the\n",
    "[Zillow Economics dataset](https://www.kaggle.com/zillow/zecon),\n",
    "on [kaggle.com](https://kaggle.com).\n",
    "There are something like\n",
    "[16,000 - 20,000](https://www2.census.gov/geo/pdfs/reference/GARM/Ch9GARM.pdf) cities in the United States,\n",
    "depending on your definition,\n",
    "but the vast majority of city-dwellers are in one of these 8,000 cities.\n",
    "\n",
    "Measuring something like this is possible now because of ubiquitous, networked computing power.\n",
    "In the past, doing something like this would've been impossible,\n",
    "and hence the need for statistics.\n",
    "\n",
    "There remain plenty of problems where the population is still too big\n",
    "to work with sensibly:\n",
    "e.g., deciding who most eligible Americans would vote for if an election were held today.\n",
    "Doing statistics on this is still a [hard problem](https://fivethirtyeight.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "houses_2010_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When we have the _entire_ population of interest, all statistics is descriptive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The distribution of the entire population is called the _population distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "What I called the \"true distribution\" in the previous lecture,\n",
    "the distribution you would see if you observed an infinite number of data points,\n",
    "is also called, by some folks, the population distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(houses_2010_df[\"InventoryRaw_AllHomes\"], kde=False, norm_hist=True)\n",
    "sns.distplot(houses_2017_df[\"InventoryRaw_AllHomes\"], kde=False, norm_hist=True); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Distributions like the above, where there are some rare very large values\n",
    "and lots of common small or intermediate values, are hard to work with,\n",
    "so let's use a common trick and just ask what the _order of magnitude_,\n",
    "or _logarithm base 10_, of the number of houses for sale is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "houses_2010_df[\"log_homes\"] = np.log10(houses_2010_df[\"InventoryRaw_AllHomes\"])\n",
    "houses_2017_df[\"log_homes\"] = np.log10(houses_2017_df[\"InventoryRaw_AllHomes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(houses_2010_df[\"log_homes\"], kde=False, norm_hist=True)\n",
    "sns.distplot(houses_2017_df[\"log_homes\"], kde=False, norm_hist=True); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you have access to the population distribution,\n",
    "the only thing to do is _describe_ it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(houses_2010_df[[\"log_homes\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(houses_2017_df[[\"log_homes\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "So just about every basic question you can ask about this data is easy to answer:\n",
    "- did the number of houses for sale increase or decrease, on average?\n",
    "- did the variability in the number of houses for sale increase or decrease?\n",
    "- did the largest number observed increase or decrease?\n",
    "\n",
    "Just look at the data, and you're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But note, the more interesting questions are about inferences, like:\n",
    "- how large of a dataset would you have to give me before I could decide whether\n",
    "the values are from 2010 or 2017?\n",
    "\n",
    "These can still be answered from the population distribution,\n",
    "but they use techniques and tools of inferential thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "true_means = {2010: houses_2010_df.log_homes.mean(), 2017: houses_2017_df.log_homes.mean()}\n",
    "true_vars = {2010: houses_2010_df.log_homes.var(ddof=0), 2017: houses_2017_df.log_homes.var(ddof=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Getting the whole population is often hard or impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Hard: we would like to make statements about large populations (millions, billions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Impossible: sometimes we want to make statements about populations with no finite size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Example: if we make a general statement about human psychology,\n",
    "we're trying to talk about every human that ever lived or will live.\n",
    "Good luck surveying all of those!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The random sample was devised to get around this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Idea: don't measure _every_ member of the population,\n",
    "just measure a _sufficiently large number of examples_.\n",
    "\n",
    "From _example_ is derived the word _sample_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively, the entire population can't be too different from those examples,\n",
    "if they are chosen _at random_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Exceptions: finding the minimum and maximum will, in some cases,\n",
    "require looking at every member of the population.\n",
    "\n",
    "Imagine you were trying to figure out how wealthy the wealthiest person was.\n",
    "Unless you lucked out and happened to talk to\n",
    "one of\n",
    "[the top 10 of these people](https://en.wikipedia.org/wiki/List_of_richest_people_in_the_world),\n",
    "you'd be off by a factor of 2, if not far more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unintuitively, _sufficiently large_ is often quite small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "subsample_2010 = houses_2010_df.log_homes.sample(100)\n",
    "subsample_2017 = houses_2017_df.log_homes.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `.sample` method, with no arguments but a size,\n",
    "performs a random sample _without replacement_,\n",
    "mimicking the process of selecting some examples at random from a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(subsample_2010.mean(), subsample_2017.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "true_means[2010], true_means[2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Law of Large Numbers guarantees this will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Loosely:\n",
    "the value of a descriptive statistic on a random sample gets closer\n",
    "to the value of that descriptive statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This theorem is originally due to\n",
    "[Jacob Bernoulli](https://en.wikipedia.org/wiki/Law_of_large_numbers#History),\n",
    "the 17th century mathematician who discovered the importance of `math.e`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively:\n",
    "the _sampling distribution of a statistic_ on a random sample\n",
    "gets tighter around, and the center gets closer to, the true value\n",
    "as the sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is the _key trick_ in applications of probability,\n",
    "e.g. information theory, statistical physics:\n",
    "when we look at the behavior of really big collections of random things,\n",
    "they often behave very predictably.\n",
    "In its general form, it's known as _concentration_.\n",
    "\n",
    "The direction and speed of each particle in my coffee cup is random,\n",
    "but I never need to worry that they'll all suddenly zoom upwards and spill my drink on me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's visualize the Law of Large Numbers in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we pick a bunch of sample sizes, with values between 2 and about 500 - 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_sizes = np.ceil(np.random.lognormal(mean=3, size=10000)).astype(np.int) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This random selection method was chosen because it results in more small sizes than large sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we draw samples of those sizes, and calculate our descriptive statistics on those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "replace = False\n",
    "means_2010 = [houses_2010_df[\"log_homes\"].sample(sample_size, replace=replace).mean()\n",
    "              for sample_size in sample_sizes]\n",
    "means_2017 = [houses_2017_df[\"log_homes\"].sample(sample_size, replace=replace).mean()\n",
    "              for sample_size in sample_sizes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These are _list comprehensions_.\n",
    "\n",
    "They are like \"one-line `for` loops\", designed to make it easy to make lists.\n",
    "Read more about comprehensions to build lists\n",
    "and other things, like dictionaries,\n",
    "[here](https://www.geeksforgeeks.org/comprehensions-in-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vars_2010 = [houses_2010_df[\"log_homes\"].sample(sample_size, replace=replace).var(ddof=0)\n",
    "                   for sample_size in sample_sizes]\n",
    "vars_2017 = [houses_2017_df[\"log_homes\"].sample(sample_size, replace=replace).var(ddof=0)\n",
    "                   for sample_size in sample_sizes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's look at our results for the 2010 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_samples(sample_sizes, means_2010, ylabel=\"Sample Mean\"); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This plot shows the mean of each sample, plotted against the sample size.\n",
    "\n",
    "Notice how quickly the mean gets to within a tight band,\n",
    "then how slowly that band gets tighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This phenomenon is an important part of how homeworks and labs are autograded.\n",
    "\n",
    "You will codeup a model,\n",
    "and I will check whether the statistics of that model's samples\n",
    "have the right value, for large sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Law of Large Numbers predicts the shape we saw above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.make_LLN_plot(sample_sizes, means_2010, true_means[2010]); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The shape is that of a _square root_,\n",
    "which loosely means that the benefit of taking 10 samples relative to taking just 1\n",
    "is the same as the benefit of taking 100 samples relative to just 10, and 10000 relative to 100.\n",
    "\n",
    "This doesn't just apply to the mean, but to a wide variety of statistics that \n",
    "are calculated by averaging some function over every value in the sample.\n",
    "\n",
    "This has a profound effect on the way statistics is done:\n",
    "unless you're taking more than 5000 samples,\n",
    "almost all of the improvement in the accuracy of your guess will come in the first 100 samples.\n",
    "If those first 100 aren't sufficient, you'll be waiting a very long time!\n",
    "\n",
    "This has often led to an obsessive focus on making the other factors that influence that curve,\n",
    "what is called in the code here `spread_scaling`,\n",
    "as small as possible:\n",
    "reducing the variability in the data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's compare the sample means for samples from our two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ax = utils.plot.plot_samples(sample_sizes, means_2010, alpha=0.05, label=\"2010 data\")\n",
    "ax = utils.plot.plot_samples(sample_sizes, means_2017, alpha=0.05, label=\"2017 data\",\n",
    "                  ylabel=\"Sample Means\", ax=ax);\n",
    "ax.legend(); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice: for larger sample sizes, we don't see any sample means from 2010 that are lower than those from 2017,\n",
    "though it seems to happen for sample sizes smaller than about 100.\n",
    "\n",
    "Zoom in on the region of interest with\n",
    "```python\n",
    "ax.set_xlim([0, 100])\n",
    "```\n",
    "\n",
    "Reduce the transparency by making `alpha` larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Repeat all the above, but with `replace=True`.\n",
    "Notice that almost nothing changes.\n",
    "\n",
    "So for sample sizes smaller than the population,\n",
    "drawing with replacement is almost the same as drawing without replacement.\n",
    "\n",
    "Put another way,\n",
    "our procedure of sampling is not that different from\n",
    "generating random numbers according to the population distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Two ways your guess can be wrong\n",
    "\n",
    "- almost always: for a sample smaller than population, sampling distribution has values other than true value.\n",
    "- sometimes: for a sample smaller than population, mean of sampling distribution is wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The former is usually operationalized as the _variance_ of the sampling distribution,\n",
    "and so is called the variance of an estimate or estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The latter is known as bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lots of intuitive choices lead to biased guesses\n",
    "\n",
    "Example: computing the variance on a sample as we've defined it gives a biased estimate of the true variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ax = utils.plot.make_LLN_plot(sample_sizes, vars_2010, true_vars[2010], ylabel=\"Variance\", spread_scaling=1);\n",
    "ax.set_xlim([0, 10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The bias for the variance can be corrected very simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "corrected_vars_2010 = [houses_2010_df[\"log_homes\"].sample(sample_size, replace=True).var(ddof=1)\n",
    "                      for sample_size in sample_sizes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: `ddof=1` is the default in pandas! Instead of dividing by `len(series)`, it divides the sum of squared differences by `len(series) - 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ax = utils.plot.make_LLN_plot(sample_sizes, corrected_vars_2010, true_vars[2010], ylabel=\"Variance\", spread_scaling=1);\n",
    "ax.set_xlim([0, 10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This bias is small enough that to be sure it's there, we need to be quantitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sds_2010_df = pd.DataFrame({\"sample_size\": 2 * list(sample_sizes),\n",
    "                            \"var\": list(vars_2010)  + list(corrected_vars_2010),\n",
    "                            \"corrected\": len(sample_sizes) * [False] + len(sample_sizes) * [True]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_2010_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(true_vars[2010])\n",
    "sds_2010_df.groupby([\"sample_size\", \"corrected\"])[\"var\"].mean().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is a groupby on multiple columns: the `sample_size` and whether the estimate was `corrected` or not.\n",
    "\n",
    "Notice that the values for `corrected==True` are sometimes above, sometimes below the true value,\n",
    "while the values for `corrected==False` are uniformly below.\n",
    "This is _bias_.\n",
    "\n",
    "The exception is often `sample_size==2`,\n",
    "where there aren't enough samples to reliably estimate the center of the sampling distribution.\n",
    "Try resampling both the `corrected_vars` and `uncorrected_vars`\n",
    "multiple times and you should see the value for `corrected==True` bouncing around,\n",
    "both above and below the correct value, while the value for `corrected==False` is almost always below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We apply an _estimator_ on the sample to estimate what the value of some _statistic_ would be on the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The _estimator_ is a function/method, like `.mean` or `.var` with `ddof=1`, but it need not be the same as the _statistic_, which might be `.mean` or `.var` with `ddof=0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Once we have an estimate, we also need to determine our uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We're almost always pretty sure our estimate is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"does {true_means[2010]} == {subsample_2010.mean()}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "No, but we know that the true mean should be \"about\" the value we measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The challenge is figuring out how big \"about\" is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our uncertainty comes from the sampling distribution\n",
    "\n",
    "So we can determine our uncertainty by estimating the sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First Pass: Let's just draw more from the sampling distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We draw more samples, calculate our estimate on all of those samples,\n",
    "and then plot the distribution of our estimates on those samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Importantly, the samples should be of the same size!\n",
    "Otherwise the sampling distribution won't be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "subsamples_2010 = [houses_2010_df[\"log_homes\"].sample(100) for _ in range(100)]\n",
    "means = [subsample.mean() for subsample in subsamples_2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(means, rug=True, label=\"New Samples\"); plt.xlabel(\"Means\"); plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "By visualizing our estiamte of the sampling distribution, we get a loose idea of what our uncertainty is:\n",
    "we can say that certain values are definitely plausible, while others are definitely implausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(means, rug=True, label=\"New Samples\"); plt.xlabel(\"Means\");\n",
    "plt.vlines([1.2, 1.8, 1.9, 2.0], 0, 5, color=\"C1\", lw=2, label=\"Which of these are plausible?\");\n",
    "plt.legend(loc=\"upper left\"); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But there will be some cases where it's unclear, and reasonable people might disagree.\n",
    "To avoid that, we need a way to quantify our uncertainty.\n",
    "\n",
    "Visualizing the sampling distribution and saying which values are plausible and implausible\n",
    "is sufficient to complete the lab for this week,\n",
    "though we'll be doing it with bootstrapping,\n",
    "as discussed later.\n",
    "\n",
    "We'll leave quantifying uncertainty, as we discuss next,\n",
    "for the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The most common way to quantify uncertainty is with an interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once we have an estimate of the sampling distribution,\n",
    "we then build an interval that covers most of that distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do we construct it, given samples from an estimate of the sampling distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Below, we'll see that some estimates of the sampling distribution don't come with samples,\n",
    "and so confidence intervals must be constructed differently.\n",
    "We'll talk about those when we come across concrete examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We build the interval,\n",
    "[Pied Piper-style](https://news.mlh.io/i-hacked-the-middle-out-compression-from-silicon-valley-06-16-2015),\n",
    "from the middle out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In Python, we can use the `np.percentile` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.percentile(range(0, 101), [5, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "means_CI = np.percentile(means, [2.5, 97.5])\n",
    "means_CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This function comes from the `numpy`, or `num`erical `Py`thon, library.\n",
    "This is one of the most important libraries in Python,\n",
    "especially for data science and statistics.\n",
    "\n",
    "For more on numpy, see\n",
    "[this tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html).\n",
    "\n",
    "There is also a similar `.quantile` method in pandas, but watch out:\n",
    "it takes numbers between 0 and 1, not 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(means, rug=True, label=\"New Samples\"); plt.xlabel(\"Means\"); \n",
    "plt.hlines(5, *means_CI, color=\"k\", lw=4, label=\"95% CI\");\n",
    "plt.vlines(true_means[2010], 0, 6, color=\"C3\", lw=2, label=\"True Mean\");\n",
    "plt.legend(loc=[0.7, 0.64])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This is an example of a _Confidence Interval_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A confidence interval is any _interval-valued statistic_\n",
    "that has the property that for some known fraction of possible samples,\n",
    "the population parameter is inside that interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The typical choice for \"sufficient percentage\" is _95%_, for essentially historical reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It goes back to a few off-hand comments by\n",
    "[Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher),\n",
    "one of the founders of modern statistics.\n",
    "\n",
    "> It is usual and convenient for researchers to take 5 percent as a standard level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Resampling to construct a confidence interval is almost never done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It increases the budget for the experiment dramatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You can compute the statistic on all of the samples together and get a new estimate. A confidence interval built from the smaller samples _vastly_ overstates what your real uncertainty is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We could instead _model_ the sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Mathematically: write down equations for the sampling distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Computationally: simulate your data, then look at the sampling distribution of your simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### These approaches are hard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hard enough that it will take us much of the rest of this course to learn to use these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mathematical approach is made easier than it sounds by the Central Limit Theorem:\n",
    "many sampling distributions have the same shape, a bell curve,\n",
    "once the sample size gets large enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But the Central Limit Theorem won't always save you.\n",
    "\n",
    "For smaller sample sizes, there's no choice but to do some really hard math,\n",
    "which you must repeat with each new kind of data distribution.\n",
    "\n",
    "More on the Central Limit Theorem later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There's an easier way: \n",
    "\n",
    "Just pull yourself up by your bootstraps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We approximate the process of sampling from the population by sampling from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_sample = subsample_2010.sample(frac=1, replace=True)\n",
    "bootstrap_sample.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This cell computes a single bootstrap sample, then takes its mean.\n",
    "\n",
    "Notice that, in general,\n",
    "the statistic on the bootstrap sample\n",
    "will be different from the statistic on the original sample,\n",
    "and different from run to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_samples = [subsample_2010.sample(frac=1, replace=True) for _ in range (100)]\n",
    "bootstrap_means = [sample.mean() for sample in bootstrap_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The above cell computes multiple bootstrap samples, then computes the mean of each,\n",
    "to be plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.distplot(means, rug=True, label=\"actual resamples\");\n",
    "sns.distplot(bootstrap_means, rug=True, label=\"bootstrap resamples\");\n",
    "plt.xlabel(\"mean\"); plt.legend(loc=\"upper left\"); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Key idea:\n",
    "the _spread_ of this distribution is generally about correct,\n",
    "even though the center is wrong,\n",
    "since it's centered around the value of the statistic on the original sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we build a confidence interval the same way we would have if we'd actually gone back and done resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_CI = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "bootstrap_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.distplot(means, rug=True, color=\"C1\", label=\"Bootstraps\"); plt.xlabel(\"Means\"); \n",
    "plt.hlines(5, *bootstrap_CI, color=\"k\", lw=4, label=\"Bootstrap CI\");\n",
    "plt.vlines(true_means[2010], 0, 6, color=\"C3\", lw=2, label=\"True Mean\"); plt.legend(loc=[0.6, 0.6])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: technically, these intervals will be too small:\n",
    "they are a biased estimate of the true confidence interval,\n",
    "especially for small sample sizes.\n",
    "So if you really want to have 95% confidence,\n",
    "you need to make the interval slightly wider.\n",
    "This is fairly minor in most settings, but a huge pain to calculate, so we won't bother with it.\n",
    "If you are supremely concerned,\n",
    "just make the intervals slightly wider.\n",
    "If it changes your conclusions,\n",
    "then consider looking into\n",
    "[bootstrap corrections](http://users.stat.umn.edu/~helwig/notes/bootci-Notes.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "IPython.display.Image(\"img/how_bootstrapping_works.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The inspiration for the term bootstrapping:\n",
    "in the [_Adventures of Baron Munchausen_](https://en.wikipedia.org/wiki/Baron_Munchausen),\n",
    "the eponymous hero claims to have once saved himself from drowning in a swamp by pulling himself out by his ponytail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's believed that this story was eventually mangled slightly into a version in which someone\n",
    "pulls themselves out using the straps on their boots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "IPython.display.Image(\"img/bootstraps.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Image Credit: [Wikipedia](https://en.wikipedia.org/wiki/M%C3%BCnchhausen_trilemma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## But what if there's no population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As noted above,\n",
    "it's more typical now to work with cases where there is no fixed, finite-size population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The process of sampling from the population distribution is replaced with the process of _generating random numbers according to a distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Because of this connection, generating random numbers is often called _sampling_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Be careful interpreting confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is tempting,\n",
    "since confidence intervals represent our uncertainty, to say that,\n",
    "when the 95% confidence interval is `[0, 1]`,\n",
    "we are 95% sure that the value of the statistic on the true distribution is inside that interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, we can see that this interpretation is wrong, because we know the true mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"is {true_means[2010]} inside the interval {bootstrap_CI}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This misapprehension about confidence intervals is very common,\n",
    "enough that if you make it publicly or in a meeting,\n",
    "you're very likely to get [well, actually'd](https://twitter.com/search?q=well%2C+actually%27d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## There's a simple counter example: what is `1 + 1`?\n",
    "\n",
    "Here's a perfectly acceptable procedure for answering this question\n",
    "using a statistic, an estimator, and a confidence interval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- roll a die"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- if that die comes up 1, guess `1`, with the confidence interval `[1, 1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- otherwise, guess `2`, with the confidence interval `[2, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def one_plus_one_CI(data):\n",
    "    if data != 1:\n",
    "        return [2, 2]\n",
    "    else:\n",
    "        return [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "one_plus_one_CI(random.randint(1, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For a 20-sided die, this is a 95% Confidence Interval,\n",
    "but no one would say that there's a 95% chance that the answer to `1+1` is inside the interval `[1, 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Alternative: Credible Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will learn to build models of data and use those to construct\n",
    "both sampling distributions of statistics\n",
    "and something much like a confidence interval, but which can be interpreted as\n",
    "\"there's a 95% chance that the true value is in this interval\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will also see that the alignment between these\n",
    "credible intervals and traditional confidence intervals can be very high,\n",
    "and so things are typically not so bad as in the examples above,\n",
    "and all of the hemming and hawing about how to interpret Confidence Intervals is a bit off base."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
