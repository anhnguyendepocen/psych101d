{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Parameters, Priors, and Posteriors 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util\n",
    "\n",
    "import utils.daft\n",
    "import utils.plot as plot\n",
    "\n",
    "import utils.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Often, our models are less precise than those we made last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We will usually specify models _only up to the values of parameters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare:\n",
    "- I model the rolls on this six-sided die as a `DiscreteUniform` with `lower=1` and `upper=6`\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\text{d}6 \\sim \\text{DiscreteUnif}(\\text{lower}=1, \\text{upper}=6)\n",
    "$\n",
    "\n",
    "```python\n",
    "d6 = pm.DiscreteUniform(lower=1, upper=6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I model the rolls on this die with an unknown number of sides as a `DiscreteUniform` with `lower=1` and an unknown value of `upper`\n",
    "\n",
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ \\text{d}X \\sim \\text{DiscreteUnif}(\\text{lower}=1, \\text{upper}=\\ ?)\n",
    "$\n",
    "\n",
    "```python\n",
    "dX = pm.DiscreteUniform(lower=1, upper=?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Written above the pyMC code, which is hopefully becoming more familiar,\n",
    "are the equivalents in more traditional mathematical notation.\n",
    "\n",
    "The symbol $\\sim$ is pronounced \"is distributed as\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our model of rainfall based on memorylessness gave us the `Poisson` and `Exponential` distributions for counts of drops and times between drops, but for any given rainstorm, the precise shape of the distributions will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$\n",
    "\\ \\ \\ \\ \\ \\ \\ N_{\\text{drops}} \\sim \\text{Pois}(\\mu)\n",
    "$\n",
    "```python\n",
    "N_drops = pm.Poisson(mu=?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, the central limit theorem told us many distributions were `Normal`, but it didn't tell us the precise shape of that distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$S \\sim \\text{Norm}(\\mu, \\sigma)$$\n",
    "\n",
    "where $S$ is a random variable representing, e.g. the value of a statistic that we measure on a random sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\mu \\sim \\ ?, \\ \\ \\sigma \\sim \\ ?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We do not know what $\\mu$ and $\\sigma$ are,\n",
    "but we know that, once we have specific value for them,\n",
    "the distribution of the values of $S$ will be normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Parameters determine the specific distribution inside a family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Different variables have different numbers and names of parameters, but they all have them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Those parameters change the particular shape of the distribution of that random variable,\n",
    "while still keeping it within the same _family_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$x\\sim\\text{Normal}(\\mu, \\sigma)$$\n",
    "\n",
    "$$u\\sim\\text{Unif}(\\text{lower}, \\text{upper})$$\n",
    "\n",
    "$$k\\sim\\text{Poisson}(\\mu)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as different_parameters_model:\n",
    "    # variables from the Normal family\n",
    "    normal_1 = pm.Normal(\"normal_1\", mu=0, sd=1)  # the \"standard normal\"\n",
    "    normal_2 = pm.Normal(\"normal_2\", mu=2, sd=1)  # different mean, same std\n",
    "    normal_3 = pm.Normal(\"normal_3\", mu=0, sd=3)  # same mean, different std\n",
    "    \n",
    "    # variables from the Uniform family\n",
    "    uniform_1 = pm.Uniform(\"uniform_1\", lower=0, upper=1)  # the \"standard uniform\"\n",
    "    uniform_2 = pm.Uniform(\"uniform_2\", lower=-2, upper=3)  # another uniform\n",
    "    \n",
    "    # variables from the Poisson family\n",
    "    poisson_1 = pm.Poisson(\"poisson_1\", mu=1)  # what you might call the \"standard Poisson\"\n",
    "    poisson_2 = pm.Poisson(\"poisson_2\", mu=0.1)  # a Poisson with a lower rate\n",
    "    poisson_2 = pm.Poisson(\"poisson_3\", mu=2)  # a Poisson with a higher rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "diff_params_samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    different_parameters_model, draws=10000, progressbar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.distplot(diff_params_samples[\"normal_1\"], label=r\"$x\\sim$Norm$(\\mu=0, \\sigma=1)$\")\n",
    "sns.distplot(diff_params_samples[\"normal_2\"], label=r\"$x\\sim$Norm$(\\mu=2, \\sigma=1)$\")\n",
    "sns.distplot(diff_params_samples[\"normal_3\"], color=\"C3\", label=r\"$x\\sim$Norm$(\\mu=0, \\sigma=3)$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend(loc=[-0.1, 0.8], framealpha=1); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.distplot(diff_params_samples[\"uniform_1\"],\n",
    "             kde=False, norm_hist=True, bins=5, label=r\"$u\\sim$ Unif$($lower$=0$, upper$=1)$\")\n",
    "sns.distplot(diff_params_samples[\"uniform_2\"],\n",
    "             kde=False, norm_hist=True, bins=5, label=r\"$u\\sim$ Unif$($lower$=-2$, upper$=3)$\");\n",
    "plt.xlabel(\"u\"); plt.axis(\"equal\"); plt.ylim([0, 5]); plt.legend(); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(diff_params_samples[\"poisson_2\"],\n",
    "         bins=range(10), align=\"left\", label=r\"$k\\sim$Pois$(\\mu=0.1)$\", histtype=\"step\", lw=4, density=True)\n",
    "plt.hist(diff_params_samples[\"poisson_1\"],\n",
    "         bins=range(10), align=\"left\", label=r\"$k\\sim$Pois$(\\mu=1)$\", histtype=\"step\", lw=4, density=True)\n",
    "plt.hist(diff_params_samples[\"poisson_3\"],\n",
    "         bins=range(10), align=\"left\", color=\"C3\", label=r\"$k\\sim$Pois$(\\mu=2)$\", histtype=\"step\", lw=4, density=True)\n",
    "plt.xlabel(\"k\"); plt.legend(); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The name of the random variable tells us the shape of the histogram _if all of the parameters are known_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider the model\n",
    "$$\n",
    "x \\sim Foo(\\beta_0,  \\beta_1, \\beta_2)\n",
    "$$\n",
    "where all of the $\\beta_i$ are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For [historical reasons](https://en.wikipedia.org/wiki/Foobar#History_and_etymology),\n",
    "the preferred names for variables in programming whose exact values don't matter,\n",
    "because they're just being used to demonstrate a concept,\n",
    "are `foo`, `bar`, and `baz`.\n",
    "In Python, folks sometimes use [`spam` and `eggs` instead](https://www.dailymotion.com/video/x2hwqlw).\n",
    "\n",
    "Replace `Foo`, in your mind, with a specific example,\n",
    "like `Normal` or `DiscreteUniform`,\n",
    "and the parameters with the parameters for that family:\n",
    "`mu` and `sd`,\n",
    "`lower` and `upper`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "All of the models we worked with last week were of this type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, distribution of x is given by samples from\n",
    "```python\n",
    "pm.Foo(\"X\", beta_0=beta_0_known, beta_1=beta_1_known, beta_2=beta_2_known)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the value of a variable is known or observed, we draw it in our graphs with the circle filled in, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_parameters_graph();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "An arrow is drawn between a pair of random variables when the value of one influences the value of the other.\n",
    "But which direction should the arrows point?\n",
    "Very often, one random variable will be a parameter for another.\n",
    "In that case, we draw the arrow with its tail on the node for the parameter\n",
    "and pointing to the variable it controls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How de we handle parameters we don't know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We treat the parameters as _random variables_: quantities we don't know exactly, but about which we can express our uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_parameters_graph(observed=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joint, Conditional, and Marginal Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Until now, we've only thought about one variable at a time.\n",
    "\n",
    "Once we start thinking about more than one variable,\n",
    "we need more words to talk about different kinds of probabilities with that variable:\n",
    "\n",
    "- What _combinations of values_ are likely to be observed together?\n",
    "- If I know something about one variable, what _values of the others_ are likely to be observed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: A simple model for effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You're studying the psychology of effort:\n",
    "what factors cause a person to try harder when presented with a task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a very simple experiment,\n",
    "you allow participants to play a game with a fixed chance of success, say 50%,\n",
    "multiple times, up to some fixed maximum number of attempts (here, 6),\n",
    "at which point you intervene and end the experiment.\n",
    "You track how many times they play the game and how many times they succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are lots of interesting questions to ask here:\n",
    "does the history of outcomes affect how many times a person plays?\n",
    "what other variables can you manipulate to change that relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But we'll focus on a very simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_bivariate_graph(\"N\", \"S\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\text{Number of Attempts: } N \\sim \\text{Categorical}(p=[0, 1/4, 1/8, 1/8, 1/8, 1/8, 1/4])\\\\\n",
    "\\text{Number of Successes: } S \\sim \\text{Binom}(n=N, p=0.5)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This model expresses the belief that `1/4` of people will only play once,\n",
    "while `1/4` will play until they are told to stop,\n",
    "and the remaining half will stop at some point in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Later, you might come along and see whether changes in some variable changes effort,\n",
    "and make the parameters of $N$ _also_ random variables, with parameters,\n",
    "or you might make $S$ something different from a `Binomial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as effort_model:\n",
    "    attempts = pm.Categorical(\"attempts\", p=[0, 1/4, 1/8, 1/8, 1/8, 1/8, 1/4])\n",
    "    successes = pm.Binomial(\"successes\", n=attempts, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here's a very loose description of the sampling process:\n",
    "- \"Imagine the person were to try 3 times\", aka select a random value for $N$ \n",
    "- \"If they tried 3 times, I can imagine they might succeed twice\", aka sample $S$ with parameter `n=3`.\n",
    "- Repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "effort_samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    effort_model, draws=10000, progressbar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.jointgrid_effort(effort_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice two plots on the sides, or _margins_.\n",
    "They show what we've been looking at so far:\n",
    "the distribution of a variable, without paying attention to the values of other variables.\n",
    "The plot on the y-margin is `sns.distplot` applied to `effort_samples[\"attempts\"]` (with suitable kwargs).\n",
    "\n",
    "The tradition of putting plots and counts like these on the side goes way back,\n",
    "so these are called\n",
    "_marginal_ distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The distributions we've plotted so far are called _marginals_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a `pymc_model` containing the two variables `X` and `Y`,\n",
    "then the heights of the histograms plotted by\n",
    "```python\n",
    "samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    pymc_model, draws))\n",
    "plt.hist(samples[\"X\"])\n",
    "plt.hist(samples[\"Y\"])\n",
    "```\n",
    "will approach a values given by\n",
    "$$\n",
    "p(X) \\text{ and } p(Y)\n",
    "$$\n",
    "as `draws` gets bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Remember that `.sample_from` is just calling `pm.sample`, inside a `with` block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The marginal probabilities of the outcomes $N=x$ and $S=y$ are\n",
    "$$\n",
    "p(N=x) \\text{ and } p(S=y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Sometimes shortened to $p(x)$ or $p_N(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The shapes of marginal distributions are not always given by the name of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the variable `X` is a `pm.Foo`, $p(X)$ is _not_ always going to be a member of the family `Foo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mx = max(effort_samples[\"successes\"]); Ns = range(mx, mx+10); ps = np.linspace(0.1, 0.9, num=90)\n",
    "\n",
    "params = {\"n\": Ns, \"p\": ps}\n",
    "best_params = utils.util.approx_mle(params, scipy.stats.binom.logpmf, effort_samples[\"successes\"])\n",
    "best_binomial_pmf = scipy.stats.binom(**best_params).pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "sns.distplot(effort_samples[\"successes\"],\n",
    "             bins=np.arange(-0.5, 11.5), kde=False, norm_hist=True, ax=ax,\n",
    "             label=r\"estimated $p(S)$\");\n",
    "ax.plot(range(11), best_binomial_pmf(range(11)), lw=4, marker=\".\", markersize=24, label=\"closest binomial\");\n",
    "plt.legend(); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Here, I am ploting $p(\\text{S})$, as estimated from our sampling,\n",
    "against the distribution (aka `pmf`, because it's a discrete variable)\n",
    "of the closest member of the `Binomial` family.\n",
    "\n",
    "It's not important to understand how the closest member of the family was chosen,\n",
    "just to recognize that the shape of $p(S)$ cannot be well-approximated by any `Binomial`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The distribution of multiple variables at once is the _joint distribution_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot.jointgrid_effort(effort_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The center of this plot is a \"2-D histogram\".\n",
    "It is created by `plt.hist2d`,\n",
    "which is much like `plt.hist`, or `sns.distplot` with `kde=False`,\n",
    "but for two variables at once.\n",
    "\n",
    "Values at each point (x, y) are the frequencies at which the pair\n",
    "(attempts, successes) was observed _together_ in the data.\n",
    "\n",
    "Because this is the distribution of values observed together,or _jointly_,\n",
    "it is known as the _joint distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pm.sample` draws from the joint distribution of all unobserved random variables in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a `pymc_model` with just two variables `X` and `Y`,\n",
    "then the heights of the histogram plotted by\n",
    "```python\n",
    "samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    pymc_model, draws))\n",
    "plt.hist2d(samples[\"X\"], samples[\"Y\"])\n",
    "```\n",
    "will approach a value given by\n",
    "$$\n",
    "p(X, Y)\n",
    "$$\n",
    "as `draws` increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: this will only work the correct bins.\n",
    "For a discrete variable, you want one bin for each outcome.\n",
    "For a continuous variable, you need to increase the number of bins along with `draws`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The joint probability of the outcome that  $N=x$ and $S=y$ is\n",
    "$$\n",
    "p(N=x, S=y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.histogram3d(effort_samples[\"attempts\"], effort_samples[\"successes\"],\n",
    "                 labels=[\"Attempts\", \"Successes\"],\n",
    "                 bins=np.arange(-0.5, 7.5), cm=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This 3-D plot presents another way to view the joint distribution.\n",
    "The bars have heights $z$, where\n",
    "$$\n",
    "z = p(N=x, S=y)\n",
    "$$\n",
    "Color corresponds to x position, to make the plot easier to read.\n",
    "Matplotlib does not have a full 3-D rendering engine,\n",
    "so you may seem some small graphical glitches.\n",
    "\n",
    "The heights of all of these bars together add up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Consider a collection of bars with the same color,\n",
    "which correspond to cases where the same number of attempts were made:\n",
    "notice that their shapes, e.g. their centers, are very different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "They are not quite probability distributions: they don't add up to 1.\n",
    "Instead, they add up to $p(N=x)$. Ignoring that point, use them to answer the question below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If I told you that a given participant made 5 attempts,\n",
    "what might you guess the number of successes was?\n",
    "What if it was 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In both cases, you'd want to look at the value of successes observed most often\n",
    "for the number of attempts that was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The most-often-observed value is called the _mode_ of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if I didn't tell you at all?\n",
    "To answer that,\n",
    "you'd want to look at the marginal distribution,\n",
    "and look for the most likely value there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.distplot(effort_samples[\"successes\"], bins=np.arange(-0.5, 7.5), kde=False, norm_hist=True, ax=ax,\n",
    "             label=r\"estimated $p(S)$\"); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this case, the mode of the distribution is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that we started thinking about the same-colored bars as _distributions_ above.\n",
    "We were implictly thinking of them as normalized.\n",
    "\n",
    "Once a collection of these bars is normalized, it is an example of what's called a _conditional distribution_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conditional distributions arise when we place _conditions_ on some of our random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and then look at the distributions of other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a discrete variable, the conditional distributions we've been talking about\n",
    "correspond to the collection of histograms made by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    pymc_model, draws))\n",
    "for n in possible_N_values:\n",
    "    plt.hist(samples[samples[\"N\" == n]][\"S\"],\n",
    "             bins=possible_S_values, density=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "where the _condition_ is `\"N\" == n`.\n",
    "\n",
    "Most of the time, the condition on the random variable will be like this:\n",
    "one or more variables has a given value.\n",
    "\n",
    "But this is not a fundamental restriction!\n",
    "We could use `\"N\" in [2, 3]` as a condition, for example,\n",
    "if we wanted to see what the distribution of `\"S\"` looks like when `\"N\"` is one of those values,\n",
    "but the precise value is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Remember, correspond means \"if I took enough samples, the heights of the histogram bars would be the output of the mathematical formula\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This collection of distributions is written like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(S \\lvert N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "where the $\\lvert$ is pronounced \"given\", as in \"probability of $S$ _given_ $N$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This thing is known, in a slight abuse of terminology, as **the** _conditional distribution_ of $S$ given $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Why abuse? Because it's actually a whole bunch of distributions, one for each possible value of $N$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While an individual histogram,\n",
    "corresponding to the one returned by the Boolean selector `samples[\"N\" == n]`,\n",
    "for some fixed value fo `n`, would be written:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(S\\lvert N=n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "in English, this is \"the probability of $S$ _given_ $N$ is equal to $n$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This thing is known as \"the conditional distribution of $S$ given $N$ is equal to $n$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can plot all of these distributions using `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "viridis_cycler = plot.create_cycler(plt.cm.viridis, 7)\n",
    "kwargs = {\"histtype\": \"step\", \"grid\": False,\n",
    "          \"density\": True, \"bins\":  range(0, 12), \"align\": \"left\"}\n",
    "\n",
    "with mpl.rc_context({\"axes.prop_cycle\": viridis_cycler}):\n",
    "    conditionals_fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    # pandas also has plotting functions, which can be used with groupbys!\n",
    "    effort_samples.groupby(\"attempts\")[\"successes\"].hist(lw=4,\n",
    "        **kwargs);\n",
    "    \n",
    "effort_samples[\"successes\"].hist(lw=6, **kwargs, color=\"k\", label=\"marginal\");\n",
    "ax.set_xlabel(\"Successes\"); plt.legend(); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The collection of all of the colored histograms above is $p(S\\lvert N)$.\n",
    "A single colored histogram is $p(S\\lvert N = n)$ for some fixed $n$.\n",
    "The thicker histogram in black is the marginal, $p(S)$.\n",
    "\n",
    "As above, more brightly-colored means $n$ is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All of these shapes are binomials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = pm.DiscreteUniform.dist(lower=1, upper=6).random().item()\n",
    "label= r\"$p(S\\vert N=\" +str(n) + \")$\"\n",
    "\n",
    "with mpl.rc_context({\"axes.prop_cycle\": viridis_cycler[n:n+1]}):\n",
    "    f, ax = plt.subplots(figsize=(8, 4))\n",
    "    data = effort_samples.groupby(\"attempts\")[\"successes\"].get_group(n)\n",
    "    best_binomial_pmf = scipy.stats.binom(n=n, p=data.mean() / n).pmf\n",
    "    data.hist(\n",
    "        histtype=\"step\", lw=4, grid=False, density=True, bins=range(0, 7), label=label, align=\"left\");\n",
    "    plt.xlabel(\"Successes\")\n",
    "    \n",
    "ax.plot(range(7),\n",
    "        best_binomial_pmf(range(7)), lw=4, marker=\".\", markersize=24,\n",
    "        label=\"closest binomial\", color=\"C1\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Here, I'm picking a random value of `N`\n",
    "(pyMC can also be used to generate random variables outside of a model,\n",
    "using the `.dist` and `.random` methods as above).\n",
    "\n",
    "Then, I'm grabbing the values of `successes` observed when the `\"attempts\"` is equal to `n`\n",
    "with a `groupby` (and `.get_group` to pull out a single group).\n",
    "\n",
    "Lastly, I'm comparing the histogram of those values to the `Binomial` whose distribution\n",
    "is closest to it.\n",
    "Again, the method for picking the parameters of that `Binomial` is not important just yet.\n",
    "\n",
    "All of the histograms are close to their `best_binomial` fits,\n",
    "which you can observe by executing the cell repeatedly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can say very concretely what it means for `X` to be a `Foo` random variable, aka the output of `pm.Foo`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It means that the conditional distribution of `X`, _given a specific value for all of its parameters_, is a `Foo` distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_parameters_graph();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: the documentation of pyMC refers to things like `pm.Foo` as \"log-likelihoods\".\n",
    "\n",
    "We'll see why at the end of this lecture, in the section on Bayes' Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the concrete case we're considering,\n",
    "```python\n",
    "S = pm.Binomial(...)\n",
    "```\n",
    "and therefore\n",
    "the conditional distribution of `S`, given all of its parameters, is `Binomial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "conditionals_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The height of the histogram at a point $s$ on the \"Successes\" axis is\n",
    "$$\n",
    "p(S=s\\lvert N=n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "in English, this is \"the probability that $S$ is equal to $s$ _given_ $N$ is equal to $n$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that, in general, the frequency at which a pair of values is observed in the data\n",
    "can't be determined by looking just at the frequencies of the two values separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is important that the values are _taken from the same sample_.\n",
    "In real data, that means measured at the same time, or from the same subject, or similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Shuffling lets us approximate what our data would look like\n",
    "if it didn't matter whether we took from the same sample or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_samples = pd.DataFrame(effort_samples[\"successes\"])\n",
    "shuffled_samples[\"attempts\"] = effort_samples[\"attempts\"].sample(frac=1).values  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.jointgrid_effort(shuffled_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that the joint distribution has changed,\n",
    "even though the marginal distributions have not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.histogram3d(shuffled_samples[\"attempts\"], shuffled_samples[\"successes\"],\n",
    "                 labels=[\"Attempts\", \"Successes\"], bins=np.arange(-0.5, 7.5),\n",
    "                 cm=plt.cm.viridis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, all of the conditional distributions have about the same shape:\n",
    "each collection of similar-colored bars has the same overall shape,\n",
    "the shape of the marginal distribution of $S$,\n",
    "though the bars are all _scaled differently_:\n",
    "if the fraction of times a given number of attempts occurred is smaller,\n",
    "all of the bars in that column are shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with mpl.rc_context({\"axes.prop_cycle\": viridis_cycler}):\n",
    "    f, ax = plt.subplots(figsize=(8, 4))\n",
    "    shuffled_samples.groupby(\"attempts\")[\"successes\"].hist(\n",
    "        histtype=\"step\", lw=4, grid=False, density=True, bins=range(0, 12));\n",
    "\n",
    "shuffled_samples[\"successes\"].hist(\n",
    "    histtype=\"step\", lw=6, grid=False, density=True, bins=range(0, 12), color=\"k\", label=\"marginal\");\n",
    "ax.set_xlabel(\"Successes\"); plt.legend(); plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This figure, which is once again plotting the conditional distributions $p(S\\lvert N)$,\n",
    "indicates that the difference in heights goes away once we take into account\n",
    "the fraction of obesrvations with $N=x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So in general,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(S=y, N=x) \\neq p(S=y) \\cdot p(N=x) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But instead,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(S=y, N=x) = p(S=y \\lvert N=x) \\cdot p(N=x) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But if $p(S=y\\lvert N=x)$ is the same as  $p(S=y)$, the marginal probability, as in the shuffled data above, then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{align}\n",
    "p(S=y, N=x) &= p(S=y \\lvert N=x) \\cdot p(N=x) \\\\\n",
    "&= p(S=y) \\cdot p(N=x) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is called _statistical independence_,\n",
    "and we'll have more to say about it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that you can do the same looking the other way:\n",
    "look at a collection of bars that have the same position on the \"Successes\" axis.\n",
    "That would be the conditional distribution\n",
    "\n",
    "$$\n",
    "p(N \\lvert S=y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Call `histogram3d` with the keyword argument `colorby=\"y\"` to color the bars\n",
    "according to the value of their position on the \"Successes\" axis instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Measurement Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whenever we measure an analog value out in the world,\n",
    "the thing we would like to measure,\n",
    "the _signal_,\n",
    "is all mixed up with things we didn't intend to measure,\n",
    "the _noise_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'd like to measure an organism's weight, but the weight we measure varies according to factors like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - most recent meal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - point in the breathing cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - air pressure fluctuations on our scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - electronic or mechanical variability inside our scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - the [position of the moon](https://www.quora.com/How-much-does-the-orbit-of-the-Moon-affect-my-weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_bivariate_graph(\"S\", \"M\", observed=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, we have a $S$ignal we'd like to know the value of and a $M$easurement we've taken:\n",
    "\n",
    "$$\n",
    "M \\sim \\text{Norm}\\left(S, 1\\right) \\\\\n",
    "S \\sim \\text{Norm}\\left(0, 1\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or, alternatively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "M  \\sim S + \\varepsilon \\\\\n",
    "S \\sim \\text{Norm}(0, 1) \\\\\n",
    "\\varepsilon \\sim \\text{Norm(0,  1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Where the term $\\varepsilon$ is called the _noise_.\n",
    "\n",
    "Why does it have a normal distribution?\n",
    "Because if we assume that the factors interfering with our measurement\n",
    "are numerous,\n",
    "are mostly independent from one another,\n",
    "and combine approximately additively,\n",
    "the Central Limit Theorem says their distribution will be normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The name _noise_ comes from what such interfering factors sound like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "noise = pd.Series(pm.Normal.dist(mu=0, sd=1).random(size=62500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Audio(noise, rate=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These ideas were worked out for the case where $S$ was an analog audio signal,\n",
    "being transmitted over radio waves or a similar medium.\n",
    "\n",
    "The exact materials through which the waves passed, the state and behavior of the air,\n",
    "the uncontrolled behavior of the small electronic components of the radios,\n",
    "all combined together to vary the audio signal at the receiver.\n",
    "Shockingly, the result always sounds about the same: it is _noise_.\n",
    "\n",
    "When you want to be particular, this kind of noise is called\n",
    "[white noise](https://en.wikipedia.org/wiki/White_noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "PIL.Image.fromarray(utils.util.to_image(noise.sample(10000))).resize((250, 250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It also shows up in the analog transmission of visual signals,\n",
    "e.g. television, where it is known as _static_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Normal distributions are perhaps less common when measuring psychological phenomena,\n",
    "for which there aren't numerous, independent nuisances, like there are for more directly physical phenomena.\n",
    "\n",
    "However, many branches of psychology now measure physical phenomena in the brain,\n",
    "using tools like\n",
    "[PET and EEG](https://charlesfrye.github.io/FoundationalNeuroscience/84/)\n",
    "or [fMRI](https://charlesfrye.github.io/FoundationalNeuroscience/83/),\n",
    "and so their measurements are often subject to Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In pyMC, our model for this measurement process looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as measurement_model:\n",
    "    signal = pm.Normal(\"signal\", mu=0, sd=1)\n",
    "    measurement = pm.Normal(\"measurement\", mu=signal, sd=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Loose description of sampling process:\n",
    "- \"Imagine the signal were 0.267\", aka select a random value of the signal \n",
    "- \"If the signal were 0.267, a plausible value of the measutement is .753\", aka sample S with parameter mu=0.267.\n",
    "- Repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "measurement_samples = shared_util.samples_to_dataframe(shared_util.sample_from(\n",
    "    measurement_model, draws=10000, progressbar=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "measurement_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hexplot = sns.jointplot(measurement_samples[\"signal\"], measurement_samples[\"measurement\"], kind=\"hex\", height=8);\n",
    "plot.add_cbar(hexplot.fig);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The center of this plot is another \"2-D histogram\".\n",
    "Rather than using square bins, it uses hexagonal bins,\n",
    "but it's still just counting how many observations are in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.histogram3d(measurement_samples[\"signal\"], measurement_samples[\"measurement\"],\n",
    "                 labels=[\"Signal\", \"Measurement\"],\n",
    "                 cm=plt.cm.Blues, colorby=\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can once again shuffle one of the columns to see what the joint distribution might look like\n",
    "if the two variables were independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hexplot = sns.jointplot(measurement_samples[\"signal\"].sample(frac=1), measurement_samples[\"measurement\"],\n",
    "                        kind=\"hex\", height=8);\n",
    "plot.add_cbar(hexplot.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot.histogram3d(measurement_samples[\"signal\"].sample(frac=1), measurement_samples[\"measurement\"],\n",
    "                 labels=[\"Signal\", \"Measurement\"],\n",
    "                 cm=plt.cm.Blues, colorby=\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice: the heights of the bars are not the same, going across x or across y,\n",
    "but the _shape_ of the collection of bars, going across y but fixing a value of x,\n",
    "is the same as the _shape_ of the collection of bars at a different value of x,\n",
    "and both shapes look like their respective marginal distribution."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
