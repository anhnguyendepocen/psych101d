{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Bayesian Inference 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import daft\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def compare_bernoullis(bernoulli_samples, colors=None, titles=None):\n",
    "    \"\"\"Given a list of Series representing samples from a Bernoulli variable,\n",
    "    plot histograms of each Series in the list.\n",
    "    Optionally, provide a color and/or title for each histogram.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    bernoulli_samples: list of Series or list of arrays. Each element in\n",
    "                       this list is passed to sns.distplot\n",
    "    colors : list of strings or None. If not None, use to color the histograms.\n",
    "    titles : list of strings or None. If not None, use to title the axes.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    f : matplotlib Figure containing axs with histograms plotted in\n",
    "    axs : array of matplotlib Axes\n",
    "    \"\"\"\n",
    "    n_bernoullis = len(bernoulli_samples)\n",
    "    \n",
    "    f, axs = plt.subplots(figsize=(6 * n_bernoullis, 6),\n",
    "                          ncols=n_bernoullis,  sharex=True, sharey=True)\n",
    "    if n_bernoullis == 1:\n",
    "        axs = np.array([axs])\n",
    "    if colors is None:\n",
    "        colors = [None] * n_bernoullis\n",
    "    if titles is None:\n",
    "        titles = [\"\"] * n_bernoullis\n",
    "        \n",
    "    assert len(colors) == n_bernoullis, f\"provide the same number of colors as bernoulli_samples: {n_bernoullis}\"\n",
    "    assert len(titles) == n_bernoullis, f\"provide the same number of titles as bernoulli_samples: {n_bernoullis}\"\n",
    "    \n",
    "    bins = [-0.5, 0.5, 1.5]\n",
    "    kwargs = {\"kde\": False, \"bins\": bins,\n",
    "              \"norm_hist\": True, \"hist_kws\": {\"alpha\": 1, \"ec\": \"k\", \"lw\": 4}}\n",
    "    for ax, bernoulli, color, title in zip(axs, bernoulli_samples, colors, titles):\n",
    "        sns.distplot(bernoulli, **kwargs, color=color, ax=ax);\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "    [ax.set_xticks([0, 1]) for ax in axs]\n",
    "    [ax.set_xticklabels([\"0\", \"1\"]) for ax in axs];\n",
    "    return f, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def add_arrow_chain(prior1, ax):\n",
    "    posterior1 = posterior_given_passing(prior1)\n",
    "    ax.arrow(prior1, posterior1, (posterior1 - prior1) * 0.67, 0, lw=4, head_width=0.02, color=\"k\")\n",
    "    \n",
    "    prior2 = posterior1\n",
    "    posterior2 = posterior_given_passing(prior2)\n",
    "    \n",
    "    ax.vlines([prior1, prior2], [prior1, prior2], [posterior1, posterior2], lw=4, color=\"C3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Previously, we derived Bayes' Rule,\n",
    "for relating conditional probabilities to one another,\n",
    "for \"inverting\" a conditional probability statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(A \\vert B) \\ \\ \\ \\overleftrightarrow{\\text{Bayes}} \\ \\ \\ p(B \\vert A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The important special case of this rule that was considered last week\n",
    "was the relationship between a hypothesis and data that provided evidence about that hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{hypothesis}\\vert \\text{data}) = \\frac{p(\\text{data}\\vert \\text{hypothesis}) p(\\text{hypothesis})}{p(\\text{data})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The left term in the numerator is the _likelihood_:\n",
    "typically, our data is fixed, and we vary the hypothesis,\n",
    "obtaining the probability we would observe the data we did observe,\n",
    "for each hypothesis we consider.\n",
    "\n",
    "When we build a model,\n",
    "this is the piece that relates unknown quantities,\n",
    "like the true mean of the population,\n",
    "to quantities we can observe, like the value on a sample.\n",
    "\n",
    "Note how much easier it is to specify this direction of conditional probability\n",
    "than the other way around.\n",
    "\n",
    "For example: if I know that an animal is a cat, rather than a dog,\n",
    "I can guess its weight.\n",
    "But if I know an animal's weight, I need to think quite a bit harder\n",
    "to determine whether its a dog or a cat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The right term in the numerator is the _prior_:\n",
    "the probability we assign to the hypothesis,\n",
    "having not seen any data.\n",
    "\n",
    "When we build a model,\n",
    "this is the piece that captures the knowledge we bring to the problem\n",
    "from our experience, from the scientific literature, or by assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall that, for pyMC to work,\n",
    "we don't need to specify the denominator:\n",
    "we only need to know the probability of the hypothesis\n",
    "\"up to a proportionality constant\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{hypothesis}\\vert \\text{data}) \\propto p(\\text{data}\\vert \\text{hypothesis}) p(\\text{hypothesis})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayes' Rule and Binary Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In last week's lab, we were even more specific:\n",
    "we focused in on the case where the \"data\" we observe is just the result of a statistical test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{hypothesis}\\vert \\text{test result}) = \\frac{p(\\text{test result}\\vert \\text{hypothesis}) p(\\text{hypothesis})}{p(\\text{test result})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $ p(\\text{hypothesis})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the _prior_ component of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prior_on_null = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In the lab, we said that we thought there was a 50% chance that the null was true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $ p(\\text{test result}\\vert \\text{hypothesis})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the _likelihood_ component of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The state of the null hypothesis determines which column we are in in this table.\n",
    "Remember that this is generally unknown, even unknowable!\n",
    "\n",
    "The output of the statistical test determines which row.\n",
    "This is the component that we actually know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+2\"> $$ p(\\text{result}\\vert \\text{hypothesis}=T)$$ </font></th>\n",
    "        <th > <font size=\"+2\"> $$ p(\\text{result}\\vert \\text{hypothesis}=F)$$ </font></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td ><font size=\"+2\"> $$+$$ </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> True Positive Rate, Power, Sensitivity </font> </td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> False Positive Rate, &#945; </font> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "         <td ><font size=\"+2\"> $$-$$</font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> False Negative Rate, &#946; </font></td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> True Negative Rate, Specificity </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Color indicates the components that are probability distributions: they add up to 1.\n",
    "The columns of this table are probability distributions, and so add up to 1.\n",
    "\n",
    "The rows of this table for our model do not add up to 1,\n",
    "and they shouldn't, in general.\n",
    "\n",
    "Since we think of our data\n",
    "(in this case, the output of the statistical test)\n",
    "as being fixed and compare the choices of the value of the unknown\n",
    "(in this case, the truth value of the null hypothesis),\n",
    "we are usually in the case where we are moving within a row of this table,\n",
    "rather than within a column.\n",
    "\n",
    "That's why this component has the name _likelihood_,\n",
    "more specificially _data likelihood_,\n",
    "rather than anything involving the word \"probability\",\n",
    "as in _prior probability_ and _posterior probability_:\n",
    "probabilities add up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These are both binary variables, so we can model them as `Bernoulli`s and need to specify a value for `p` for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.05; power = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These values were used in the lab.\n",
    "\n",
    "The value of `alpha`, remember, is determined by our cutoff on the $p$ statistic.\n",
    "\n",
    "The value of `power` is trickier to determine, and ranges from `0.3` for small, noisy studies,\n",
    "as are common in many branches of biology, including neuroscience,\n",
    "up to `0.8` or `0.9` or higher for large, well-controlled studies,\n",
    "like clinical trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We Can Almost Never Write Down a Table, But We Can Almost Always Write Down a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as science_model_positive_result:\n",
    "    null_true = pm.Bernoulli(\"null_true\", p=prior_on_null)\n",
    "    positive_result = pm.Bernoulli(\"positive_result\",\n",
    "                                   p=pm.math.switch(null_true, alpha, power), observed=1,\n",
    "                                   dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Depending on the context, this will be called a\n",
    "- _`pyMC` model_, when we want to emphasize the concrete implementation\n",
    "- _generative model_, when we want to emphasize the abstract concept\n",
    "\n",
    "Some terms you might hear elsewhere:\n",
    "- _Bayesian model_, _Bayesian network_, _graphical model_, _probabilistic program_, _directed acylic graph_ (DAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we want to ask questions of the model,\n",
    "we draw samples from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Any technique for statistical estimation based on simulating random samples is a _Monte Carlo_ technique.\n",
    "\n",
    "For example, bootstrapping is also a Monte Carlo technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples_from_prior = pm.sample_prior_predictive(model=science_model_positive_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples_from_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "samples_from_prior_df = shared_util.samples_to_dataframe(samples_from_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`sample_prior_predictive` produces a dictionary,\n",
    "as does `sample_posterior_predictive`,\n",
    "while `pm.sample` produces something else called a `MultiTrace`.\n",
    "\n",
    "For most of our analysis, we want to think of these all as _samples_,\n",
    "so we convert to one datatype, a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(samples_from_prior_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "null_true_selector = samples_from_prior_df[\"null_true\"].astype(bool)\n",
    "null_false_selector = -null_true_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: pyMC works exclusively with numbers.\n",
    "Variable values cannot be `bool`eans or `str`ings,\n",
    "only things like `int`s and `float`s.\n",
    "\n",
    "`pandas`, on the other hand, uses `bool`eans and `str`ings quite a lot,\n",
    "and so you'll need to interconvert between the two.\n",
    "\n",
    "This will come up when using data from `pandas` as\n",
    "the observed values in pyMC,\n",
    "e.g. in this week's lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "compare_bernoullis(\n",
    "    [samples_from_prior_df[\"positive_result\"].loc[null_true_selector],\n",
    "     samples_from_prior_df[\"positive_result\"].loc[null_false_selector]],\n",
    "    colors=[\"C0\", \"C1\"], titles=[\n",
    "        \"Null Hypothesis True:\\n $P(R\\\\vert H_0=$True$)$\",\n",
    "        \"Null Hypothesis False:\\n $P(R\\\\vert H_0=$False$)$\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> $$F$$ </font> </th>\n",
    "        <th > <font size=\"+1\"> $$T$$ </font> </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td > <font size=\"+2\"> $$+$$ </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> True Positive Rate, Power, Sensitivity </font> </td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> False Positive Rate, &#945; </font> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "         <td ><font size=\"+2\"> $$-$$ </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> False Negative Rate, &#946; </font></td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> True Negative Rate, Specificity </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayes and Bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, let's do another example, also with binary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "HTML(filename=\"data/debug_tweet.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we write code, we aim for it to have no bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To try and ensure this,\n",
    "we write tests and check whether the code passes those tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If a chunk of code fails a test,\n",
    "then we know there's a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Presuming our tests don't have bugs! Remember [Cromwell's Rule](https://en.wikipedia.org/wiki/Cromwell%27s_rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But in Python, even if we've got really good tests,\n",
    "there's still a chance a bug slips through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some other languages can make guarantees, of a sort,\n",
    "that certain kinds of bugs are not present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the inferential question here is:\n",
    "if I write code that passes all my tests,\n",
    "what's the chance that it has no bugs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $$ p(\\text{no bugs}\\vert \\text{pass tests}) = 🤔$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, what should I _believe_ about the bugginess of my code,\n",
    "_after_ I've passed the tests.\n",
    "\n",
    "It's intuitive that this depends on what kinds of code I tend to write\n",
    "and how good my tests are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As we'll see,\n",
    "if we just write out Bayes' Rule\n",
    "and start filling it in,\n",
    "those two intuitions will pop out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{no bugs}\\vert \\text{pass tests}) = \\frac{p(\\text{pass tests}\\vert \\text{no bugs}) p(\\text{no bugs})}{p(\\text{pass tests})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Afterwards, we'll compare our answer to pyMC's results.\n",
    "\n",
    "The \"direct\" method we use here won't scale\n",
    "to bigger, more complicated problems,\n",
    "but pyMC will."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "At least to a certain extent.\n",
    "\n",
    "There are, of course, problems too big for any approach.\n",
    "For Bayesian Monte Carlo methods like pyMC,\n",
    "some of those problems are practical applications,\n",
    "like images and video.\n",
    "\n",
    "But for statistical inference\n",
    "of the kind most often done in research psychology,\n",
    "Bayesian Monte Carlo will scale well enough to do the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This example comes from\n",
    "[Chapter 1](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb)\n",
    "of the GitHub textbook\n",
    "[Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers),\n",
    "one of the core inspirations for this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prior: $ p(\\text{no bugs}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is the chance that the code I have written, without testing it,\n",
    "has no bugs in it.\n",
    "\n",
    "It expresses my beliefs about my code, before I have observed the results of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In real life, this prior wouldn't be so simple:\n",
    "if the code were more complicated,\n",
    "the prior probability would be lower,\n",
    "while if it were less complicated,\n",
    "or I had worked on it with a friend,\n",
    "the prior probability might be higher.\n",
    "\n",
    "You might even start to think of it as a function of other variables,\n",
    "some of which you can measure and some of which you can't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prior_no_bugs = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Below, this will be denoted $p_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Likelihood: $ p(\\text{pass tests} \\lvert \\text{no bugs}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This component relates one variable's value to the distribution over another variable's possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Most often, it relates the value of a variable we _cannot_ observe\n",
    "to a distribution over the values of a variable we _can_ observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> No Bugs </font> </th>\n",
    "      <th > <font size=\"+1\"> Some Bugs </font> </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td > <font size=\"+1\"> Pass </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 1 </font> </td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.5 </font> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "      <td ><font size=\"+1\"> Fail </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 0 </font></td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.5 </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def tests_likelihood(observation, truth_about_code):\n",
    "    if observation == \"pass tests\":\n",
    "        if truth_about_code == \"no bugs\":\n",
    "            return 1\n",
    "        elif truth_about_code == \"some bugs\":\n",
    "            return 0.5\n",
    "        \n",
    "    if observation == \"fail tests\":\n",
    "        if truth_about_code == \"no bugs\":\n",
    "            return 0\n",
    "        elif truth_about_code == \"some bugs\":\n",
    "            return 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This code implements a \"look-up table\"\n",
    "for the likelihood above.\n",
    "\n",
    "You might think of all of the likelihoods in all of our models as being\n",
    "just big, fast versions of a look-up table like this one:\n",
    "given a value for the parameters (bugs or no bugs)\n",
    "and the observations (pass or fail),\n",
    "they return a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are only interested in what happens if the code passes the tests,\n",
    "so we can make a simple function that only looks at a \"row\" of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def likelihood_test_passed(truth_about_code):\n",
    "    return tests_likelihood(\"pass tests\", truth_about_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "likelihood_test_passed(\"no bugs\") + likelihood_test_passed(\"some bugs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalizing Factor: $p(\\text{pass tests})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is also called the _marginal probability of the observations_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{pass tests}) = p(\\text{pass tests}\\ ,\\ \\text{no bugs}) + p(\\text{pass tests}\\ ,\\ \\text{some bugs})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The chance that we pass the tests is\n",
    "\n",
    "- the chance we pass the tests and there are no bugs PLUS\n",
    "- the chance we pass the tests and there are some bugs\n",
    "\n",
    "We could have instead written it as\n",
    "\n",
    "- the chance we pass the tests and [Mercury is in retrograde](https://www.ismercuryinretrograde.com/) PLUS\n",
    "- the chance we pass the tests and Mercurcy is not in retrograde\n",
    "\n",
    "since the only thing that matters is that we break the probabiity down\n",
    "in terms of two mutually exclusive events.\n",
    "\n",
    "But using the behavior of Mercury wouldn't give us\n",
    "a useful way of breaking down the number we're trying to calculate,\n",
    "whereas the way we chose gives us,\n",
    "by applying the rule $p(x,y) = p(x\\vert y)p(y)$ twice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{pass tests}) = p(\\text{pass tests}\\vert \\text{no bugs}) p(\\text{no bugs}) + p(\\text{pass tests}\\vert \\text{some bugs}) p(\\text{some bugs})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These are all numbers from our likelihood and prior!\n",
    "\n",
    "And indeed, once you have a likelihood and a prior,\n",
    "nothing in principle is stopping you from calculating\n",
    "this normalization factor.\n",
    "\n",
    "For us,\n",
    "the numbers are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{pass tests}) = 1 \\cdot p_n + 0.5 \\cdot (1 - p_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Which we calculate in Python as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "prior_some_bugs = 1 - prior_no_bugs\n",
    "\n",
    "normalizing_factor = likelihood_test_passed(\"no bugs\") * prior_no_bugs\\\n",
    "    + likelihood_test_passed(\"some bugs\") * prior_some_bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "normalizing_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This example is a bit deceptive:\n",
    "with more complicated discrete models, the number of things we need to add together grows very rapidly.\n",
    "With continuous variables, the sum becomes an integral, and those are very hard in general.\n",
    "With complicated continuous models, the result is a high dimensional integral,\n",
    "for which we have very limited mathematical tools.\n",
    "\n",
    "So even though it's possible to do, in theory,\n",
    "it is impractical, and so pyMC is built specifically to avoid computing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Posterior: $p(\\text{no bugs}\\vert \\text{pass tests})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is what we were actually interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $$ p(\\text{no bugs}\\vert \\text{pass tests}) = 🤔$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unlike the majority of cases,\n",
    "in this one we can actually calculate the posterior directly by hand,\n",
    "using the quantities above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We begin by writing out Bayes' Rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{align}\n",
    "p(\\text{no bugs}\\vert \\text{pass tests}) &= \\frac{p(\\text{pass tests}\\vert \\text{no bugs})p(\\text{no bugs})}{ p(\\text{pass tests})}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "then we plug in the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{align}\n",
    "p(\\text{no bugs}\\vert \\text{pass tests}) &= \\frac{1 \\cdot p_n}{ 1 \\cdot p_n + 0.5 \\cdot (1 - p_n)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "and simplify:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\begin{align}\n",
    "p(\\text{no bugs}\\vert \\text{pass tests}) &= \\frac{2 p_n}{2 p_n +(1 - p_n)}\\\\\n",
    "&= \\frac{2 p_n}{ p_n + 1}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And so our posterior probability is no longer a mystery.\n",
    "\n",
    "It's just this simple function of our prior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $$ p(\\text{no bugs}\\vert \\text{pass tests}) \\neq 🤔$$ \n",
    "\n",
    "### $$ p(\\text{no bugs}\\vert \\text{pass tests}) = \\frac{2 p_n}{p_n + 1}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's use this function to get our posterior,\n",
    "given all of the assumptions we made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# note that this assumes that our likelihood of passing with some bugs was 0.5!\n",
    "# if you change the definition of likelihood above, you also need to rederive the values for this function\n",
    "\n",
    "def posterior_given_passing(p_no_bugs):\n",
    "    return 2 * p_no_bugs / (p_no_bugs + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(prior_no_bugs, posterior_given_passing(prior_no_bugs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This makes sense: once you've seen the tests pass,\n",
    "the chance there are no bugs increases, but it doesn't go to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Clearly, the posterior depends on our prior,\n",
    "which we set fairly arbitrarily.\n",
    "\n",
    "Let's take a look at what the posterior probability looks like for \n",
    "a bunch of different values of the prior porbability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10)); ps = np.linspace(0, 1, num=100)\n",
    "ax.plot([0, 1],  [0, 1], color=\"gray\", lw=4, ls=\"--\", label=\"Prior\");\n",
    "ax.plot(ps, posterior_given_passing(ps), lw=4, label=\"Posterior\");\n",
    "ax.vlines(ps, ps, posterior_given_passing(ps), color=\"C3\", zorder=0, label=\"Change in Beliefs\");\n",
    "ax.set_xlim(0, 1); ax.set_ylim(0, 1); ax.legend();\n",
    "ax.set_xlabel(\"$p_n$, prior $p$ of bug-free code\");\n",
    "ax.set_ylabel(\"$p($no bugs $\\\\vert$ passed tests$)$\\nposterior $p$ of bug-free code\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "1. Observing that the tests were passed always decreases the chance that there are bugs.\n",
    "2. The only time that observing that the tests were passed doesn't change the posterior from the prior\n",
    "is when the prior is 0 or 1: if you're certain, you have no need of evidence.\n",
    "3. The change is maximized when the prior is 0.5: evidence is most useful when you are most uncertain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For Comparison, the pyMC Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Returning to the original problem,\n",
    "let's remind ourselves of how we'd use pyMC to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $$ p(\\text{no bugs}\\vert \\text{pass tests}) = 🤔$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The pyMC approach to solving this problem is to _approximate the posterior_\n",
    "by drawing samples from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as bugs_model:\n",
    "    bug_free = pm.Bernoulli(\"bug_free\", p=prior_no_bugs)  # prior\n",
    "    \n",
    "    pass_test_no_bugs = likelihood_test_passed(\"no bugs\")\n",
    "    pass_test_some_bugs = likelihood_test_passed(\"some bugs\")\n",
    "    \n",
    "    pass_tests = pm.Bernoulli(  # likelihood\n",
    "        \"pass_tests\",\n",
    "        p=pm.math.switch(\n",
    "            bug_free, pass_test_no_bugs, pass_test_some_bugs),\n",
    "        observed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "posterior_samples_trace = shared_util.sample_from(bugs_model)\n",
    "posterior_samples_df = shared_util.samples_to_dataframe(posterior_samples_trace)\n",
    "\n",
    "posterior_ps = posterior_samples_df[\"bug_free\"].value_counts().sort_index() / len(posterior_samples_df)\n",
    "posterior_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.bar([0, 1], posterior_ps, color=\"C2\");\n",
    "ax.set_xticks([0, 1]); ax.set_xticklabels([\"some bugs\", \"bug free\"]);\n",
    "ax.set_ylabel(\"Posterior probability\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iteratively Applying Bayes' Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say we write another set of tests, and the code passes again.\n",
    "\n",
    "What is our new answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $$ p(\\text{no bugs}\\vert \\text{pass both sets of tests}) = 🤔$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember that our prior represented our beliefs before we observed the first tests had been passed.\n",
    "\n",
    "The posterior represents our beliefs after we observed the first tests had been passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_After_ the first tests have been passed is also _before_ the second tests have been passed.\n",
    "\n",
    "Therefore the posterior for the first set of tests is the prior for the second set of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Nach dem Spiel ist vor dem Spiel\n",
    "\n",
    "Sepp Herberger, German football coach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In English: \"After the game is before the game\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(posterior_given_passing(prior_no_bugs), # prior for second tests\n",
    "      posterior_given_passing(posterior_given_passing(prior_no_bugs)) ) # posterior for second tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10)); ps = np.linspace(0, 1, num=100)\n",
    "ax.plot([0, 1],  [0, 1], color=\"gray\", lw=4, ls=\"--\", label=\"Prior\");\n",
    "ax.plot(ps, posterior_given_passing(ps), lw=4, label=\"Posterior\");\n",
    "ax.vlines(ps, ps, posterior_given_passing(ps), color=\"C3\", zorder=0, label=\"Change in Beliefs\");\n",
    "ax.set_xlim(0, 1); ax.set_ylim(0, 1); ax.legend();\n",
    "add_arrow_chain(prior_no_bugs, ax);\n",
    "ax.set_xlabel(\"$p_n$, prior $p$ of bug-free code\"); #plt.axis(\"equal\");\n",
    "ax.set_ylabel(\"$p($no bugs $\\\\vert$ passed tests$)$\\nposterior $p$ of bug-free code\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The thick red vertical lines above represent the updating of our beliefs from the prior to the posterior.\n",
    "\n",
    "The one going from `0.2` to approximately `0.33` represents the update to our beliefs after the first set of tests.\n",
    "\n",
    "The arrow indicates that, when we apply another test to the same unknown variable,\n",
    "the posterior (position on y-axis) becomes the prior (position of x-axis).\n",
    "Our final beliefs about the unknown variable,\n",
    "whether the code has bugs,\n",
    "are obtained by applying Bayes' Rule to get a posterior from that prior\n",
    "(graphically, by following the thick red line from `0.33` to `0.5`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A fun exercise:\n",
    "rewrite `posterior_given_passing` so that it also takes in the `likelihood_test_passed`\n",
    "and compute the posterior given Bayes' rule,\n",
    "then edit the parameters of the likelihood and see how it changes the posterior as a function of the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Rule Flips the Table Around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Returning to the picture in terms of tables representing conditional distributions,\n",
    "we can see that Bayes' Rule has taken this table,\n",
    "representing the likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> No Bugs </font> </th>\n",
    "      <th > <font size=\"+1\"> Some Bugs </font> </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td > <font size=\"+1\"> Pass </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 1 </font> </td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.5 </font> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "      <td ><font size=\"+1\"> Fail </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 0 </font></td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.5 </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and, by combining it with the prior, turned it into this table,\n",
    "representing the posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> No Bugs </font> </th>\n",
    "      <th > <font size=\"+1\"> Some Bugs </font> </th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(0,50,98); color: white\">\n",
    "        <td > <font size=\"+1\"> Pass </font></td>\n",
    "      <td> <font size=\"+2\"> 1/3 </font> </td>\n",
    "      <td> <font size=\"+2\"> 2/3 </font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(253,181,21);\">\n",
    "      <td><font size=\"+1\"> Fail </font></td>\n",
    "      <td> <font size=\"+2\"> 0 </font></td>\n",
    "      <td> <font size=\"+2\"> 1 </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For NHST, these probabilities have special names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> Null Hypothesis False </font> </th>\n",
    "      <th > <font size=\"+1\"> Null Hypothesis True </font> </th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(0,50,98); color: white\">\n",
    "        <td > <font size=\"+2\"> + </font></td>\n",
    "      <td> <font size=\"+2\"> Positive Predictive Value </font> </td>\n",
    "      <td> <font size=\"+2\"> False Discovery Rate</font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(253,181,21);\">\n",
    "      <td><font size=\"+2\"> - </font></td>\n",
    "      <td> <font size=\"+2\"> False Omission Rate </font></td>\n",
    "      <td> <font size=\"+2\"> Negative Predictive Value </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's think about these terms for the \"bugs\" example,\n",
    "where the null hypothesis is that you have some bugs.\n",
    "\n",
    "- Tests have a very high negative predictive value: if you fail a test, you have a bug,\n",
    "so failing a test is very informative\n",
    "\n",
    "- Tests have a much lower positive predictive value: if you pass the tests,\n",
    "you still have a good chance of having a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The need for prior probabilities to \"flip the table around\" with Bayes' Rule\n",
    "is one reason why most statistical treatments only focus on the likelihood,\n",
    "the \"forward model\" table.\n",
    "\n",
    "But when you're trying to interpret the outputs of a test,\n",
    "this table is the one you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Medical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Someone I know had a medical test (below, Test 2) done in an attempt to confirm a diagnosis strongly suggested by an earlier test (Test 1).\n",
    "\n",
    "Test 2 came back negative, out of alignment with both Test 1 and with some other clinical evidence.\n",
    "In light of this, the physician recommended more expensive and invasive testing to rule out alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The reported numbers for $p(+\\vert \\text{Disease})$ and\n",
    "$p(-\\vert \\text{No Disease})$ looked quite good:\n",
    "the former, the _sensitivity_ (or power) was around 70%\n",
    "and the latter, the _specificity_, was around 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+1\"> Disease </font> </th>\n",
    "      <th > <font size=\"+1\"> No Disease </font> </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td > <font size=\"+1\"> Test 2 + </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 0.7 </font> </td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.1 </font> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "      <td ><font size=\"+1\"> Test 2 - </font></td>\n",
    "      <td style=\"background-color: rgb(0,50,98); color: white\"> <font size=\"+2\"> 0.3 </font></td>\n",
    "      <td style=\"background-color: rgb(253,181,21);\"> <font size=\"+2\"> 0.9 </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When you hear someone say “90% of folks without the disease tested negative”,\n",
    "the immediate gut reaction is to infer “someone with a negative result probably doesn’t have the disease”\n",
    "and even \"someone with a positive result probably does have the disease.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But remember that we need to consider the chance that the person given the test had the disease in the first place:\n",
    "the _prior_ probability of the person having the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "I checked out the paper that was used to design Test 2:\n",
    "they noted that over 90% of individuals who tested positive on Test 1 turned out to, in fact, have the disease.\n",
    "This is the _positive predictive value_ of the test,\n",
    "and it is also the posterior probability that an individual has the disease,\n",
    "given that they got a positive result on that test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+2\"> Disease </font> </th>\n",
    "      <th > <font size=\"+2\"> No Disease </font> </th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(0,50,98); color: white\">\n",
    "        <td > <font size=\"+2\"> Test 1 + </font></td>\n",
    "      <td> <font size=\"+2\"> 0.9</font> </td>\n",
    "      <td> <font size=\"+2\"> 0.1 </font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(253,181,21);\">\n",
    "      <td><font size=\"+2\"> Test 1 - </font></td>\n",
    "      <td> <font size=\"+2\"> ? </font></td>\n",
    "      <td> <font size=\"+2\"> ? </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once someone has gotten a positive result on Test 1,\n",
    "that becomes our new prior probabilty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Combining that information with the likelihood table for Test 2,\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+2\"> Disease </font> </th>\n",
    "      <th > <font size=\"+2\"> No Disease </font> </th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(0,50,98); color: white\">\n",
    "        <td > <font size=\"+2\"> Test 2 + </font></td>\n",
    "      <td> <font size=\"+2\"> 0.98</font> </td>\n",
    "      <td> <font size=\"+2\"> 0.02 </font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(253,181,21);\">\n",
    "      <td><font size=\"+2\"> Test 2 - </font></td>\n",
    "      <td> <font size=\"+2\"> 0.75 </font></td>\n",
    "      <td> <font size=\"+2\"> 0.25 </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is our final posterior: what we think _after_ seeing the results of test 2 and test 1.\n",
    "\n",
    "Seeing a negative result on the second test does not have nearly the effect that one might expect: it changes 9:1 odds into 3:1 odds. A positive result similarly takes 9:1 odds to ~50:1 odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Think back to the example with waking up in your room to find it dark:\n",
    "the sensitivity of this test is high,\n",
    "since the room is likely to be dark if the sun has gone out,\n",
    "but that doesn't mean it's right to infer the sun has gone out just because your room is dark!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This example is covered in slightly more detail in\n",
    "[this blog post](https://charlesfrye.github.io/stats/2018/01/09/hypothesis-test-example.html).\n",
    "\n",
    "As a note:\n",
    "the second test was based on machine learning,\n",
    "while the first test was based on biology.\n",
    "If there's another take away from this,\n",
    "besides \"Be Bayesian About Evidence\",\n",
    "it's: \"Take Care Incorporating ML Into Your Decision-Making\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Last Bit: The Joint Probability Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The tables we considered were the _conditional probabilities_:\n",
    "\n",
    "if I assume that some condition is true,\n",
    "what will the other variables look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, we can consider what the chance is of observing any pair\n",
    "of outcomes, one for each variable,\n",
    "and so consider the _joint probability_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+2\"> $$H_0 \\text{ False}$$ </font></th>\n",
    "        <th > <font size=\"+2\"> $$H_0 \\text{ True}$$  </font></th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(255,255,255);\">\n",
    "        <td ><font size=\"+2\"> $$+$$ </font></td>\n",
    "      <td> <font size=\"+2\"> $$p(F, +)$$</font> </td>\n",
    "      <td> <font size=\"+2\"> $$p(T, +)$$</font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(255,255,255);\">\n",
    "         <td ><font size=\"+2\"> $$-$$</font></td>\n",
    "      <td> <font size=\"+2\"> $$p(F, -)$$ </font></td>\n",
    "      <td> <font size=\"+2\"> $$p(T, -)$$ </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These events have special names for the case of hypothesis testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table class=\"center\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th class=\"border-less\"></th>\n",
    "        <th > <font size=\"+2\"> $$H_0 \\text{ False}$$ </font></th>\n",
    "        <th > <font size=\"+2\"> $$H_0 \\text{ True}$$  </font></th>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: rgb(255,255,255);\">\n",
    "        <td ><font size=\"+2\"> $$+$$ </font></td>\n",
    "      <td> <font size=\"+2\"> True Positive </font> </td>\n",
    "      <td> <font size=\"+2\"> False Positive, Type I Error </font> </td>\n",
    "    </tr>\n",
    "     <tr style=\"background-color: rgb(255,255,255);\">\n",
    "         <td ><font size=\"+2\"> $$-$$</font></td>\n",
    "      <td> <font size=\"+2\"> False Negative, Type II Error </font></td>\n",
    "      <td> <font size=\"+2\"> True Negative </font> </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: these are not the names of the _probabilities_ but the names of the _events_.\n",
    "The previous tables had names for the probabilities.\n",
    "The names of the probabilites, the equivalents of \"power\" and \"positive predictive value\",\n",
    "would be \"_Chance of_ True Positive\", \"_Chance of_ Type I Error\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note: the names \"Type I Error\" and \"Type II Error\" should be\n",
    "[banished from language](https://en.wikipedia.org/wiki/Damnatio_memoriae)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Their literal etymology is as follows:\n",
    "while writing about errors that can occur during hypothesis testing,\n",
    "in 1933 Jerzy Neyman and Egon Pearson wrote\n",
    "\n",
    "> these errors will be of two kinds:\n",
    "<br>(I) we reject $H_0$ ... when it is true,\n",
    "<br>(II) we fail to reject $H_0$ when some alternative hypothesis $H_A$ or $H_1$ is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Sourced from [Wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Etymology),\n",
    "though the original quote is from their paper _The testing of statistical hypotheses in relation to probabilities a priori_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This labeling stuck, in part because the field of traditional statistics is so hide-bound\n",
    "and taught in a way that encourages practitioners to treat it as a series of magical incantations and fixed recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These labels are literally there just in order to separate out the two kinds of errors;\n",
    "there is no meaning to them.\n",
    "They could have written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> these errors will be of two kinds:\n",
    "<br>(😢) we reject $H_0$ ... when it is true,\n",
    "<br>(😡) we fail to reject $H_0$ when some alternative hypothesis $H_A$ or $H_1$ is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and we'd probably be talking about Type 😡 Errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{hypothesis}\\vert \\text{test result}) = \\frac{p(\\text{test result}\\vert \\text{hypothesis}) p(\\text{hypothesis})}{p(\\text{test result})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "go back to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{hypothesis}\\vert \\text{data}) = \\frac{p(\\text{data}\\vert \\text{hypothesis}) p(\\text{hypothesis})}{p(\\text{data})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "that is, use data more complicated than just a binary test result to determine our posterior beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Binary hypothesis testing, and its special case of null hypothesis significance testing,\n",
    "are a specific form of inferential thinking.\n",
    "\n",
    "NHST has, for the past century or so,\n",
    "been the dominant method for inferential thinking in science,\n",
    "for the essentially historical and technological reasons\n",
    "outlined last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With Bayesian inference, each hypothesis will be a concrete choice for the parameters of our model,\n",
    "and this will lead to a much simpler approach to understanding how to interpret our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Inference for Differences in Means: Guinness and Barley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Problem setup:\n",
    "William Gosset, alias \"Student\",\n",
    "is interested in determining which variety of barley produces a higher yield when planted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_A_yield = pd.Series([3, 1, 4, 5, 2])\n",
    "barley_B_yield = pd.Series([7, 5, 3, 4, 6])\n",
    "\n",
    "yields = pd.concat([barley_A_yield, barley_B_yield])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_df = pd.DataFrame({\"yield\": yields, \"variety\": [\"A\"] * 5 + [\"B\"] * 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since it's clear that sometimes Variety A produces more,\n",
    "while sometimes Variety B produces more,\n",
    "we have to frame the question in terms of some statistic or parameter.\n",
    "\n",
    "The typical choice is the _mean_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For our first model, let's use some ideas from the $t$-test:\n",
    "\n",
    "1. Both groups are normally-distributed\n",
    "2. The two groups have the same standard deviation\n",
    "\n",
    "The first statement means our likelihood will be `Normal`.\n",
    "\n",
    "The `Normal` has two parameters, `mu` and `sd`.\n",
    "The second statement means that `sd` is shared between the groups.\n",
    "\n",
    "And so our model has three latent, or hidden, variables:\n",
    "the variance parameter of the likelihood\n",
    "and the two mean parameters of the likelihood,\n",
    "one for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Means: `pm.Normal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most objective way to set this prior\n",
    "would be to look at past data about barley yields,\n",
    "allowing us to get a sense for what's likely\n",
    "for these novel barley varieties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But that's usually not possible:\n",
    "we're often working with new data,\n",
    "for which there isn't a large database.\n",
    "The closest thing we have is\n",
    "the data we have collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_A_yield.mean(), barley_B_yield.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.std([barley_A_yield.mean(), barley_B_yield.mean()], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It's somewhat cheating to use your data in setting your prior.\n",
    "\n",
    "To remedy this somewhat,\n",
    "we will just increase the standard deviation by a factor of about 2.\n",
    "\n",
    "This reduces the impact of our prior on our posterior\n",
    "by spreading out the distribution.\n",
    "More widely-spread priors have less impact on posteriors,\n",
    "as you saw in the lab on parameterized models.\n",
    "\n",
    "If you're concerned about \"double-dipping\", you can always just increase the standard deviation further.\n",
    "\n",
    "We'll see below that this choice of parameters has a fairly modest impact on inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as barley_model:\n",
    "    # priors on parameters\n",
    "    means = pm.Normal(\"means\", mu=4, sd=3, shape=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Standard Deviation: `pm.Exponential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Originally introduced back in the second lecture on random variables as \"time in between events in a memoryless process\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A _memoryless process_ is one where events have no influence on each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples: raindrops, Amazon orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Counterexamples: [buses](http://jakevdp.github.io/blog/2018/09/13/waiting-time-paradox/), parliamentary elections, bedtimes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `Exponential` is also a common choice whenever we want to express the belief\n",
    "\n",
    "#### This variable is positive, and larger values get less likely fairly quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with barley_model:\n",
    "    # priors on parameters\n",
    "    pooled_sd = pm.Exponential(r\"$\\sigma$\", lam=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It has one parameter, `lam` or $\\lambda$, which is 1 / mean, or the 1 / average time between events,\n",
    "aka the average rate at which events occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this model, we are saying that the standard deviation is positive,\n",
    "and that very large values of the standard deviation are very unlikely:\n",
    "we don't expect that a variety will sometimes produce 1, other times 100, bushels\n",
    "with very high probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Look up `pm.HalfNormal`, `pm.HalfStudentT`, and `pm.Lognormal` for two more distributions\n",
    "that express a similar belief.\n",
    "They are also positive-only:\n",
    "the first two are \"positive-only\" versions of the `Normal` and the `StudentT` distribution.\n",
    "\n",
    "The `HalfNormal` most strongly discounts large values,\n",
    "while the `HalfStudentT` is somewhere in between `HalfNormal` and `Exponential`,\n",
    "depending on its parameter.\n",
    "\n",
    "The distribution `pm.Lognormal` says that we can guess the order of magnitude\n",
    "of the variable, plus or minus some spread.\n",
    "This can be a very weak prior if the spread is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finishing the Model with a Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with barley_model:\n",
    "    # likelihood to relate parameters to data\n",
    "    varieties = pd.Series(barley_df[\"variety\"] == \"B\", dtype=int)\n",
    "    yields = pm.Normal(\"yields\", mu=means[varieties], sd=pooled_sd,\n",
    "                       observed=barley_df[\"yield\"])\n",
    "    delta_means = pm.Deterministic(\"$\\mu_1 - \\mu_0$\", means[1] - means[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now, let's take a look at our prior by sampling with `sample_prior_predictive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_prior_samples = shared_util.samples_to_dataframe(pm.sample_prior_predictive(\n",
    "    model=barley_model, samples=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "shared_scales = True\n",
    "f, axs = plt.subplots(nrows=3, figsize=(12, 12), sharex=shared_scales, sharey=shared_scales)\n",
    "sns.distplot(barley_model_prior_samples[r\"$\\sigma$\"], ax=axs[0]);\n",
    "sns.distplot(barley_model_prior_samples[\"means\"].apply(lambda xs: xs[0]), ax=axs[1], axlabel=r\"$\\mu_0$\");\n",
    "sns.distplot(barley_model_prior_samples[\"$\\mu_1 - \\mu_0$\"], ax=axs[2]);\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that we didn't _explicitly_ specify a prior on the latter:\n",
    "our prior on the value of \"$\\mu_1 - \\mu_0$\" is a consequence of our other priors.\n",
    "\n",
    "This is something like the sampling distribution of the \"difference in means\"\n",
    "statistic under the prior.\n",
    "\n",
    "If we observe a value of this variable that is very unlikely under our prior distribution,\n",
    "that suggests our prior might be wrong,\n",
    "just as observing a value of a statistic that is very unlikely under\n",
    "the sampling distribution of the null hypothesis (a low $p$ value)\n",
    "suggests that the null hypothesis might be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And then look at the posterior given the data with `sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_trace = shared_util.sample_from(barley_model)\n",
    "barley_model_samples = shared_util.samples_to_dataframe(barley_model_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(barley_model_samples[\"$\\sigma$\"], color=\"C2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, the posterior for the standard deviation.\n",
    "\n",
    "It's somewhat hard to interpret without comparing to the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(barley_model_prior_samples[\"$\\sigma$\"], color=\"C0\", label=\"prior\");\n",
    "sns.distplot(barley_model_samples[\"$\\sigma$\"], color=\"C2\", label=\"posterior\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our posterior is much tighter than our prior:\n",
    "where before, we thought there was about a 50% chance\n",
    "that the standard deviation was below 1 or above 4,\n",
    "we now put a vanishly small chance on that being true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(barley_model_prior_samples[\"$\\sigma$\"] < 1).mean() + (barley_model_prior_samples[\"$\\sigma$\"] > 4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(barley_model_samples[\"$\\sigma$\"] < 1).mean() + (barley_model_samples[\"$\\sigma$\"] > 4).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: determining something like this while running a $t$-test would have required\n",
    "the elaboration of _another_ statistical test,\n",
    "likely with additional assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But we were more interested in the difference of means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.distplot(barley_model_prior_samples[\"$\\mu_1 - \\mu_0$\"], color=\"C0\", label=\"prior\");\n",
    "sns.distplot(barley_model_samples[\"$\\mu_1 - \\mu_0$\"], color=\"C2\", label=\"posterior\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Again,\n",
    "even though we only observed a relatively small amount of data,\n",
    "it's enough to massively change our prior,\n",
    "since it reflected our state of very extreme ignorance.\n",
    "\n",
    "If we'd like to infer whether the\n",
    "mean of Variety B is higher,\n",
    "we just need to check what the probability\n",
    "of that claim is, under the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(barley_model_samples[\"$\\mu_1 - \\mu_0$\"] > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that the resulting value is dramatically different from\n",
    "what we had in the prior:\n",
    "about 50-50 odds.\n",
    "\n",
    "This experiment was very informative,\n",
    "even if it wasn't definitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "(barley_model_prior_samples[\"$\\mu_1 - \\mu_0$\"] > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice what is being done here,\n",
    "along with what was being done above:\n",
    "we are checking whether the inference we wanted to draw\n",
    "was true on each sample,\n",
    "and then calculating the fraction of samples on which it was true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can be generalized to all kinds of different inferences,\n",
    "without any need to do more than change what we calculate on our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_posterior_p(posterior_samples, check_inference):\n",
    "    inference_true_booleans = []\n",
    "    for _, sample in posterior_samples.iterrows():\n",
    "        inference_true_booleans.append(check_inference(sample))\n",
    "    return pd.Series(inference_true_booleans).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# the inference we were interested in\n",
    "def mu1_greater(sample):\n",
    "    return sample[\"$\\mu_1 - \\mu_0$\"] > 0\n",
    "\n",
    "# what's the chance that these varieties have a low value of sigma\n",
    "def sigma_under_3(sample):  \n",
    "    return sample[\"$\\sigma$\"] < 3\n",
    "\n",
    "# a wacky inference, but one we can ask\n",
    "def mu0_less_than_sigma(sample):  # \n",
    "    return sample[\"$\\sigma$\"] > sample[\"means\"][0]\n",
    "\n",
    "print(compute_posterior_p(barley_model_samples, mu1_greater),\n",
    "      compute_posterior_p(barley_model_samples, sigma_under_3),\n",
    "      compute_posterior_p(barley_model_samples, mu0_less_than_sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Credible Intervals: Confidence Intervals for Bayesians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Confidence Interval was intended to give an estimate of what values of a variable were plausible or likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But remember, that's not what a Confidence Interval really is:\n",
    "it is merely an interval that,\n",
    "on 95% of samples, covers the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Credible Intervals are the Bayesian equivalent of Confidence Intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A **Bayesian Credible Interval** is _any_ interval that covers 95% of the posterior density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Highest Posterior Density Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The _Highest Posterior Density Interval_ is the shortest credible interval.\n",
    "\n",
    "It is computed with `pm.stats.hpd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.stats.hpd(barley_model_samples[\"$\\mu_1 - \\mu_0$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `plot_posterior`\n",
    "\n",
    "Given the output of `pm.sample` or `shared_util.sample_from`\n",
    "(not a `DataFrame`, aka the output of `shared_util.samples_to_dataframe`),\n",
    "pyMC can make a convenient plot of the posterior and the Highest Posterior Density Interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(barley_model_trace, varnames=[\"$\\mu_1 - \\mu_0$\"], figsize=(12, 6), text_size=24,\n",
    "                  color=\"C2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is a histogram, just like in `sns.distplot`.\n",
    "\n",
    "The black bar covers, by default, the 95% HPD.\n",
    "The endpoints are indicated by hovering text,\n",
    "as is the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Quantiles: Equal Tail Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The _Equal Tail Interval_ is the credible interval with equal total probability\n",
    "above it and below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.stats.quantiles(barley_model_samples[\"$\\mu_1 - \\mu_0$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that the Equal Tail Interval covering 95% of the posterior\n",
    "is not the same as the Highest Posterior Density Interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(barley_model_samples[\"$\\mu_1 - \\mu_0$\"], width=0.2, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We display quantile information using a _box plot_,\n",
    "aka a _box-and-whisker plot_\n",
    "accessible with `sns.boxplot`.\n",
    "\n",
    "The middle half of the data is indicated with the box:\n",
    "its left edge is at the 25th percentile\n",
    "and its right edge is at the 75th percentile.\n",
    "The width of this box is called the \"interquartile range\".\n",
    "The median is indicated with a bar through the box.\n",
    "\n",
    "The \"whiskers\" extend to cover all data points up to a maximum length equal to some number\n",
    "times the width of the box in the middle.\n",
    "The keyword argument in seaborn is `whis` and the default value is `1.5`,\n",
    "which is standard.\n",
    "\n",
    "Any points outside of this range are plotted individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comparing the Prior and Posterior with `boxplot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The cell below combines the samples from the posterior with the samples from the prior into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "posterior_prior_comparison_df = pd.concat([barley_model_samples, barley_model_prior_samples])\n",
    "\n",
    "posterior_prior_comparison_df[\"distribution\"] = \\\n",
    "    [\"posterior\"] * len(barley_model_samples) + [\"prior\"] * len(barley_model_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "posterior_prior_comparison_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Side note: you might notice a column $\\sigma$`_log__`. Internally, pyMC works with logarithms for positive-only variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The additional `distribution` column identifies where a given sample was from the `prior` or the `posterior`.\n",
    "\n",
    "We can use this column for `groupby` operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "posterior_prior_comparison_df.groupby(\"distribution\")[\"$\\sigma$\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And for hooking into seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Many seaborn plotting functions, including `boxplot`,\n",
    "can use columns of the dataframe to split up the data and automatically produce\n",
    "the same visualization for multiple subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.boxplot(x=\"$\\mu_1 - \\mu_0$\", data=posterior_prior_comparison_df,\n",
    "            y=\"distribution\", hue=\"distribution\",\n",
    "            palette=[\"C2\", \"C0\"], linewidth=4);\n",
    "ax.legend([], frameon=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For `boxplot` the `y` argument determines which variable sets the height of the boxes,\n",
    "while the `hue` argument determines which variable sets their color.\n",
    "\n",
    "If you use learn to use these features of seaborn,\n",
    "you can make very rich and informative plots in just a few lines!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Model with Weaker Priors: `agnostic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sometimes, we want to bring even less prior information to bear on our modeling problem.\n",
    "\n",
    "Our previous model very strongly discounted the possibility that the mean number of bushels\n",
    "would be in the hundreds or the hundreds of thousands.\n",
    "\n",
    "But perhaps that was too strong of an assumption?\n",
    "\n",
    "There are several \"go-to\" choices of prior that are common when trying to make as few assumptions as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pm.HalfCauchy` and `pm.Cauchy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These two distributions have very \"long tails\":\n",
    "the chance of producing a value very far away from their center is relatively small,\n",
    "but substantially higher than for the `Exponential` or `Normal` distributions.\n",
    "\n",
    "They are used when we want to say that even extremely large values aren't too unsurprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The `HalfCauchy`, like the `HalfNormal`, the `HalfStudentT`, and the `HalfFlat`,\n",
    "is the positive-only version of the `Cauchy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These distributions are so broad that sampling from them is difficult,\n",
    "so instead of showing what they look like by drawing samples,\n",
    "the code below plots their distribution functions directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano.tensor as tt\n",
    "\n",
    "def make_probability(distribution, **params):\n",
    "    \"\"\"Constructs a function that evaluates the exponential of\n",
    "    distribution's logp function for a given set of parameters,\n",
    "    provided as kwargs.\n",
    "    \n",
    "    For continuous distributions, this is a probability density.\n",
    "    For discrete distributions, this is a probability mass.\n",
    "    \"\"\"\n",
    "    logp = distribution.dist(**params).logp\n",
    "    \n",
    "    def probability(vals):\n",
    "        return np.exp(logp(shared_util.to_pymc(vals)).eval())\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "half_cauchy_probability = make_probability(pm.HalfCauchy, beta=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "exponential_probability = make_probability(pm.Exponential, lam=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sigmas = np.logspace(-5, 5, num=1000)\n",
    "half_cauchy_ps = half_cauchy_probability(sigmas)\n",
    "exponential_ps = exponential_probability(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(sigmas, exponential_ps, lw=4); plt.xlim([100, 1000]);\n",
    "\n",
    "plt.plot(sigmas, half_cauchy_ps, lw=4); plt.xlim([100, 1000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As you can see, the `HalfCauchy` is just so slightly above the `Exponential`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This difference is much easier to see if we log-transform the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.semilogy(sigmas, exponential_ps, lw=4); plt.xlim([0, 100000]);\n",
    "\n",
    "plt.semilogy(sigmas, half_cauchy_ps, lw=4); plt.xlim([0, 100000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The probabilities are exponentially decreasing for the `Exponential` distribution,\n",
    "as indicated by the fact that the log probabilities are decreasing in a straight line.\n",
    "\n",
    "The probabilities are decreasing much more slowly than exponentially for the `Cauchy` distribution:\n",
    "even though they are small, they are not dropping nearly as low as for the `Exponential`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The difference is much easier to see\n",
    "if we just look at a `rugplot` of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as barley_model_agnostic:\n",
    "    pooled_sd = pm.HalfCauchy(r\"$\\sigma$\", beta=10)\n",
    "    means = pm.Cauchy(\"means\",\n",
    "                      alpha=4,  # center\n",
    "                      beta=1,  # spread\n",
    "                      shape=2)\n",
    "    \n",
    "    varieties = pd.Series(barley_df[\"variety\"] == \"B\", dtype=int)\n",
    "    yields = pm.Normal(\"yields\", mu=means[varieties], sd=pooled_sd,\n",
    "                       observed=barley_df[\"yield\"])\n",
    "    delta_means = pm.Deterministic(\"$\\mu_1 - \\mu_0$\", means[1] - means[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_agnostic_prior_samples = shared_util.samples_to_dataframe(pm.sample_prior_predictive(\n",
    "    model=barley_model_agnostic, samples=5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "shared_scales = True\n",
    "f, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12), sharex=shared_scales, sharey=shared_scales)\n",
    "\n",
    "sns.distplot(barley_model_prior_samples[r\"$\\sigma$\"],\n",
    "             ax=axs[0, 0], rug=True);\n",
    "sns.distplot(barley_model_prior_samples[\"means\"].apply(lambda xs: xs[0]),\n",
    "             ax=axs[1, 0], rug=True, axlabel=r\"$\\mu_0$\");\n",
    "sns.distplot(barley_model_prior_samples[\"$\\mu_1 - \\mu_0$\"],\n",
    "             ax=axs[2, 0], rug=True);\n",
    "\n",
    "sns.distplot(barley_model_agnostic_prior_samples[r\"$\\sigma$\"],\n",
    "             ax=axs[0, 1], kde=False, rug=True, norm_hist=True, bins=1000, color=\"C1\");\n",
    "sns.distplot(barley_model_agnostic_prior_samples[\"means\"].apply(lambda xs: xs[0]),\n",
    "             ax=axs[1, 1], kde=False, rug=True, norm_hist=True, bins=1000, color=\"C1\", axlabel=r\"$\\mu_0$\");\n",
    "sns.distplot(barley_model_agnostic_prior_samples[\"$\\mu_1 - \\mu_0$\"],\n",
    "             ax=axs[2, 1], kde=False, rug=True, norm_hist=True, bins=1000, color=\"C1\");\n",
    "axs[0, 0].set_title(\"Model A:\\nExponential-Normal Prior\")\n",
    "axs[0, 1].set_title(\"Model B:\\nHalfCauchy-Cauchy Prior\")\n",
    "axs[-1, -1].set_xlim([-100, 100]); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While the draws from the original model are fairly tightly concentrated around the regions around 0,\n",
    "the draws from the agnostic model, with the `HalfCauchy` and `Cauchy` prior,\n",
    "are much more broadly distributed.\n",
    "\n",
    "Intuitively, this model is much less opinionated than the other about the data.\n",
    "\n",
    "Of course, the chance of a variety of barley having a yield\n",
    "that is an order or of magnitude or more higher than all the others is quite small,\n",
    "and so the `Exponential`-`Normal` model is very reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "shared_scales = True\n",
    "f, axs = plt.subplots(nrows=3, figsize=(12, 12), sharex=shared_scales, sharey=shared_scales)\n",
    "\n",
    "sns.distplot(barley_model_agnostic_prior_samples[r\"$\\sigma$\"],\n",
    "             ax=axs[0], kde=False, norm_hist=True, bins=1000, color=\"C1\");\n",
    "sns.distplot(barley_model_agnostic_prior_samples[\"means\"].apply(lambda xs: xs[0]),\n",
    "             ax=axs[1], kde=False, norm_hist=True, bins=1000, color=\"C1\", axlabel=r\"$\\mu_0$\");\n",
    "sns.distplot(barley_model_agnostic_prior_samples[\"$\\mu_1 - \\mu_0$\"],\n",
    "             ax=axs[2], kde=False, norm_hist=True, bins=1000, color=\"C1\");\n",
    "axs[-1].set_xlim([-100, 100]); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This kernel density estimates don't quite do these distributions justice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Once again, we draw some samples,\n",
    "package them into a dataframe, and visualize the posterior\n",
    "with a box-and-whisker plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_agnostic_trace = shared_util.sample_from(barley_model_agnostic)\n",
    "barley_model_agnostic_samples = shared_util.samples_to_dataframe(barley_model_agnostic_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "agnostic_posterior_prior_comparison_df = pd.concat(\n",
    "    [barley_model_agnostic_samples, barley_model_agnostic_prior_samples])\n",
    "\n",
    "agnostic_posterior_prior_comparison_df[\"distribution\"] = \\\n",
    "    [\"posterior\"] * len(barley_model_agnostic_samples) + [\"prior\"] * len(barley_model_agnostic_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "agnostic_posterior_prior_comparison_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.boxplot(x=\"$\\mu_1 - \\mu_0$\", y=\"distribution\", data=agnostic_posterior_prior_comparison_df, hue=\"distribution\",\n",
    "            palette=[\"C2\", \"C0\"], linewidth=4);\n",
    "ax.legend([], frameon=False);\n",
    "ax.set_xlim([-20, 20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If combine the samples from both of our models into a single dataframe,\n",
    "including samples from the prior and the posterior for both,\n",
    "we can plot the original and updated beliefs for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_comparison_df = pd.concat([posterior_prior_comparison_df, agnostic_posterior_prior_comparison_df])\n",
    "model_comparison_df[\"model\"] = \\\n",
    "    [\"original\"] * len(posterior_prior_comparison_df) + [\"agnostic\"] * len(agnostic_posterior_prior_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_comparison_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.boxplot(x=\"$\\mu_1 - \\mu_0$\", y=\"model\", data=model_comparison_df, hue=\"distribution\",\n",
    "            palette=[\"C2\", \"C0\"], linewidth=4);\n",
    "ax.set_xlim([-20, 20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This plot separates out the original and the agnostic model on the y-axis\n",
    "and then uses color to indicate which distribution hte samples are drawn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Directly from this plot,\n",
    "we can see that though the centers of the two priors are similar,\n",
    "the prior of the agnostic model is much more widely distributed.\n",
    "\n",
    "We can also see that the difference in posteriors is much smaller.\n",
    "At least on the scale of the priors,\n",
    "the centers are fairly close,\n",
    "and the widths are about the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Model with the Weakest Priors: `improper`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we wanted to make no assumption about what values of the standard deviation or the mean were more or less likely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `pm.Flat` and `pm.HalfFlat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "pyMC provides access to two distributions that aren't really probability distributions at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "flat_probability = make_probability(pm.Flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "half_flat_probability = make_probability(pm.HalfFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.arange(-10, 10)\n",
    "plt.step(xs, half_flat_probability(xs), lw=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.arange(-10, 10)\n",
    "plt.step(xs, flat_probability(xs), lw=4);\n",
    "plt.ylim([0, 1.1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Because the values are the same everywhere,\n",
    "except where they are 0,\n",
    "in the case of `HalfFlat`,\n",
    "they have no effect on the posterior\n",
    "except to say that some values are impossible.\n",
    "\n",
    "Because they aren't probability distributions,\n",
    "as they don't add up to 1, they can't be sampled from\n",
    "with `sample_prior_predictive`.\n",
    "\n",
    "But they still result in a valid posterior,\n",
    "so we draw samples with `pm.sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as barley_model_improper:\n",
    "    pooled_sd = pm.HalfFlat(r\"$\\sigma$\")\n",
    "    means = pm.Flat(\"means\", shape=2)\n",
    "    \n",
    "    varieties = pd.Series(barley_df[\"variety\"] == \"B\", dtype=int)\n",
    "    yields = pm.Normal(\"yields\", mu=means[varieties], sd=pooled_sd,\n",
    "                       observed=barley_df[\"yield\"])\n",
    "    delta_means = pm.Deterministic(\"$\\mu_1 - \\mu_0$\", means[1] - means[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_improper_trace = shared_util.sample_from(barley_model_improper)\n",
    "barley_model_improper_samples = shared_util.samples_to_dataframe(barley_model_improper_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "barley_model_improper_samples[\"model\"] = \"improper\"\n",
    "barley_model_improper_samples[\"distribution\"] = \"posterior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_comparison_df = model_comparison_df.append(barley_model_improper_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.boxplot(x=\"$\\mu_1 - \\mu_0$\", y=\"model\", data=model_comparison_df, hue=\"distribution\",\n",
    "            palette=[\"C2\", \"C0\"], linewidth=4);\n",
    "ax.set_xlim([-20, 20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## What would you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "My opinion: the evidence is somewhat ambiguous.\n",
    "If this is a low-downside decision,\n",
    "plant Variety 1 and then reassess after the next harvest.\n",
    "\n",
    "If this is a high-downside decision,\n",
    "either repeat the experiment,\n",
    "using some combination of these posteriors as a prior,\n",
    "or maybe plant some of each!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
