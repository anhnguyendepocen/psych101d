{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Bayesian Inference 03 - Flexibility of Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util\n",
    "\n",
    "import utils.daft\n",
    "import utils.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def arrays_to_scalars(MAP):\n",
    "    for key, value in MAP.items():\n",
    "        if isinstance(value, np.ndarray) and value.shape is ():\n",
    "            MAP[key] = np.asscalar(value)\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Once You've Learned to Specify Models, Inference Becomes Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the traditional approach,\n",
    "each change to the model requires a new statistical test\n",
    "or the verification/extension of an old one.\n",
    "\n",
    "In the Bayesian Monte Carlo approach,\n",
    "each change to a model either requires just changing what we do with our samples\n",
    "or changing our model specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Within the context of our difference-in-means problem,\n",
    "that means that all of the questions below\n",
    "become difficult to answer,\n",
    "essentially requiring a trip back to the blackboard or Wikipedia.\n",
    "\n",
    "Can I use the standard $t$-test if..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my standard deviations are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, the test will still perform well, but only if the groups have roughly the same number of observations.\n",
    "Otherwise, you must use [Welch's modified $t$ test](https://en.wikipedia.org/wiki/Welch%27s_t-test),\n",
    "aka `scipy.stats.ttest_ind` with argument `equal_var=False`.\n",
    "\n",
    "Note: what does it mean for a test to \"perform well\"? The first-order answer is that the distribution of $p$ stays uniform, meaning that applying a threshold of $\\alpha$ to $p$ gives a false positive rate equal to $\\alpha$. The harder question is what happens to the power. The answers to all of these questions are in terms of the false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...the groups have different sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, but only if the groups have roughly the same standard deviation. See above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my likelihood changes from `Normal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, [so long as your sample size is large enough](https://thestatsgeek.com/2013/09/28/the-t-test-and-robustness-to-non-normality/). How large is large enough? That's another hard question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- ...I care about differences in medians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes, if the likelihood is symmetric, because the mean is then the same as the median.\n",
    "If the mean and median are different,\n",
    "which is likely why you're interested in the median rather than the mean, then you need a new test,\n",
    "the [Mann-Whitney $U$ test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Comparison_to_Student's_t-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And all of that is while still assuming we are working with comparing the \"center value\" of just two groups in terms of a single measurement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## All of these questions have simple answers in the Bayesian approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do I do if..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my standard deviations are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model! Just make sure there's a different standard deviation variable for each group,\n",
    "as in some of the examples from the other set of slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...the groups have different sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model!\n",
    "pyMC will automatically handle combining information across groups,\n",
    "of varying sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my likelihood changes from `Normal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Include that in your model! Just switch the likelihood component and possibly redefine some of the hidden parameter variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...I care about differences in medians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model! Add a `pm.Deterministic` for calculating that value, or just calculate it afterwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The secret is putting modeling first and statistics second "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All of these questions are about how the model behaves when its assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When you just call a function like `scipy.stats.ttest_ind`,\n",
    "it's unclear what model is being used, what its assumptions are,\n",
    "and how to change that model when those assumptions are violated.\n",
    "\n",
    "It is no different, fundamentally, from looking up the values in a table.\n",
    "How the values inside would change if the assumptions used to generate it were different\n",
    "is not something that a table can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When you write out a pyMC model, all of the assumptions are right there, in the program you have written,\n",
    "and can be changed on the fly, as can the statistic you calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you want to see what happens when the model is wrong,\n",
    "you can simulate data from the alternate model and see how your model behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This flexibility pays major dividends when specifying models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than sticking only to the \"off-the-shelf\" models we've carefully studied and reviewed in a statistics course,\n",
    "we can build them from scratch to answer the exact question we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Donald Trump and Hip-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Throughout the 90s,\n",
    "Donald Trump's name appeared repeatedly in hip-hop lyrics,\n",
    "especially those by East Coast rappers,\n",
    "where his name was synonymous with wealth and status.\n",
    "\n",
    "Trump's rise to the presidency has changed how many people feel about him.\n",
    "Can we quantify when and to what degree this occurred in hip-hop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Data collection by [fivethirtyeight](https://fivethirtyeight.com),\n",
    "downloaded from\n",
    "[kaggle](https://www.kaggle.com/fivethirtyeight/fivethirtyeight-hip-hop-candidate-lyrics-dataset),\n",
    "see [this fivethirtyeight post](https://projects.fivethirtyeight.com/clinton-trump-hip-hop-lyrics/)\n",
    "for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: the model used here is inspired by two examples in _Bayesian Methods for Hackers_:\n",
    "1. The \"texting switchpoint\" example, from [Chapter 1](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb).\n",
    "2. The \"Challenger O-Ring\" example, from [Chapter 2](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = Path(\".\") / \"data\"\n",
    "\n",
    "trump_data = pd.read_csv(data_folder / \"trump_hiphop_sentiment_data.csv\", index_col=0)\n",
    "\n",
    "print(trump_data.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's eliminate the \"neutral\" category\n",
    "and treat sentiment as binary: `\"positive\"` (`1`) or `\"negative\"` (`0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_to_posneg(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0\n",
    "    elif sentiment == \"positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "trump_data[\"positive\"] = trump_data[\"sentiment\"].apply(sentiment_to_posneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "utils.plot.plot_raw_data_sentiment(trump_data, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Darker circles mean more lyrics with that sentiment were observed in that year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Switchpoint Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For each observation (pair of year and sentiment), there is some unknown chance $p$ that it was positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One reasonable model for this data is that the chance $p$ switched, one year,\n",
    "from being high to low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So our model will have three latent, or hidden, variables\n",
    "that give rise to the unknown variable $p$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Chance of positive sentiment before switch, `p_1` / $p_1$\n",
    "- Chance of positive sentiment after swith, `p_2` / $p_2$\n",
    "- Time that switch occurred, `switchpoint` / $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting model looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_switchpoint_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What are some reasonable priors for these variables?\n",
    "\n",
    "- $p_1$/$p_2$: unknown number between 0 and 1.\n",
    "- $s$: unknown integer between 1989 and 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we want to express no strong prior beliefs,\n",
    "we might say `Uniform` for the $p_i$ and\n",
    "`DiscreteUniform` for $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is our likelihood?\n",
    "- obs: whether sentiment in a lyric was positive or negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It's a binary variable, so it's a `Bernoulli` likelihood,\n",
    "with $p$ set by `pm.math.switch`ing between $p_1$ and $p_2$ depending on the date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What would we like to infer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For one, the parameter $s$, which determines when the change happened.\n",
    "If this value has a wide posterior, then\n",
    "the change was perhaps gradual or small.\n",
    "\n",
    "For another,\n",
    "the difference between $p_2$ and $p_1$,\n",
    "which captures whether the change was positive or negative and to what degree.\n",
    "If $p_2 - p_1$ is small in magnitude, or has equal chance of being positive or negative,\n",
    "then the change was minimal or nonexistent.\n",
    "\n",
    "Lastly, we might be interested in the relationships between our parameters and fixed quantities:\n",
    "what is the chance that the final value of sentiment is below 50% positive?\n",
    "what is the chance that the switch happened after 2012?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trump_data_sub = trump_data.dropna()  # remove all the na values before passing to pyMC\n",
    "dates = trump_data_sub[\"album_release_date\"]\n",
    "positive = trump_data_sub[\"positive\"]\n",
    "\n",
    "with pm.Model() as sentiment_switch_model:\n",
    "    p1 = pm.Uniform(\"$p_1$\", lower=0, upper=1)  # prior\n",
    "    p2 = pm.Uniform(\"$p_2$\", lower=0, upper=1)  # prior\n",
    "    switchpoint = pm.DiscreteUniform(        # prior\n",
    "        \"switchpoint\", lower=min(dates), upper=max(dates))  \n",
    "    \n",
    "    p = pm.math.switch(shared_util.to_pymc(dates) >= switchpoint, p2, p1)\n",
    "    \n",
    "    # likelihood\n",
    "    positive_sentiment = pm.Bernoulli(\"positive_sentiment\", p, observed=positive)\n",
    "    \n",
    "    # statistic / observation of interest\n",
    "    change_in_sentiment = pm.Deterministic(\"$p_2 - p_1$\", var=p2 - p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with sentiment_switch_model:\n",
    "    sentiment_trace = pm.sample(draws=2500, target_accept=0.9, chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Above, draw samples and save them as a trace, then put them into a dataframe, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "switchpoint_samples = shared_util.samples_to_dataframe(sentiment_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=3, sharex=True)\n",
    "sns.distplot(switchpoint_samples[\"$p_1$\"], ax=axs[0], color=\"C2\");\n",
    "sns.distplot(switchpoint_samples[\"$p_2$\"], ax=axs[1], color=\"C2\");\n",
    "sns.distplot(switchpoint_samples[\"$p_2 - p_1$\"], ax=axs[2], color=\"C2\");\n",
    "axs[-1].set_xlim([-1, 1]); axs[0].set_title(\"Posteriors for Switchpoint Model\"); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Looking at the posterior, it seems that sentiment most likely _dropped_ between before and after the switchpoint,\n",
    "from about 90% positive to about 30% positive.\n",
    "\n",
    "The total drop was about 60%, but could be as low as 30% or as high as 70%.\n",
    "Most of the uncertainty comes from the value after the switchpoint:\n",
    "the posterior for $p_2$ is much wider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our posterior for the time of the switch is very tight: it almost certainly happened in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.distplot(switchpoint_samples[\"switchpoint\"], kde=False, norm_hist=True, bins=range(1989, 2019),\n",
    "             color=\"C2\");\n",
    "ax.set_title(\"Posterior for Switchpoint Model\"); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For simplicity, could use `plot_posterior` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(sentiment_trace, figsize=(12, 12),\n",
    "                  varnames=[\"$p_1$\", \"$p_2$\", \"switchpoint\",  \"$p_2 - p_1$\"],\n",
    "                  text_size=24, color=\"C2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But don't be afraid to make a special visualization for your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The generic `plot_posterior` visualization is good,\n",
    "but you can usually do better if you make your own\n",
    "plot that directly visualizes data and uncertainty estimates together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "utils.plot.plot_raw_data_sentiment(trump_data_sub, ax)\n",
    "\n",
    "# plot median value for each prediction\n",
    "utils.plot.plot_switchpoint(switchpoint_samples[\"$p_1$\"].median(),\n",
    "                 switchpoint_samples[\"$p_2$\"].median(),\n",
    "                 switchpoint_samples[\"switchpoint\"].median(),\n",
    "                 range(1989, 2019), ax, lw=4, color=\"C0\", zorder=4);\n",
    "\n",
    "# plot each sample\n",
    "for _, sample in switchpoint_samples.sample(frac=0.05).iterrows():\n",
    "    utils.plot.plot_switchpoint(sample[\"$p_1$\"], sample[\"$p_2$\"], sample[\"switchpoint\"],\n",
    "                                range(1989, 2019), ax, alpha=0.05, color=\"C1\");\n",
    "    \n",
    "ax.legend(\n",
    "[matplotlib.lines.Line2D([], [], color=\"C1\"),\n",
    " matplotlib.lines.Line2D([], [], color=\"C0\", lw=4)],\n",
    "[\"Sampled Predictions\", \"Median Prediction\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The median of each parameter is used to select a single model to plot, labeled the \"Median Prediction\".\n",
    "\n",
    "The predictions of many samples from the posterior are plotted transparently over the median prediction.\n",
    "Where the color is darker, more samples were making approximately the same prediction,\n",
    "whereas where it is lighter, fewer samples were making that prediction.\n",
    "\n",
    "The median and the mean across samples are not always good choices for single parameters,\n",
    "but here they seem to fall in a region of high probability under the posterior:\n",
    "a place where the color is dark in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Rather than just viewing the posteriors of the parameters,\n",
    "it's good to compare the predictions directly to the data,\n",
    "in some way that makes visually apparent where there's high and low uncertainty.\n",
    "\n",
    "The fact that all of the samples change heights in 2015 indicates\n",
    "that there's essentially no uncertainty in the switchpoint,\n",
    "while the fact that the samples are very spread out afterwards\n",
    "indicates that there's a good deal of uncertainty in the value after the switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can also directly compute posterior probabilities from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(switchpoint_samples[\"$p_2$\"] < 0.5).mean()  # posterior belief that p_2 is below half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can check the posterior probability of anything we can express as a boolean function of a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# posterior belief that positive sentiment dropped by a larger amount than remained afterwards\n",
    "(np.abs(switchpoint_samples[\"$p_2 - p_1$\"]) > switchpoint_samples[\"$p_2$\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What about when you absolutely must produce a point estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most natural way to talk about unknown quantities in Bayesian inference is with distributions:\n",
    "for each possible value of the unknown quantity,\n",
    "I give a probability.\n",
    "\n",
    "More broadly, for a given inference, I state the probability that it is true under my posterior,\n",
    "as computed in the section immediately above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second most natural way to talk about unknowns is with _intervals_,\n",
    "as in the highest posterior density interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This preserves some sense of uncertainty, but it easier to work with than a full distribution:\n",
    "it's only two numbers, instead of a number for each outcome or a function or a bag of samples.\n",
    "\n",
    "This is what we do when we use `plot_posterior`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is very unnatural, in Bayesian inference, to talk about unknown values with a single \"best guess\". A single \"best guess\" of an unknown quantity is called a _point estimate_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, it is sometimes necessary to give a point estimate:\n",
    "someone has a proverbial \"gun to your head\" and is demanding it.\n",
    "\n",
    "- Non-quantitative audiences will often more easily understand a point estimate\n",
    "- The dominance of frequentist techniques means that scientific audiences often expect a point estimate\n",
    "- For high-dimensional data, distributions become prohibitively expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For example, the median prediction in the visualization above is a point estimate, selected to summarize the predictions of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### If you have no other choice, use the MAP value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The closest thing to a Bayesian approach to providing point estimates is the **maximum a posteriori** or (MAP) value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The MAP is the setting of all of the unknown variables that has the highest probability under the posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, the values whose probability is _maximal_ after seeing the data, or _a posteriori_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choose params to make $$p(\\text{params} \\vert \\text{data})$$ as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For a variety of reasons, some of them numerical,\n",
    "pyMC and other computational libraries instead do the equivalent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choose params to make $$\\log p(\\text{params} \\vert \\text{data})$$ as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The pyMC function for this is `find_MAP`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than using sampling, this function uses _optimization_:\n",
    "starting from an initial guess of the parameter values,\n",
    "it iteratively makes targeted, small changes their values\n",
    "until no small changes can increase the probability any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with sentiment_switch_model:\n",
    "    sentiment_MAP = arrays_to_scalars(pm.find_MAP(start=sentiment_trace[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice the `logp` on the left in the output: that's the probability we are maximizing.\n",
    "\n",
    "The most important argument here is `start`,\n",
    "which is used to tell `find_MAP` what its initial guess should be.\n",
    "If you have samples available, then one of them is usually a good choice for a starting point.\n",
    "\n",
    "If you don't provide a `start` value, pyMC will try to guess where to start from.\n",
    "This often goes poorly.\n",
    "We'll see what the consequences of a bad initial guess are in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = utils.plot.plot_MAP(sentiment_MAP, switchpoint_samples, \"$p_2 - p_1$\", compare_mean=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The MAP is typically located at a \"peak\" of the distribution: a _mode_.\n",
    "If the distribution has more than one mode, MAP inference can run into problems.\n",
    "A distribution with one mode is called _unimodal_.\n",
    "\n",
    "For symmetric distributions with only one mode, the mean and the mode are the same.\n",
    "Since the distribution above is approximately symmetric and unimodal,\n",
    "the mean and the mode are approximately the same.\n",
    "\n",
    "But note that `find_MAP` is maximizing the _joint probability_\n",
    "of all of the parameters at once.\n",
    "Therefore, it is at a mode of the _joint distribution_,\n",
    "rather than a mode of any of the _marginal distributions_,\n",
    "or the distributions of any single variable.\n",
    "The plot above is of a marginal distribution: the values of just $p_2 - p_1$.\n",
    "It is very common for modes of the joint distribution to line up with\n",
    "modes of the marginal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Texting Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A major advantage of the Bayesian approach is that\n",
    "when the type of data changes while the inferential question stays the same,\n",
    "we only need to make minor adjustments to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following example is from\n",
    "[Chapter 1](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb)\n",
    "of _Bayesian Methods for Hackers_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's say that I suspect that, at some point in the last few months,\n",
    "the rate at which I sent and received text messages changed.\n",
    "\n",
    "This is similar in spirit to the question about sentiment above,\n",
    "in which we wanted to determine if there was a sudden shift in sentiment,\n",
    "but the data we observed there was binary.\n",
    "Now, our data is in terms of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(data_folder / \"txtdata.csv\", index_col=0)\n",
    "print(text_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.bar(text_data.index, text_data[\"counts\"]);\n",
    "ax.set_ylabel(\"Number of Texts\"); ax.set_xlabel(\"Day\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So what do we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### We need to update the likelihood portion of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The part that relates parameters to data\n",
    "needs to be updated to reflect the new form of the data.\n",
    "Furthermore, if that likelihood has different parameters,\n",
    "we need to update the prior to reflect that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But our inference process remains the same:\n",
    "draw samples and then look at HPDs\n",
    "and compute posterior probabilities.\n",
    "This is accomplished _with almost identical code_,\n",
    "no matter how the model has changed:\n",
    "`pm.sample`, `pm.plot_posterior`,\n",
    "and computing the mean of conditions applied to `samples[\"var\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For an approach based on traditional hypothesis testing,\n",
    "there is no obvious way to transfer tools or skills from modeling one dataset onto another.\n",
    "\n",
    "In order to think inferentially about a new type of data,\n",
    "you have to learn or derive a new hypothesis test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Likelihood: `pm.Poisson`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `Poisson` distribution was derived originally to determine the distribution of the number of falsely-convicted individuals.\n",
    "\n",
    "It is commonly used for count data,\n",
    "but it presumes that all of the events are independent:\n",
    "that the events being counted are instances of a memoryless process,\n",
    "just as `Exponential` is used for the intervals between such events.\n",
    "\n",
    "This is decidedly not the case for text messages:\n",
    "sending a text message makes it more likely to receive a text message.\n",
    "However, we can hope that the deviations are relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `Poisson` distribution has one parameter:\n",
    "`mu`, the average number of events,\n",
    "in this case messages sent and received.\n",
    "\n",
    "The values, and so the average, cannot be negative:\n",
    "what does it mean to send -10 text messages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Side note: why is there not also a parameter for the width of the distribution,\n",
    "as is the case for, e.g. `Normal` and `Cauchy` distributions?\n",
    "\n",
    "One signature characteristic of the `Poisson` distribution\n",
    "is that its standard deviation is related to its mean:\n",
    "the mean is the standard deviation squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "So we need a prior over `mu`, over what the possible average number of messages per day might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prior: `pm.Exponential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is just one of many possible choices.\n",
    "\n",
    "The main constraint to respect here is non-negativity.\n",
    "\n",
    "Can you think of any other choices that satisfy this constraint?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- `HalfFlat`, if you don't mind having an improper prior\n",
    "- `HalfCauchy`, if you want to put more probability into large values\n",
    "- `TruncatedNormal`, if you think it's probably close to some value but not less than another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`Exponential` also has a parameter: `lam`, or 1 / average.\n",
    "\n",
    "Since this value is unknown,\n",
    "you might be tempted to put a prior over it.\n",
    "But that prior would most likely itself have a parameter,\n",
    "which would be unknown.\n",
    "\n",
    "It's simpler to set this to a relatively neutral value.\n",
    "For example, if the means were the same,\n",
    "then `lam` would be 1 / the mean of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lam =  1 / text_data[\"counts\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We might alternatively make it even smaller, so the `Exponential` distribution becomes even flatter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Graphically, this model looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "utils.daft.make_text_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = text_data.index\n",
    "counts = text_data[\"counts\"]\n",
    "\n",
    "with pm.Model() as text_switch_model:\n",
    "    mu1 = pm.Exponential(\"$\\mu_1$\", lam=lam)  # prior\n",
    "    mu2 = pm.Exponential(\"$\\mu_2$\", lam=lam)  # prior\n",
    "    switchpoint = pm.DiscreteUniform(        # prior\n",
    "        \"switchpoint\", lower=min(dates), upper=max(dates))  \n",
    "    \n",
    "    mu = pm.Deterministic(\"mu\",\n",
    "        pm.math.switch(shared_util.to_pymc(dates) >= switchpoint, mu2, mu1))\n",
    "    \n",
    "    # likelihood\n",
    "    text_counts = pm.Poisson(\"text_count\", mu, observed=counts)\n",
    "    \n",
    "    # statistic / observation of interest\n",
    "    change_in_rate = pm.Deterministic(\"$\\mu_2 - \\mu_1$\", var=mu2 - mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with text_switch_model:\n",
    "    text_samples = pm.sample(draws=1000, chains=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "On some runs, you may get an error message about the \"Gelman-Rubin statistic\"\n",
    "and the need to reparameterize or change `target_accept`.\n",
    "This message appears when pyMC detects that sampling from the posterior may have failed.\n",
    "The results below will often look very different in that case.\n",
    "\n",
    "If this is the case, try setting the `target_accept` keyword argument above to `0.9`.\n",
    "The default value is `0.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(text_samples, figsize=(16, 16), color=\"C2\", text_size=24,\n",
    "                  varnames=[\"$\\mu_1$\", \"$\\mu_2$\", \"$\\mu_2 - \\mu_1$\", \"switchpoint\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some notes on the posterior:\n",
    "\n",
    "1. We are almost completely certain that there was, in fact, a change:\n",
    "the posterior for the difference in means has no samples below 0.\n",
    "2. There are several plausible dates for when the change occurred:\n",
    "it could've been day 44 or 45, perhaps 43, but not any other time.\n",
    "This is somewhat surprising, given that such a stark pattern is not obvious in the data,\n",
    "but according to the original example, this is approximately the date\n",
    "on which the user moved cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Again, it is helpful to visualize the posterior\n",
    "along with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "text_samples_df = shared_util.samples_to_dataframe(text_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.bar(dates, counts);\n",
    "for _, sample in text_samples_df.sample(n=500).iterrows():\n",
    "    ax.plot(dates, sample[\"mu\"], color=\"C1\", lw=2, alpha=0.02);\n",
    "    \n",
    "ax.legend(\n",
    "[matplotlib.lines.Line2D([], [], color=\"C1\"),\n",
    " matplotlib.lines.Line2D([], [], color=\"C0\", lw=4)],\n",
    "[\"Sampled Predictions of Mean\", \"Raw Data\"]);\n",
    "ax.set_ylabel(\"Number of Texts\"); ax.set_xlabel(\"Day\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Like the visualization for the sentiment example,\n",
    "darker lines indicate higher posterior probability:\n",
    "more samples from the posterior are concentrated around those values.\n",
    "\n",
    "This visualization gives some perspective:\n",
    "while we are certain that a change occurred,\n",
    "it's not a particularly dramatic one.\n",
    "The spread of the data\n",
    "is much larger than the difference in means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying MAP inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we want to give a single answer to \"what is most likely the day my texting behavior changed, and what was it before and after?\" we need to compute the MAP value for all of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with text_switch_model:\n",
    "    text_MAP = pm.find_MAP(start=text_samples[random.randint(0, len(text_samples))])\n",
    "\n",
    "text_MAP = arrays_to_scalars(text_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Again, we use a randomly-chosen posterior sample as our starting point.\n",
    "Using different random `start` values can result in different answers below.\n",
    "\n",
    "A technical detail:\n",
    "the `find_MAP` function returns all parameters as arrays,\n",
    "including parameters that are just a single value.\n",
    "The function `arrays_to_scalars` above\n",
    "converts any arrays in the output of `find_MAP`\n",
    "that have just one entry back into non-array, or scalar, form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.plot_MAP(text_MAP, text_samples_df, \"$\\mu_2 - \\mu_1$\", compare_mean=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.plot_MAP(text_MAP, text_samples_df, \"switchpoint\", compare_mean=True,\n",
    "         bins=range(40, 50), kde=False, norm_hist=True, hist_kws={\"align\": \"left\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Another nice property of the MAP estimate over the mean is that\n",
    "the MAP is always a valid parameter value.\n",
    "\n",
    "Here, the mean switchpoint is not a specific day,\n",
    "but rather in between two days:\n",
    "sommething like 44.3,\n",
    "while the MAP is always a valid day, e.g. 45."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MAP inference can go horribly wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When initialized badly, MAP inference can return very bad answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with text_switch_model:\n",
    "    bad_text_MAP = pm.find_MAP()\n",
    "\n",
    "bad_text_MAP = arrays_to_scalars(bad_text_MAP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot.plot_MAP(bad_text_MAP, text_samples_df, \"$\\mu_2 - \\mu_1$\");\n",
    "plt.title(\"Incorrect MAP Estimate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Most MAP inference algorithms only perform \"local\" improvements:\n",
    "they consider small changes to parameter values and look for which make the posterior probability higher.\n",
    "\n",
    "If they get trapped in a \"bad neighborhood\",\n",
    "where everything nearby is worse, they will stop,\n",
    "even though there are better solutions far away.\n",
    "\n",
    "Imagine trying to find the highest point on a mountain range in a heavy fog.\n",
    "Without knowledge of the terrain, your best bet is to just keep climbing.\n",
    "This will only work if you lucked out and started on the tallest peak.\n",
    "The more mountains there are in the range,\n",
    "the less likely this is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Returning to the big picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By thinking about our data and then writing down generative models in pyMC,\n",
    "we were able to draw posterior samples\n",
    "and make inferences about the process by which the data was generated.\n",
    "\n",
    "We didn't need a recipe book or a prefabricated model:\n",
    "we just needed to think about our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Don't forget about this flexibility when modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the next few weeks, we'll focus on models that are Bayesian versions of traditional models:\n",
    "- ANOVA\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All examples of [_generalized linear models_](https://twiecki.io/blog/2013/08/12/bayesian-glms-1/) or GLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These models are ubiquitous not only because they are amenable to traditional analysis,\n",
    "but also because they are the first tool even very sophisticated statisticians reach for\n",
    "when modeling new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll still have more freedom because of our approach, especially when writing down our likelihoods,\n",
    "but don't forget that, if you can formulate a model for your data that doesn't fit into one of the \"cookie-cutter\" models,\n",
    "you can always just use that model directly!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
