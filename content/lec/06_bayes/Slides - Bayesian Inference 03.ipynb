{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Bayesian Inference 03 - Flexibility of Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import daft\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_raw_data_sentiment(data, ax):\n",
    "\n",
    "    ax.scatter(data[\"album_release_date\"], data[\"positive\"],\n",
    "               alpha=0.1, s=144, color=\"k\");\n",
    "    ax.set_xlabel(\"Album Release Date\")\n",
    "    ax.set_ylabel(\"Positive Sentiment About\\nTrump in Hip-Hop Lyric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_switchpoint(p1, p2, switch, xs, ax, **plot_kwargs):\n",
    "    ps = np.where(np.array(xs) < switch, p1, p2)\n",
    "    ax.plot(xs, ps, **plot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Once You've Learned to Specify Models, Inference Becomes Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the traditional approach,\n",
    "each change to the model requires a new statistical test\n",
    "or the verification/extension of an old one.\n",
    "\n",
    "In the Bayesian Monte Carlo approach,\n",
    "each change to a model either requires just changing what we do with our samples\n",
    "or changing our model specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Within the context of our difference-in-mean problem,\n",
    "that means that all of the questions below\n",
    "become difficult to answer,\n",
    "essentially requiring a trip back to the blackboard or Wikipedia.\n",
    "\n",
    "Can I use the standard $t$-test if..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my standard deviations are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, the test will still perform well, but only if the groups have roughly the same number of observations.\n",
    "Otherwise, you must use [Welch's modified $t$ test](https://en.wikipedia.org/wiki/Welch%27s_t-test),\n",
    "or `scipy.stats.ttest_ind` with argument `equal_var=False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...the groups have different sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, but only if the groups have roughly the same standard deviation. See above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my likelihood changes from `Normal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Yes, [so long as your sample size is large enough](https://thestatsgeek.com/2013/09/28/the-t-test-and-robustness-to-non-normality/). How large is large enough? That's another hard question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- ...I care about differences in medians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes, if the likelihood is symmetric, because the mean is then the same as the median.\n",
    "If the mean and median are different,\n",
    "which is likely why you're interested in the median rather than the mean, then you need a new test,\n",
    "the [Mann-Whitney $U$ test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Comparison_to_Student's_t-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And all of that is while still assuming we are working with comparing the \"center value\" of just two groups in terms of a single measurement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## All of these questions have simple answers in the Bayesian approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do I do if..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my standard deviations are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model! Just make sure there's a different standard deviation variable for each group,\n",
    "as in some of the example from the other set of slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...the groups have different sizes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model!\n",
    "pyMC will automatically handle combining estimates from each group,\n",
    "if the standard deviations are pooled, or separately inferring the values, if they are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...my likelihood changes from `Normal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Include that in your model! Just switch the likelihood component and possibly redefine some of the hidden parameter variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ...I care about differences in medians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Include that in your model! Add a `pm.Deterministic` for calculating that value, or just calculate it afterwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The secret is putting modeling first and statistics second "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All of these questions are about how the model behaves when its assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When you just call a function like `scipy.stats.ttest_ind`,\n",
    "it's unclear what model is being used, what its assumptions are,\n",
    "and how to change that model when those assumptions are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When you write out a pyMC model, all of the assumptions are right there, in the program you have written,\n",
    "and can be changed on the fly, as can the statistic you calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you want to see what happens when the model is wrong,\n",
    "you can simulate data from the alternate model and see how your model behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This Flexibility Pays Major Dividends when Specifying Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than sticking only to the \"off-the-shelf\" models we've carefully studied and reviewed in a statistics course,\n",
    "we can build them from scratch to answer the exact question we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Donald Trump and Hip-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Throughout the 90s,\n",
    "Donald Trump's name appeared repeatedly in hip-hop lyrics,\n",
    "especially by East Coast rappers,\n",
    "where his name was synonymous with wealth and status.\n",
    "\n",
    "Trump's rise to the presidency has changed how many people feel about him.\n",
    "Can we quantify when and to what degree this occurred in hip-hop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Data collection by [fivethirtyeight](https://fivethirtyeight.com),\n",
    "downloaded from\n",
    "[kaggle](https://www.kaggle.com/fivethirtyeight/fivethirtyeight-hip-hop-candidate-lyrics-dataset),\n",
    "see [this fivethirtyeight post](https://projects.fivethirtyeight.com/clinton-trump-hip-hop-lyrics/)\n",
    "for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: the model used here is inspired by two examples in _Bayesian Methods for Hackers_:\n",
    "1. The \"texting switchpoint\" example, from [Chapter 1](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb).\n",
    "2. The \"Challenger O-Ring\" example, from [Chapter 2](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = Path(\".\") / \"data\"\n",
    "\n",
    "trump_data = pd.read_csv(data_folder / \"trump_hiphop_sentiment_data.csv\", index_col=0)\n",
    "\n",
    "print(trump_data.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's eliminate the \"neutral\" category\n",
    "and treat sentiment as binary: `\"positive\"` (`1`) or `\"negative\"` (`0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_to_posneg(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0\n",
    "    elif sentiment == \"positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "trump_data[\"positive\"] = trump_data[\"sentiment\"].apply(sentiment_to_posneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "plot_raw_data_sentiment(trump_data, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Darker circles mean more lyrics with that sentiment were observed in that year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Switchpoint Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For each observation (pair of year and sentiment), there is some unknown chance $p$ that it was positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One reasonable model for this data is that the chance $p$ switched, one year,\n",
    "from being high to low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So our model will have three latent, or hidden, variables\n",
    "that give rise to the unknown variable $p$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Chance of positive sentiment before switch, `p_1` / $p_1$\n",
    "- Chance of positive sentiment after swith, `p_2` / $p_2$\n",
    "- Time that switch occurred, `switchpoint` / $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting model looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_switchpoint_model():\n",
    "    scale = 2\n",
    "    p1 = daft.Node(\"$p_1$\", \"$p_1$\", x=3, y=5.25, scale=scale)\n",
    "    p2 = daft.Node(\"$p_2$\", \"$p_2$\", x=5, y=5.25, scale=scale)\n",
    "    s = daft.Node(\"$s$\", \"$s$\", x=1.5, y=4, scale=scale)\n",
    "    p = daft.Node(\"$p$\", \"$p$\", x=3.5, y=3, scale=scale)\n",
    "    obs = daft.Node(\"obs\", \"obs\", x=3.5, y=0.75, observed=True, scale=scale)\n",
    "    \n",
    "    plate = daft.Plate((2.5, 0.15, 2, 3.5),label=\"$N$\")\n",
    "\n",
    "    nodes = [p1, p2, s, p, obs]\n",
    "    edges = [(\"$p_1$\", \"$p$\"), (\"$p_2$\", \"$p$\"), (\"$s$\", \"$p$\"), (\"$p$\", \"obs\")]\n",
    "\n",
    "    pgm = daft.PGM((6, 6))\n",
    "    [pgm.add_node(node) for node in nodes]\n",
    "    [pgm.add_edge(*edge, lw=3, head_width=0.3) for edge in edges]\n",
    "    \n",
    "    pgm.add_plate(plate)\n",
    "    pgm.render();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or, as a graphical model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "make_switchpoint_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What are some reasonable priors for these variables?\n",
    "\n",
    "- $p_1$/$p_2$: unknown number between 0 and 1.\n",
    "- $s$: unknown integer between 1989 and 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we want to express no strong prior beliefs,\n",
    "we might say `Uniform` for the $p_i$ and\n",
    "`DiscreteUniform` for $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is our likelihood?\n",
    "- obs: whether sentiment in a lyric was positive or negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It's a binary variable, so it's a `Bernoulli` likelihood,\n",
    "with $p$ set by `pm.math.switch`ing between $p_1$ and $p_2$ depending on the date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is our statistic of interest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For one, the parameter $s$, which determines when the change happened.\n",
    "If this value has a wide posterior, then\n",
    "the change was either gradual or small/\n",
    "\n",
    "For another,\n",
    "the difference between $p_2$ and $p_1$,\n",
    "which captures whether the change was positive or negative and to what degree.\n",
    "If $p_2 - p_1$ is small in magnitude, or has equal chance of being positive or negative,\n",
    "then the change was minimal or nonexistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trump_data_sub = trump_data.dropna()  # remove all the na values before passing to pyMC\n",
    "dates = trump_data_sub[\"album_release_date\"]\n",
    "positive = trump_data_sub[\"positive\"]\n",
    "\n",
    "with pm.Model() as sentiment_switch_model:\n",
    "    p1 = pm.Uniform(\"$p_1$\", lower=0, upper=1)  # prior\n",
    "    p2 = pm.Uniform(\"$p_2$\", lower=0, upper=1)  # prior\n",
    "    switchpoint = pm.DiscreteUniform(        # prior\n",
    "        \"switchpoint\", lower=min(dates), upper=max(dates))  \n",
    "    \n",
    "    p = pm.math.switch(shared_util.to_pymc(dates) >= switchpoint, p2, p1)\n",
    "    \n",
    "    # likelihood\n",
    "    positive_sentiment = pm.Bernoulli(\"positive_sentiment\", p, observed=positive)\n",
    "    \n",
    "    # statistic / observation of interest\n",
    "    change_in_sentiment = pm.Deterministic(\"$p_2 - p_1$\", var=p2 - p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with sentiment_switch_model:\n",
    "    sentiment_trace = pm.sample(draws=2500, target_accept=0.9, chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Above, draw samples and save them as a trace, then put them into a dataframe, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "switchpoint_samples = shared_util.samples_to_dataframe(sentiment_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=3, sharex=True)\n",
    "sns.distplot(switchpoint_samples[\"$p_1$\"], ax=axs[0], color=\"C2\");\n",
    "sns.distplot(switchpoint_samples[\"$p_2$\"], ax=axs[1], color=\"C2\");\n",
    "sns.distplot(switchpoint_samples[\"$p_2 - p_1$\"], ax=axs[2], color=\"C2\");\n",
    "axs[-1].set_xlim([-1, 1]); axs[0].set_title(\"Posteriors for Switchpoint Model\"); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Looking at the posterior, it seems that sentiment most likely dropped between before and after the switchpoint,\n",
    "from about 90% positive to about 30% positive.\n",
    "\n",
    "The total drop was about 60%, but could be as low as 30% or as high as 70%.\n",
    "Most of the uncertainty comes from the value after the switchpoint:\n",
    "the posterior for $p_2$ is much wider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Our posterior for the time of the switch is very tight: it almost certainly happened in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.distplot(switchpoint_samples[\"switchpoint\"], kde=False, norm_hist=True, bins=range(1989, 2019),\n",
    "             color=\"C2\");\n",
    "ax.set_title(\"Posterior for Switchpoint Model\"); plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For simplicity, could use `plot_posterior` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(sentiment_trace, figsize=(12, 12),\n",
    "                  varnames=[\"$p_1$\", \"$p_2$\", \"switchpoint\",  \"$p_2 - p_1$\"],\n",
    "                  text_size=24, color=\"C2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But don't be afraid to make a special visualization for your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "plot_raw_data_sentiment(trump_data_sub, ax)\n",
    "\n",
    "# plot median value for each prediction\n",
    "plot_switchpoint(switchpoint_samples[\"$p_1$\"].median(),\n",
    "                 switchpoint_samples[\"$p_2$\"].median(),\n",
    "                 switchpoint_samples[\"switchpoint\"].median(),\n",
    "                 range(1989, 2019), ax, lw=4, color=\"C0\", zorder=4);\n",
    "\n",
    "# plot each sample\n",
    "for _, sample in switchpoint_samples.sample(frac=0.05).iterrows():\n",
    "    plot_switchpoint(sample[\"$p_1$\"], sample[\"$p_2$\"], sample[\"switchpoint\"],\n",
    "                    range(1989, 2019), ax, alpha=0.05, color=\"C1\");\n",
    "    \n",
    "ax.legend(\n",
    "[matplotlib.lines.Line2D([], [], color=\"C1\"),\n",
    " matplotlib.lines.Line2D([], [], color=\"C0\", lw=4)],\n",
    "[\"Sampled Predictions\", \"Median Prediction\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The median of each parameter is used to select a single model to plot, labeled the \"Median Prediction\".\n",
    "\n",
    "The prediction of each sample in the posterior is plotted transparently over the median prediction.\n",
    "Where the color is darker, more samples were making approximately the same prediction,\n",
    "whereas where it is lighter, fewer samples were making that prediction.\n",
    "\n",
    "The median and the mean across samples are not always good choices for single parameters,\n",
    "but here they seem to fall in a region of high posterior value:\n",
    "a place where the color is dark in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Rather than just viewing the posteriors of the parameters,\n",
    "it's good to compare the predictions directly to the data,\n",
    "in some way that makes visually apparent where there's high and low uncertainty.\n",
    "\n",
    "The fact that all of the samples change heights in 2015 indicates\n",
    "that there's essentially no uncertainty in the switchpoint,\n",
    "while the fact that the samples are very spread out afterwards\n",
    "indicates that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Don't Forget About This Flexibility When Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the next few weeks, we'll focus on models that are Bayesian versions of traditional models:\n",
    "- ANOVA\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These models are ubiquitous not only because they are amenable to traditional analysis,\n",
    "but also because they are the first tool even very sophisticated statisticians reach for\n",
    "when modeling new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll still have more freedom because of our approach, especially when writing down our likelihoods,\n",
    "but don't forget that, if you can formulate a model for your data that doesn't fit into one of the \"cookie-cutter\" models,\n",
    "you can always just use that model directly!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
