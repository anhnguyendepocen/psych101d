{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 08a - Effects and Interactions in Multiway Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_groupbys(df, by, column=\"X\"):\n",
    "    _, gbs =  zip(*list(df.groupby(by=by)[column]))\n",
    "    return gbs\n",
    "\n",
    "def make_plot(mus, ax=None, **plot_kwargs):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(figsize=(12, 6))\n",
    "    xs = np.arange(mus.shape[0])\n",
    "    ax.plot(xs, mus[:, 0], lw=4, color=\"C0\", **plot_kwargs)\n",
    "    ax.plot(xs, mus[:, 1], lw=4, color=\"C1\", **plot_kwargs)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def make_line(color, linewidth=4):\n",
    "    return Line2D([0], [0], linewidth=linewidth, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously, we worked with data that varied only along one category, or factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:\n",
    "- how does a participant's performance on a task vary depending on whether they are given caffeine or not?\n",
    "- how do a participant's brain activity patterns vary with the type of music they are listening to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In these lectures, we will learn how to work with data that varies along two or more categories, which might _interact_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:\n",
    "- how do whether a participant drinks caffeine and whether they're over 40 interact to determine their performance on a task?\n",
    "- if we show a person movies inside an fMRI machine, how do both the sound and the image being presented together determine the pattern of activity in their brain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's start by considering how we might make a detailed mechanistic model of an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, we want to describe _exactly_ the process by which each data point is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we run an experiment,\n",
    "we typically only record and control only a very small subset\n",
    "of all the variables we _could_ record and control,\n",
    "and which _in principle_ have an effect on each other and on the variable we are interested in measuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Physics Example: Measuring weight of an object\n",
    "\n",
    "If we measure the weight of an object more than once,\n",
    "we find that what we observe varies from measurement to measurement.\n",
    "\n",
    "That's in part because we usually ignore all of the following:\n",
    "- Air pressure\n",
    "- Temperature\n",
    "- Gravitational pull of the moon\n",
    "- Gravitational pull of the sun and other heavenly bodies\n",
    "- Changes in the stiffness of the springs inside our scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Psychology Example: Measuring a brain signal in response to hearing a word\n",
    "\n",
    "If we perform an experiment where we repeatedly measure a brain signal,\n",
    "e.g. the electrical signal of an EEG (aka brain wave)\n",
    "or the magnetic signal of an fMRI,\n",
    "in response to the same stimulus,\n",
    "e.g. a spoken word,\n",
    "we'll see that the signals vary,\n",
    "both from person to person and within the same person.\n",
    "\n",
    "That's in part because we are ignoring all of the following factors:\n",
    "\n",
    "- How closely they are paying attention\n",
    "- Their bodily state - hungry, sleepy, overheated\n",
    "- The different indviduals' histories with that word\n",
    "- The precise orientation of their skull relative to our probes\n",
    "- The intonation of the word\n",
    "- The behavior of individual brain cells\n",
    "- Variability in our equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In one view, it is our ignorance of these factors that leads to what we call randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The laws of physics are deterministic,\n",
    "excepting certain interpretations of quantum mechanics,\n",
    "meaning that, in principle,\n",
    "once certain values are known\n",
    "(position, velocity, mass, charge, etc.)\n",
    "for all of the pieces of the system,\n",
    "then there is nothing left to chance.\n",
    "\n",
    "And at the scale that most phenomena of interest to humans happen,\n",
    "quantum effects are negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Therefore when we say our data is random, we _must_ be cheating a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## That is, _randomness_ is just code for _things I don't know_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imagine an experiment where there are exactly 12 categorical factors that influence the measured value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is,\n",
    "once one knows the values of each of the 12 factors,\n",
    "the final value of the measurement is _fully determined_.\n",
    "\n",
    "That is, it is deterministic, rather than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Assume further that each factor is binary: it is present or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Lastly, let's say every factor, when present, adds a certain amount to the measurement, which we call the _size_ of the _effect_ of the factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "factor_effect_sizes = list(sorted(pm.Uniform.dist(lower=-1, upper=1).random(size=12)))\n",
    "\n",
    "factor_effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# factor_effect_sizes = [-3] + factor_effect_sizes + [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## To make this work with pyMC, let's say that on any given trial, which effects are present is _random_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is an example of using `pyMC` to simulate a system,\n",
    "as opposed to using `pyMC` to compute posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as many_effects_model:\n",
    "    effects_present = pm.Bernoulli(\"effect_present\", p=0.5, shape=len(factor_effect_sizes))\n",
    "    \n",
    "    sum_of_effects = 0\n",
    "    for ii in range(len(factor_effect_sizes)):\n",
    "        sum_of_effects += factor_effect_sizes[ii] * effects_present[ii]\n",
    "        \n",
    "    observed_data = pm.Deterministic(\"X\", sum_of_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "How to make this more realistic:\n",
    "- Not all factors are binary and have equal chance - could switch to `Categorical`\n",
    "- Many factors are related to each other (we'll see more on that today)\n",
    "- Not all effects are discrete! (we'll talk about that next week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with many_effects_model:\n",
    "    many_effects_trace = pm.sample(draws=500, chains=10)\n",
    "\n",
    "    many_effects_df = pm.trace_to_dataframe(many_effects_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "many_effects_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we know which factors are present and absent, the data looks deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The next block of code finds all the rows that are equal to a given row\n",
    "using `apply` on the `row_equal_to` function defined below.\n",
    "\n",
    "Not all rows will be duplicated,\n",
    "so if the result printed by this cell has only one row,\n",
    "try changing the `row_index`.\n",
    "\n",
    "If you inspect the `effect_present` columns in the output of the cell,\n",
    "you'll see that the values are the same in all the printed rows.\n",
    "Furthermore, the value of the `X` column is also equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def row_equal_to(row, other_row):\n",
    "    return all(row[:-1] == other_row[:-1])\n",
    "\n",
    "row_index = 1\n",
    "equal_to_row = many_effects_df.apply(row_equal_to, axis=1,\n",
    "                                     other_row=many_effects_df.iloc[row_index])\n",
    "\n",
    "many_effects_df[equal_to_row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And so if we were to group our data by all of these columns simultaneously\n",
    "and then look at the histogram of `X`, the result would just be a single point:\n",
    "there would be no \"distribution\" of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Despite the deterministic nature of our data, if we ignore which factors are present, we obtain a familiar-looking distribution for the `X` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is,\n",
    "we pretend that we didn't measure the values of the `effect_present` variables\n",
    "and then look at the distribution.\n",
    "\n",
    "This simulates the realistic setting where we measure the outcome variable\n",
    "but not all of the factors that determine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(min(many_effects_df[\"X\"]), max(many_effects_df[\"X\"]))\n",
    "ps = scipy.stats.norm.pdf(\n",
    "    xs, loc=many_effects_df[\"X\"].mean(), scale=many_effects_df[\"X\"].std())\n",
    "\n",
    "sns.distplot(many_effects_df[\"X\"], label=\"Observed\");\n",
    "ax.plot(xs, ps, lw=4, label=\"Closest Gaussian\"); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The fact that this distribution is bell-shaped is a case of the _Central Limit Theorem_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whenever our measurement is subject to a large number of non-interacting effects\n",
    "of about the same size, the distribution we observe of measurement values\n",
    "if we allow those effects to vary is a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If some of the effects are much larger than the others,\n",
    "then the Central Limit Theorem holds much more loosely:\n",
    "we need more and more interfering effects to end up with a bell curve.\n",
    "\n",
    "It is often the case that some effects are much larger and more important than others:\n",
    "in science, we rely on this to make simple models.\n",
    "\n",
    "To see what this kind of looks like, execute the commented out cell skipped above\n",
    "that adds two new factors to the data, each larger in magnitude than the others,\n",
    "then re-run the cells above.\n",
    "You'll see that the data is no longer distributed normally.\n",
    "If you also run the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can _estimate_ the effect sizes by grouping and taking averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "effect_columns = many_effects_df.columns[:-1]; factor_index = -1\n",
    "group_means = many_effects_df.groupby(effect_columns[factor_index])[\"X\"].mean()\n",
    "group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "group_means[1] - group_means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "factor_effect_sizes[factor_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we group on one of effects and then plot, we still see data that looks random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "column = effect_columns[-1]\n",
    "gbs = retrieve_groupbys(many_effects_df, by=column)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=column, y=\"X\", data=many_effects_df, ax=ax, width=0.5, linewidth=4);\n",
    "\n",
    "scipy.stats.f_oneway(*gbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This type of plot is known as a [Violin Plot](https://seaborn.pydata.org/generated/seaborn.violinplot.html),\n",
    "for the resemblance to the musical instrument.\n",
    "\n",
    "The \"lumpy\" portion of the plot is a kernel density estimate, as in `distplot`.\n",
    "The only difference is that the density is mirrored,\n",
    "on the left and right of the box in the center.\n",
    "The box in the center is a boxplot:\n",
    "the median and the 25th and 75th percentile are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our modeling tools are designed to try and manage the uncertainty that our ignorance of the unmeasured factors introduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This remains true if we group on a small number of effects, relative to the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=effect_columns[-1], y=\"X\", hue=effect_columns[-2], data=many_effects_df, ax=ax, width=0.5,\n",
    "               linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In a real experiment, we would typically only measure a small handful of the influencing factors at most: say, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, treat the model above as the _true model_,\n",
    "one that accurately describes our data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In real life,\n",
    "we usually don't know this model:\n",
    "we don't know the effect sizes,\n",
    "we don't even know the identities of the factors!\n",
    "(and there are actually infinite, or at least an extremely large number of, possibilities\n",
    "for factors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And furthermore, we don't typically measure everything of relevance.\n",
    "We identify, based on our intuition or on previous results,\n",
    "factors that we think are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the data we actually observe, in a real experiment, looks more like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "observed_data_df = pd.DataFrame()\n",
    "\n",
    "factor1_idx = 0\n",
    "factor2_idx = -1\n",
    "\n",
    "observed_data_df[\"factor1\"] = many_effects_df[effect_columns[factor1_idx]]\n",
    "observed_data_df[\"factor2\"] = many_effects_df[effect_columns[factor2_idx]]\n",
    "\n",
    "observed_data_df[\"measurement\"] = many_effects_df[\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, we do not have access to the values of the other factors:\n",
    "they are not columns in our `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Because the factors are ordered by their effect size, from most negative to most positive,\n",
    "setting the indices to 0 and -1 presumes we identifed the factors with the largest effects.\n",
    "\n",
    "Try setting them to different values to see what happens when we try to build models of data\n",
    "where some of the most important factors are left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(observed_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Always think of your data this way:\n",
    "the tip of the iceberg,\n",
    "or as a \"slice\" through what you should be observing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From this dataframe,\n",
    "which represents what we might actually observe in an experiment,\n",
    "we can produce the kinds of plots we've made for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor2\", y=\"measurement\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But, just as we cannot use our data to\n",
    "we cannot see the deterministic nature of the true model in `observed_data_df`,\n",
    "neither can we recover the exact values of the effect sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we specify a model, we can use its posterior to determine the likely values for the effect sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# first part of prior: describing uncertainty in the group means\n",
    "\n",
    "with pm.Model() as synthetic_data_model:\n",
    "    mus = pm.Normal(\"mus\", mu=0, sd=1e2, shape=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The new piece here is in the `shape` argument:\n",
    "now, the shape argument is getting a tuple of values, `shape=(2, 2)`,\n",
    "rather than a single value, e.g. `shape=3`.\n",
    "\n",
    "Previously, when shape had only one value,\n",
    "we though of `mus` as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Technically, in that case and in this one,\n",
    "`mus` is something called a `Tensor`,\n",
    "from the `theano` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this case, you can think of it like a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list_of_lists = [[0, 1], [2, 3]]\n",
    "list_of_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Lists of lists are like `DataFrame`s:\n",
    "each \"inner\" list is a row of the dataframe.\n",
    "\n",
    "To access all the values in a column,\n",
    "we'd want a value from each \"inner\" list\n",
    "that corresponds to a given index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The interpretation of `mus` is still the same:\n",
    "it's just a random variable that holds values for\n",
    "each of the groups means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# second part of prior: describing uncertainty in the standard deviation\n",
    "\n",
    "with synthetic_data_model:\n",
    "    sd = pm.Exponential(\"sigma\", lam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# likelihood: if we knew the means and sds, what would be our remaining uncertainty?\n",
    "\n",
    "with synthetic_data_model:\n",
    "    # where does the uncertainty represented by this Normal come from?\n",
    "    #  from things we're not measuring and modeling\n",
    "    observations = pm.Normal(\"observations\",\n",
    "                             mu=mus[observed_data_df[\"factor1\"], observed_data_df[\"factor2\"]],\n",
    "                             # implementation detail: we use _two_ Series to index mus now\n",
    "                             #  the choice of order means the _rows_ of mu are different levels of factor1\n",
    "                             #  while the _columns_ of mu are different levels of factor2\n",
    "                             sd=sd, observed=observed_data_df[\"measurement\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To determine which group we're in, we need to know our position in both the \"outer\" and the \"inner\" list:\n",
    "we need to index into `mus` based on `factor1` _and_ on `factor2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, there is a different mean for each level of each factor,\n",
    "so to determine the correct mean for each datapoint,\n",
    "we need to know which level it was in in each factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice: this isn't a _mechanistic_ model of our data,\n",
    "or at least not a complete one.\n",
    "\n",
    "We know that the real mechanistic model of our data\n",
    "is the `many_effects_model` above.\n",
    "\n",
    "Instead, we say that some of the mechanisms in our system\n",
    "we are going to approximate with a Normal likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\mu[i, j] \\sim \\text{Normal}(0, 1\\mathrm{e}2)\\\\\n",
    "\\sigma \\sim \\text{Exponential}(0.1)\\\\\n",
    "d \\sim \\text{Normal}(\\mu[i, j], \\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The notation here is meant to evoke the syntax we use to index into `DataFrame`s with `iloc`,\n",
    "which is the same syntax we use to index into arrays, like `mus` in this case.\n",
    "More on that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with synthetic_data_model:\n",
    "    synthetic_trace = pm.sample()\n",
    "    synthetic_posterior_samples = shared_util.samples_to_dataframe(synthetic_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(synthetic_posterior_samples.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that the sampled values of `mus` also look like lists-of-lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_posterior_samples[\"mus\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But they are _not_ actually lists:\n",
    "they are `arrays`,\n",
    "provided by the `numpy` library, alias `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(synthetic_posterior_samples[\"mus\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "They are also like `DataFrames`, in that we can use\n",
    "the indexing syntax, `[...]`, to access their contents.\n",
    "\n",
    "However unlike `DataFrames`,\n",
    "`arrays` only have one style of indexing,\n",
    "which is equivalent to `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(synthetic_posterior_samples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_posterior_samples.iloc[1, 0]   # entry in second row of first column of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_array = synthetic_posterior_samples.iloc[1, 0] \n",
    "\n",
    "example_array, example_array[1, 0]  # entry in second row of first column of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_array, example_array[:, 0]  # entries in all rows of first column of array (result is 1-D array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Also unlike `DataFrames`, arrays can have more (or less) than two dimensions.\n",
    "\n",
    "See [this tutorial for more on numpy and arrays](https://hackernoon.com/introduction-to-numpy-1-an-absolute-beginners-guide-to-machine-learning-and-data-science-5d87f13f0d51)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then estimate the effects of factors from the entries of the `mu` array on each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's look at the mean when both factors are present and when they are absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_both_factors_absent(row):\n",
    "    mus = row[\"mus\"]\n",
    "    return mus[0, 0]  # factor1=0, factor2=0\n",
    "\n",
    "def get_mean_both_factors_present(row):\n",
    "    mus = row[\"mus\"]\n",
    "    return mus[1, 1] # factor1=1, factor2=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mean_both_present = synthetic_posterior_samples.apply(get_mean_both_factors_absent, axis=1)\n",
    "mean_both_absent = synthetic_posterior_samples.apply(get_mean_both_factors_present, axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(mean_both_present - mean_both_absent); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this doesn't tell us what either factor does separately.\n",
    "\n",
    "To do that, we need a bit more work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we need to specify one combination of factor values as a baseline.\n",
    "\n",
    "For this data, the natural choice for baseline is when\n",
    "both factors are absent: `mus[0, 0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We compare the mean when only one of the factors is present to this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_delta_factor1(row):\n",
    "    mus = row[\"mus\"]\n",
    "    \n",
    "    baseline = mus[0, 0]\n",
    "    # remember: rows differ by value of factor 1, columns by value of factor 2\n",
    "    factor1_present = mus[1, 0]\n",
    "    \n",
    "    return factor1_present - baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This represents the effect of factor 1 _in the absence of factor 2_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "delta_factor1_posterior = synthetic_posterior_samples.apply(compute_delta_factor1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor1_posterior, label=\"Posterior\", axlabel=\"Factor 1 Effect, Factor 2 = 0\");\n",
    "ax.vlines(factor_effect_sizes[factor1_idx], 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can do the same for factor 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_delta_factor2(row):\n",
    "    mus = row[\"mus\"]\n",
    "    \n",
    "    baseline = mus[0, 0]\n",
    "    factor2_present = mus[0, 1]\n",
    "    \n",
    "    return factor2_present - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "delta_factor2_posterior = synthetic_posterior_samples.apply(compute_delta_factor2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor2_posterior, label=\"Posterior\", axlabel=\"Factor 2 Effect, Factor 1 = 0\");\n",
    "ax.vlines(factor_effect_sizes[factor2_idx], 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## But this is only the effect of factor 2 _given_ factor 1 is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The problem is that we don't know whether the effect of factor 2 is different\n",
    "depending on whether factor 1 is present or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example: what is the \"effect\" of drinking orange juice on your taste sensation?\n",
    "\n",
    "Normally, the effect is that you taste something sweet and delicious.\n",
    "\n",
    "But in the presence of toothpaste,\n",
    "the effect is that you\n",
    "[taste something bitter instead](https://health.howstuffworks.com/mental-health/human-nature/perception/orange-juice-toothpaste.htm).\n",
    "\n",
    "So we have to be very specific about what we mean about \"the effect\" of a factor,\n",
    "especially when those factors are inter-related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's calculate our posterior for the effect of factor 2 when factor 1 _is_ present (`== 1`)\n",
    "and compare it to the posterior we obtained previously for the effect of factor 2\n",
    "when factor 1 _is not_ present (`== 0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_delta_factor2_factor1_present(row):\n",
    "    mus = row[\"mus\"]\n",
    "    \n",
    "    baseline = mus[1, 0]\n",
    "    factor2_present = mus[1, 1]\n",
    "    \n",
    "    return factor2_present - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "delta_factor2_factor1_present_posterior = synthetic_posterior_samples.apply(\n",
    "    compute_delta_factor2_factor1_present, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor2_posterior, label=\"Factor 2 Effect, Factor 1 = 0\");\n",
    "sns.distplot(delta_factor2_factor1_present_posterior, label=\"Factor 2 Effect, Factor 1 = 1\");\n",
    "ax.vlines(factor_effect_sizes[factor2_idx], 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The posteriors overlap almost perfectly,\n",
    "indicating that we don't expect the measurement to change differently\n",
    "when factor 2 is changed _depending on_ the value of factor 1.\n",
    "\n",
    "The plot below visualizes this directly:\n",
    "it is the posterior for the _difference_ in\n",
    "the values for the change in means induced by\n",
    "the presence of factor 2 in the presence and absence of factor 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor2_posterior - delta_factor2_factor1_present_posterior,\n",
    "             axlabel=\"Difference in Factor 2 Effect across Levels of Factor 1\");\n",
    "ax.vlines(0, 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that the difference appears to be basically 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# This is what we mean by _non-interacting effects_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The effect of one factor is not dependent on the value of the other factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Draw lines between the means: they'll be parallel.\n",
    "Or, alternatively, the two pairs of \"violins\",\n",
    "one pair for `factor1 = 0` and one pair for `factor1 = 1`,\n",
    "are just shifted relative to one another.\n",
    "\n",
    "The seaborn function `pointplot` directly displays the means of different groups\n",
    "(by default, as circles)\n",
    "and connects them with lines.\n",
    "\n",
    "If the slopes of these lines are different,\n",
    "then the effect of factor 1 is different depending on the value of factor 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.pointplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You might notice vertical lines sticking out from the means.\n",
    "These are an estimate of the uncertainty in the mean.\n",
    "By default, `pointplot` uses bootstrapping to estimate this uncertainty.\n",
    "\n",
    "In order to determine whether there is an effect from the `pointplot`,\n",
    "you need to mentally compare the heights of those bars\n",
    "to the differences in slopes of the lines.\n",
    "\n",
    "Alternatively, you could bootstrap the `pointplot`:\n",
    "draw a bootstrap sample from the data and recreate the `pointplot`.\n",
    "If the difference in slopes persists on most bootstraps,\n",
    "then it's likely not due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "[sns.pointplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\",\n",
    "              data=observed_data_df.sample(frac=1, replace=True), linewidth=4)\n",
    " for _ in range(100)]; ax.legend().remove();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can instead use our posteriors over the means and look for the same pattern:\n",
    "do the slopes of these lines look different on a large fraction of the samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "[make_plot(synthetic_posterior_samples.iloc[ii][\"mus\"], ax=ax, alpha=0.01)\n",
    " for ii in random.sample(range(len(synthetic_posterior_samples)), 100)];\n",
    "ax.set_xticks([0, 1]); ax.set_xlabel(\"factor1\");\n",
    "ax.set_ylabel(\"Group Average\"); ax.set_xlim([-0.5, 1.5])\n",
    "ax.legend([make_line(\"C0\"), make_line(\"C1\")], [\"factor2 = 0\", \"factor2 = 1\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When two factors _interact_, they are more than the sum of their parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Literally:\n",
    "if there is _no interaction_,\n",
    "we can guess the mean when both factors appear together\n",
    "by estimating the effect of the two factors separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is the same thing as saying that the two lines above have different slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_interaction_effect(row):\n",
    "    mus = row[\"mus\"]\n",
    "\n",
    "    baseline = mus[0, 0]\n",
    "    prediction_from_separate = baseline + \\\n",
    "        compute_delta_factor1(row) + \\\n",
    "        compute_delta_factor2(row)\n",
    "    \n",
    "    actually_observed_effect = mus[1, 1]\n",
    "    \n",
    "    return actually_observed_effect - prediction_from_separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`compute_interaction_effect` is computing the same thing (up to a minus sign)\n",
    "as `delta_factor2_posterior - delta_factor2_factor1_present_posterior`,\n",
    "but in a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "interaction_effects = synthetic_posterior_samples.apply(\n",
    "    compute_interaction_effect, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(interaction_effects, label=\"Posterior\", axlabel=\"Interaction Effect\");\n",
    "ax.vlines(0, 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(interaction_effects > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But many real-life factors do interact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For example: closing each eye while firing a bow and arrow at a target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Trying to predict what happens when you close _both_ your eyes\n",
    "by just adding together what happens when you close _either_ eye doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's quickly connect this back to our mechanistic model:\n",
    "what are some factors that determine accuracy that we aren't considering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as accuracy_model:\n",
    "    left_eye_closed = pm.Bernoulli(\"left_eye_closed\", p=0.5)\n",
    "    right_eye_closed = pm.Bernoulli(\"right_eye_closed\", p=0.5)\n",
    "    \n",
    "    accuracies = shared_util.to_pymc([[0.8, 0.73],  # notice: a list of lists\n",
    "                                      [0.73, 0.1]])\n",
    "    \n",
    "    target_hit = pm.Bernoulli(\"target_hit\", p=accuracies[left_eye_closed, right_eye_closed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`shared_util.to_pymc` converts the argument to a type of `theano.Tensor` so that it can be used in a pyMC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with accuracy_model:\n",
    "    accuracy_trace = pm.sample()\n",
    "    accuracy_df = pm.trace_to_dataframe(accuracy_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.groupby([\"left_eye_closed\", \"right_eye_closed\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.pointplot(x=\"left_eye_closed\", y=\"target_hit\", hue=\"right_eye_closed\",\n",
    "            data=accuracy_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Look at the lines between the means:\n",
    "they are very much _not_ parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Be careful interpreting effects of factors when there are possible interactions present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consider what this means for the question of \"what is the _effect_ of closing your left eye on accuracy\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The answer is: it depends very much on whether your right eye is open or not!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When interaction effects are present,\n",
    "we need to be careful about making claims regarding the \"effect\" of any factors that interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=2, sharex=True, sharey=True)\n",
    "sns.pointplot(x=\"left_eye_closed\", y=\"target_hit\", hue=\"right_eye_closed\",\n",
    "            data=accuracy_df, linewidth=4, ax=axs[0]);\n",
    "sns.pointplot(x=\"left_eye_closed\", y=\"target_hit\",\n",
    "            data=accuracy_df, linewidth=4, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The second plot is what we would observe if we ignored whether the right eye was open or not:\n",
    "we'd decide that, with high certainty,\n",
    "the \"effect of closing your left eye\" was to decrease accuracy to 0.5,\n",
    "even though this is very far from the whole story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### This is a serious problem for studies of complex systems, like living cells, human bodies and minds, and economies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As suggested by the mechanistic model above,\n",
    "we typically don't and can't measure everything that impacts a system.\n",
    "\n",
    "The systems we describe as complex typically have many factors\n",
    "that interact, and powerfully, in various ways to determine outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "An example: doctors frequently recommend decreased salt intake to decrease the risk of cardiovascular disease by reducing blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, for about 15% individuals,\n",
    "decreasing salt intake actually _increases blood pressure_\n",
    "([see Figure 1 in this article from the American Heart Association](https://www.ahajournals.org/doi/full/10.1161/hyp.0000000000000047)).\n",
    "This is likely to be due to a combination of genetic and environmental factors.\n",
    "\n",
    "These individuals are less numerous and the decreases are smaller,\n",
    "so they are \"washed out\" in the average by the folks whose blood pressure decreases.\n",
    "\n",
    "It is common to say,\n",
    "even in the presence of these facts,\n",
    "that \"the effect of decreasing salt intake\" is to reduce blood pressure,\n",
    "but this is only true _on average_.\n",
    "When we take other factors into account,\n",
    "the effects can be very different."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
