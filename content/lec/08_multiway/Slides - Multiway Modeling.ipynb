{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Multi-way Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_groupbys(df, by, column=\"X\"):\n",
    "    _, gbs =  zip(*list(df.groupby(by=by)[column]))\n",
    "    return gbs\n",
    "\n",
    "def make_plot(mus, ax=None, **plot_kwargs):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(figsize=(12, 6))\n",
    "    xs = np.arange(mus.shape[0])\n",
    "    ax.plot(xs, mus[:, 0], lw=4, color=\"C0\", **plot_kwargs)\n",
    "    ax.plot(xs, mus[:, 1], lw=4, color=\"C1\", **plot_kwargs)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def make_line(color, linewidth=4):\n",
    "    return Line2D([0], [0], linewidth=linewidth, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Previously, we worked with data that varied only along one category, or factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:\n",
    "- how does a participant's performance on a task vary depending on whether they are given caffeine or not?\n",
    "- how do a participant's brain activity patterns vary with the type of music they are listening to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In the next two lectures, we will learn how to work with data that varies along two or more categories, which might _interact_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example:\n",
    "- how do whether a participant drinks caffeine and whether they're over 40 interact to determine their performance on a task?\n",
    "- if we show a person movies inside an fMRI machine, how do both the sound and the image being presented together determine the pattern of activity in their brain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's start by considering how we might make a detailed mechanistic model of an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, we want to describe _exactly_ the process by which each data point is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we run an experiment,\n",
    "we typically only record and control only a very small subset\n",
    "of all the variables we _could_ record and control,\n",
    "and which _in principle_ have an effect on each other and on the variable we are interested in measuring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Physics Example: Measuring weight of an object\n",
    "\n",
    "If we measure the weight of an object more than once,\n",
    "we find that what we observe varies from measurement to measurement.\n",
    "\n",
    "That's in part because we usually ignore all of the following:\n",
    "- Air pressure\n",
    "- Temperature\n",
    "- Gravitational pull of the moon\n",
    "- Gravitational pull of the sun and other heavenly bodies\n",
    "- Changes in the stiffness of the springs inside our scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Psychology Example: Measuring a brain signal in response to hearing a word\n",
    "\n",
    "If we perform an experiment where we repeatedly measure a brain signal,\n",
    "e.g. the electrical signal of an EEG (aka brain wave)\n",
    "or the magnetic signal of an fMRI,\n",
    "in response to the same stimulus,\n",
    "e.g. a spoken word,\n",
    "we'll see that the signals vary,\n",
    "both from person to person and within the same person.\n",
    "\n",
    "That's in part because we are ignoring all of the following factors:\n",
    "\n",
    "- How closely they are paying attention\n",
    "- Their bodily state - hungry, sleepy, overheated\n",
    "- The different indviduals' histories with that word\n",
    "- The precise orientation of their skull relative to our probes\n",
    "- The intonation of the word\n",
    "- The behavior of individual brain cells\n",
    "- Variability in our equipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In one view, it is our ignorance of these factors that leads to what we call randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The laws of physics are deterministic,\n",
    "excepting certain interpretations of quantum mechanics,\n",
    "meaning that, in principle,\n",
    "once certain values are known\n",
    "(position, velocity, mass, charge, etc.)\n",
    "for all of the pieces of the system,\n",
    "then there is nothing left to chance.\n",
    "\n",
    "And at the scale that most phenomena of interest to humans happen,\n",
    "quantum effects are negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Therefore when we say our data is random, we _must_ be cheating a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## That is, _randomness_ is just code for _things I don't know_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imagine an experiment where there are exactly 12 categorical factors that influence the measured value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is,\n",
    "once one knows the values of each of the 12 factors,\n",
    "the final value of the measurement is _fully determined_.\n",
    "\n",
    "That is, it is deterministic, rather than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Assume further that each factor is binary: it is present or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Lastly, let's say every factor, when present, adds a certain amount to the measurement, which we call the _size_ of the _effect_ of the factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "factor_effect_sizes = list(sorted(pm.Uniform.dist(lower=-1, upper=1).random(size=12)))\n",
    "\n",
    "factor_effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# factor_effect_sizes = [-3] + factor_effect_sizes + [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## To make this work with pyMC, let's say that on any given trial, which effects are present is _random_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is an example of using `pyMC` to simulate a system,\n",
    "as opposed to using `pyMC` to compute posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as many_effects_model:\n",
    "    effects_present = pm.Bernoulli(\"effect_present\", p=0.5, shape=len(factor_effect_sizes))\n",
    "    \n",
    "    sum_of_effects = 0\n",
    "    for ii in range(len(factor_effect_sizes)):\n",
    "        sum_of_effects += factor_effect_sizes[ii] * effects_present[ii]\n",
    "        \n",
    "    observed_data = pm.Deterministic(\"X\", sum_of_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "How to make this more realistic:\n",
    "- Not all factors are binary and have equal chance - could switch to `Categorical`\n",
    "- Many factors are related to each other (we'll see more on that today)\n",
    "- Not all effects are discrete! (we'll talk about that next week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with many_effects_model:\n",
    "    many_effects_trace = pm.sample(draws=500, chains=10)\n",
    "\n",
    "    many_effects_df = pm.trace_to_dataframe(many_effects_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "many_effects_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we know which factors are present and absent, the data looks deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The next block of code finds all the rows that are equal to a given row\n",
    "using `apply` on the `row_equal_to` function defined below.\n",
    "\n",
    "Not all rows will be duplicated,\n",
    "so if the result printed by this cell has only one row,\n",
    "try changing the `row_index`.\n",
    "\n",
    "If you inspect the `effect_present` columns in the output of the cell,\n",
    "you'll see that the values are the same in all the printed rows.\n",
    "Furthermore, the value of the `X` column is also equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def row_equal_to(row, other_row):\n",
    "    return all(row[:-1] == other_row[:-1])\n",
    "\n",
    "row_index = 0\n",
    "equal_to_row = many_effects_df.apply(row_equal_to, axis=1,\n",
    "                                     other_row=many_effects_df.iloc[row_index])\n",
    "\n",
    "many_effects_df[equal_to_row]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And so if we were to group our data by all of these columns simultaneously\n",
    "and then look at the histogram of `X`, the result would just be a single point:\n",
    "there would be no \"distribution\" of `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Despite the deterministic nature of our data, if we ignore which factors are present, we obtain a familiar-looking distribution for the `X` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is,\n",
    "we pretend that we didn't measure the values of the `effect_present` variables\n",
    "and then look at the distribution.\n",
    "\n",
    "This simulates the realistic setting where we measure the outcome variable\n",
    "but not all of the factors that determine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(min(many_effects_df[\"X\"]), max(many_effects_df[\"X\"]))\n",
    "ps = scipy.stats.norm.pdf(\n",
    "    xs, loc=many_effects_df[\"X\"].mean(), scale=many_effects_df[\"X\"].std())\n",
    "sns.distplot(many_effects_df[\"X\"], label=\"Observed\");\n",
    "ax.plot(xs, ps, lw=4, label=\"Closest Gaussian\"); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The fact that this distribution is bell-shaped is a case of the _Central Limit Theorem_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whenever our measurement is subject to a large number of non-interacting effects\n",
    "of about the same size, the distribution we observe of measurement values\n",
    "if we allow those effects to vary is a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If some of the effects are much larger than the others,\n",
    "then the Central Limit Theorem holds much more loosely:\n",
    "we need more and more interfering effects to end up with a bell curve.\n",
    "\n",
    "It is often the case that some effects are much larger and more important than others:\n",
    "in science, we rely on this to make simple models.\n",
    "\n",
    "To see what this kind of looks like, execute the commented out cell skipped above\n",
    "that adds two new factors to the data, each larger in magnitude than the others,\n",
    "then re-run the cells above.\n",
    "You'll see that the data is no longer distributed normally.\n",
    "If you also run the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We can _estimate_ the effect sizes by grouping and taking averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "effect_columns = many_effects_df.columns[:-1]; factor_index = -1\n",
    "group_means = many_effects_df.groupby(effect_columns[factor_index])[\"X\"].mean()\n",
    "group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "group_means[1] - group_means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "factor_effect_sizes[factor_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we group on one of effects and then plot, we still see data that looks random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "column = effect_columns[-1]\n",
    "gbs = retrieve_groupbys(many_effects_df, by=column)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=column, y=\"X\", data=many_effects_df, ax=ax, width=0.5, linewidth=4);\n",
    "\n",
    "scipy.stats.f_oneway(*gbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This type of plot is known as a [Violin Plot](https://seaborn.pydata.org/generated/seaborn.violinplot.html),\n",
    "for the resemblance to the musical instrument.\n",
    "\n",
    "The \"lumpy\" portion of the plot is a kernel density estimate, as in `distplot`.\n",
    "The only difference is that the density is mirrored,\n",
    "on the left and right of the box in the center.\n",
    "The box in the center is a boxplot:\n",
    "the median and the 25th and 75th percentile are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our modeling tools are designed to try and manage the uncertainty that our ignorance of the unmeasured factors introduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This remains true if we group on a small number of effects, relative to the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=effect_columns[-1], y=\"X\", hue=effect_columns[-2], data=many_effects_df, ax=ax, width=0.5,\n",
    "               linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In a real experiment, we would typically only measure a small handful of the influencing factors at most: say, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, treat the model above as the _true model_,\n",
    "one that accurately describes our data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In real life,\n",
    "we usually don't know this model:\n",
    "we don't know the effect sizes,\n",
    "we don't even know the identities of the factors!\n",
    "(and there are actually infinite, or at least extremely large number of, possibilities\n",
    "for factors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And furthermore, we don't typically measure everything of relevance.\n",
    "We identify, based on our intuition or on previous results,\n",
    "factors that we think are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the data we actually observe, in a real experiment, looks more like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "observed_data_df = pd.DataFrame()\n",
    "\n",
    "factor1_idx = 0\n",
    "factor2_idx = -1\n",
    "\n",
    "observed_data_df[\"factor1\"] = many_effects_df[effect_columns[factor1_idx]]\n",
    "observed_data_df[\"factor2\"] = many_effects_df[effect_columns[factor2_idx]]\n",
    "\n",
    "observed_data_df[\"measurement\"] = many_effects_df[\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Because the factors are ordered by their effect size, from most negative to most positive,\n",
    "setting the indices to 0 and -1 presumes we identifed the factors with the largest effects.\n",
    "\n",
    "Try setting them to different values to see what happens when we try to build models of data\n",
    "where some of the most important factors are left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(observed_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Always think of your data this way:\n",
    "the tip of the iceberg,\n",
    "or as a \"slice\" through what you should be observing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From this dataframe,\n",
    "which represents what we might actually observe in an experiment,\n",
    "we can produce the kinds of plots we've made for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor2\", y=\"measurement\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But, just as we cannot use our data to\n",
    "we cannot see the deterministic nature of the true model in `observed_data_df`,\n",
    "nor can we recover the exact values of the effect sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our modeling tools are designed to try and manage the uncertainty that our ignorance of the unmeasured factors introduces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# first part of prior: describing uncertainty in the group means\n",
    "\n",
    "with pm.Model() as synthetic_data_model:\n",
    "    mus = pm.Normal(\"mus\", mu=0, sd=1e2, shape=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The new piece here is in the `shape` argument:\n",
    "now, the shape argument is getting a tuple of values, `shape=(2, 2)`,\n",
    "rather than a single value, e.g. `shape=3`.\n",
    "\n",
    "Previously, when shape had only one value,\n",
    "we though of `mus` as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Technically, in that case and in this one,\n",
    "`mus` is something called a `Tensor`,\n",
    "from the `theano` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this case, you can think of it like a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list_of_lists = [[0, 1], [2, 3]]\n",
    "list_of_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The interpretation of `mus` is still the same:\n",
    "it's just a random variable that holds values for\n",
    "each of the groups means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To determine which group we're in, we need to know our position in both the \"outer\" and the \"inner\" list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# second part of prior: describing uncertainty in the standard deviation\n",
    "\n",
    "with synthetic_data_model:\n",
    "    sd = pm.Exponential(\"sigma\", lam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# likelihood: if we knew the means and sds, what would be our remaining uncertainty?\n",
    "\n",
    "with synthetic_data_model:\n",
    "    # where does the uncertainty represented by this Normal come from?\n",
    "    #  from things we're not measuring and modeling\n",
    "    observations = pm.Normal(\"observations\",\n",
    "                             mu=mus[observed_data_df[\"factor1\"], observed_data_df[\"factor2\"]],\n",
    "                             # implementation detail: we use _two_ Series to index mus now\n",
    "                             sd=sd, observed=observed_data_df[\"measurement\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: this isn't a _mechanistic_ model of our data,\n",
    "or at least not a complete one.\n",
    "\n",
    "We know that the real mechanistic model of our data\n",
    "is the `many_effects_model` above.\n",
    "\n",
    "Instead, we say that some of the mechanisms in our system\n",
    "we are going to approximate with a Normal likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\mu[i, j] \\sim \\text{Normal}(0, 1\\mathrm{e}2)\\\\\n",
    "\\sigma \\sim \\text{Exponential}(0.1)\\\\\n",
    "d \\sim \\text{Normal}(\\mu[i, j], \\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The notation here is meant to evoke the syntax we use to index into `DataFrame`s with `iloc`.\n",
    "More on that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with synthetic_data_model:\n",
    "    synthetic_trace = pm.sample()\n",
    "    synthetic_posterior_samples = shared_util.samples_to_dataframe(synthetic_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(synthetic_posterior_samples.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that the sampled values of `mus` also look like lists-of-lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_posterior_samples[\"mus\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But they are _not_ actually lists:\n",
    "they are `arrays`,\n",
    "provided by the `numpy` library, alias `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(synthetic_posterior_samples[\"mus\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "They are also like `DataFrames`, in that we can use\n",
    "the indexing syntax, `[...]`, to access their contents.\n",
    "\n",
    "However unlike `DataFrames`,\n",
    "`arrays` only have one style of indexing,\n",
    "which is equivalent to `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(synthetic_posterior_samples.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_posterior_samples.iloc[1, 0]   # entry in second row of first column of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_array = synthetic_posterior_samples.iloc[1, 0] \n",
    "\n",
    "example_array, example_array[1, 0]  # entry in second row of first column of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "example_array, example_array[:, 0]  # entries in all rows of first column of array (result is 1-D array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Also unlike `DataFrames`, arrays can have more (or less) than two dimensions.\n",
    "\n",
    "See [this tutorial for more on numpy and arrays](https://hackernoon.com/introduction-to-numpy-1-an-absolute-beginners-guide-to-machine-learning-and-data-science-5d87f13f0d51)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then estimate the effects of factors from the entries of the `mu` array on each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's look at the mean when both factors are present and when they are absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_both_factors_absent(row):\n",
    "    mus = row[\"mus\"]\n",
    "    return mus[0, 0]\n",
    "\n",
    "def get_mean_both_factors_present(row):\n",
    "    mus = row[\"mus\"]\n",
    "    return mus[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mean_both_present = synthetic_posterior_samples.apply(get_mean_both_factors_absent, axis=1)\n",
    "mean_both_absent = synthetic_posterior_samples.apply(get_mean_both_factors_present, axis=1)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(mean_both_present - mean_both_absent);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this doesn't tell us what either factor does separately.\n",
    "\n",
    "To do that, we need a bit more work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_delta_factor1(row):\n",
    "    mus = row[\"mus\"]\n",
    "    \n",
    "    # what is the mean when factor1 is present, averaging across factor2?\n",
    "    mean_factor1_present = (mus[1, 0] + mus[1, 1]) / 2\n",
    "    \n",
    "    # same as above, but for factor1 absent\n",
    "    mean_factor1_absent = np.mean(mus[0, :]) \n",
    "    return mean_factor1_present - mean_factor1_absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "delta_factor1_posterior = synthetic_posterior_samples.apply(compute_delta_factor1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor1_posterior, label=\"Posterior\", axlabel=\"Factor 1 Effect\");\n",
    "ax.vlines(factor_effect_sizes[factor1_idx], 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_delta_factor2(row):\n",
    "    mus = row[\"mus\"]\n",
    "    \n",
    "    # what are the means for the factor2 groups, averaging across factor1?\n",
    "    factor2_group_means = np.mean(mus[:, 0]), np.mean(mus[:, 1])\n",
    "    \n",
    "    return factor2_group_means[1] - factor2_group_means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "delta_factor2_posterior = synthetic_posterior_samples.apply(compute_delta_factor2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_factor2_posterior, label=\"Posterior\", axlabel=\"Factor 2 Effect\");\n",
    "ax.vlines(factor_effect_sizes[factor2_idx], 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What do we mean  by _non-interacting_ effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(x=\"factor1\", y=\"measurement\", hue=\"factor2\", data=observed_data_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Draw lines between the means: they'll be parallel.\n",
    "Or, alternatively, the two pairs of \"violins\",\n",
    "one pair for `factor1 = 0` and one pair for `factor1 = 1`,\n",
    "are just shifted relative to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can check for interactions directly from our posterior values for the means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "[make_plot(synthetic_posterior_samples.iloc[ii][\"mus\"], ax=ax, alpha=0.1)\n",
    " for ii in random.sample(range(len(synthetic_posterior_samples)), 200)];\n",
    "ax.set_xticks([0, 1]); ax.set_xlabel(\"factor1\");\n",
    "ax.set_ylabel(\"Group Average\")\n",
    "ax.legend([make_line(\"C0\"), make_line(\"C1\")], [\"factor2 = 0\", \"factor2 = 1\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When two factors _interact_, they are more than the sum of their parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Literally:\n",
    "if there is _no interaction_,\n",
    "we can guess the effect of both factors together\n",
    "by estimating the effect of the two factors separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_interaction_effect(row):\n",
    "    mus = row[\"mus\"]\n",
    "    # compute the \"mean of means\" with np.mean,\n",
    "    #  which by default averages _across rows and columns_\n",
    "    grand_mean = np.mean(mus)\n",
    "    \n",
    "    prediction_from_separate = grand_mean + \\\n",
    "        compute_delta_factor1(row) + \\\n",
    "        compute_delta_factor2(row)\n",
    "    \n",
    "    actually_observed_effect = mus[1, 1]\n",
    "    \n",
    "    return actually_observed_effect - prediction_from_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "interaction_effects = synthetic_posterior_samples.apply(\n",
    "    compute_interaction_effect, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(interaction_effects, label=\"Posterior\", axlabel=\"Interaction Effect\");\n",
    "ax.vlines(0, 0, 4, lw=4, label=\"True Value\");\n",
    "ax.legend(); ax.set_xlim(-1.5, 1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(interaction_effects > 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note:\n",
    "sometimes more than 95% of the posterior is on one side or the other\n",
    "of `0`, indicating that a \n",
    "\n",
    "But notice how small the values are,\n",
    "relative to the effects for the main factors\n",
    "and relative to the variability in the data.\n",
    "\n",
    "This underscores the importance of thinking about whether an effect in the data is _meaningful_\n",
    "not just whether it is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# what is the posterior chance that the interaction effect is larger than 5% of the variability in the data?\n",
    "(np.abs(interaction_effects) > (5e-2 / observed_data_df[\"measurement\"].std())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# what is the posterior chance that the effect of factor1 is larger than 5% of the variability in the data?\n",
    "(np.abs(delta_factor1_posterior) > (5e-2 / observed_data_df[\"measurement\"].std())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But many real-life factors do interact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For example: closing each eye while firing a bow and arrow at a target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Trying to predict what happens when you close _both_ your eyes\n",
    "by just adding together what happens when you close _either_ eye doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's quickly connect this back to our mechanistic model:\n",
    "what are some factors that determine accuracy that we aren't considering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as accuracy_model:\n",
    "    left_eye_closed = pm.Bernoulli(\"left_eye_closed\", p=0.5)\n",
    "    right_eye_closed = pm.Bernoulli(\"right_eye_closed\", p=0.5)\n",
    "    \n",
    "    accuracies = shared_util.to_pymc([[0.8, 0.73],  # notice: a list of lists\n",
    "                                      [0.73, 0.1]])\n",
    "    \n",
    "    target_hit = pm.Bernoulli(\"target_hit\", p=accuracies[left_eye_closed, right_eye_closed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`shared_util.to_pymc` converts the argument to a type of `theano.Tensor` so that it can be used in a pyMC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with accuracy_model:\n",
    "    accuracy_trace = pm.sample()\n",
    "    accuracy_df = pm.trace_to_dataframe(accuracy_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.groupby([\"left_eye_closed\", \"right_eye_closed\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.barplot(x=\"left_eye_closed\", y=\"target_hit\", hue=\"right_eye_closed\",\n",
    "            data=accuracy_df, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Draw lines between the means:\n",
    "they are very much _not_ parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's look for interactions in some real data.\n",
    "\n",
    "We'll be using some EEG experiment data graciously provided by the [Voytek lab](http://voyteklab.com/about-us/) of UCSD. Participants of varying ages were asked to perform a working memory task with varying levels of difficulty. The raw EEG signal has been summarized into the following two measures:\n",
    "\n",
    "* [Contralateral Delay Activity](https://www.ncbi.nlm.nih.gov/pubmed/26802451), or CDA, is used to measure the engagement of visual working memory.\n",
    "\n",
    "* [Frontal Midline Theta](https://www.ncbi.nlm.nih.gov/pubmed/9895201) oscillation amplitude has been correlated with sustained, internally-directed cognitive activity.\n",
    "\n",
    "The performance of the subjects has also been summarized using the measure\n",
    "[d'](https://en.wikipedia.org/wiki/Sensitivity_index) (pronounced \"d-prime\"), also known as the *sensitivity index*. D' is a measure of the subject's performance in  a task. It's based on comparing the true positive rate and false positive rate.\n",
    "\n",
    "In this lecture, we will look at `d`, the subject performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "shared_data_path = Path(\"..\") / \"..\" / \"shared\" / 'data'\n",
    "\n",
    "df = pd.read_csv(shared_data_path / 'voytek_working_memory_aging_split.csv', index_col=None)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(df.groupby(\"group\")[\"age\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(df[\"d\"], ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# If we split this data up by one variable at a time, we know what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(y=\"d\", x=\"group\", data=df, ax=ax, linewidth=4, width=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scipy.stats.f_oneway(df[\"d\"][df[\"group\"] == 1],\n",
    "                     df[\"d\"][df[\"group\"] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(y=\"d\", x=\"difficulty\", data=df, ax=ax, linewidth=4, width=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scipy.stats.f_oneway(df[\"d\"][df[\"difficulty\"] == 1],\n",
    "                     df[\"d\"][df[\"difficulty\"] == 2],\n",
    "                     df[\"d\"][df[\"difficulty\"] == 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We've already worked with one-way models in pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's simplify and format our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "data[\"age_group\"] = df[\"group\"] - 1  # subtract 1 so that it starts from 0, like Python indexing\n",
    "data[\"difficulty\"] = df[\"difficulty\"] - 1\n",
    "data[\"d\"] = df[\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For a one-way model, we define something like a list of parameters, then index into that list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\mu[i] \\sim \\text{Normal}(0, 1\\mathrm{e}6, \\text{shape}=3)\\\\\n",
    "\\sigma \\sim \\text{Exponential}(0.1)\\\\\n",
    "d \\sim \\text{Normal}(\\mu[i], \\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "difficulty_indexer = data[\"difficulty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as eeg_difficulty_model:\n",
    "    means = pm.Normal(\"mus\", mu=0, sd=1e6, shape=3)\n",
    "    sd = pm.Exponential(\"sigma\", lam=0.1)\n",
    "    \n",
    "    observations = pm.Normal(\"d\", mu=means[difficulty_indexer], sd=sd, observed=data[\"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In class, we won't sample from and work with these models,\n",
    "since we've already seen them,\n",
    "but feel frree to add cells and look at the posteriors in your copy of the slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For a different one-way model, we define a different indexer and change the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "age_indexer = data[\"age_group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$\n",
    "\\mu[j] \\sim \\text{Normal}(0, 1\\mathrm{e}6, \\text{shape}=2)\\\\\n",
    "\\sigma \\sim \\text{Exponential}(0.1)\\\\\n",
    "d \\sim \\text{Normal}(\\mu[j], \\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as eeg_age_model:\n",
    "    means = pm.Normal(\"mus\", mu=0, sd=1e6, shape=2)\n",
    "    sd = pm.Exponential(\"sigma\", lam=1)\n",
    "    \n",
    "    observations = pm.Normal(\"d\", mu=means[age_indexer], sd=sd, observed=data[\"d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# But if we group the data by two categories at once, it's unclear what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax, = plt.subplots(figsize=(12, 6))\n",
    "sns.violinplot(y=\"d\", x=\"difficulty\", hue=\"group\", data=df, ax=ax, linewidth=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`scipy` does not provide functions for performing statistical tests\n",
    "about multiple factors at once:\n",
    "hence the `one` in `f_oneway`.\n",
    "\n",
    "Next time,\n",
    "we'll see how this is done using a different Python library,\n",
    "`statsmodels`.\n",
    "\n",
    "The fact that the analytical statistical testing approach requires a new library\n",
    "is another sign of its inflexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We've already been working around this problem.\n",
    "The `attention` dataset also has multiple possible grouping factors:\n",
    "the `attention` column and the `solutions` column.\n",
    "Previously, we either ignored one column\n",
    "or looked at only rows where one of the two was fixed.\n",
    "\n",
    "But we'll get a more complete understanding of our data\n",
    "if we include all of the factors we measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In pyMC, multi-way models are only a small adjustment: we define something like a list-of-lists for the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That is, we have one parameter for each combination of each factor.\n",
    "\n",
    "$$\n",
    "d \\sim \\text{Normal}(\\mu[i, j], \\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as eeg_combined_model:\n",
    "    means = pm.Normal(\"mus\", mu=0, sd=1e6, shape=(3, 2))\n",
    "    sigma = pm.Exponential(\"sigma\", lam=0.1)\n",
    "    \n",
    "    observations = pm.Normal(\"d\", mu=means[difficulty_indexer, age_indexer], sd=sigma, observed=data[\"d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with eeg_combined_model:\n",
    "    eeg_combined_trace = pm.sample(draws=1000)\n",
    "    eeg_combined_df = shared_util.samples_to_dataframe(eeg_combined_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(eeg_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "eeg_combined_df[\"mus\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Each sample contains a mean for each combination of age group (column)\n",
    "and task difficulty (row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## As always, the first move is to visualize our posterior,\n",
    "\n",
    "ideally in a manner similar to how we visualized our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=2, sharex=True, sharey=True); ax=axs[0]\n",
    "[make_plot(eeg_combined_df.iloc[ii][\"mus\"], ax=ax, alpha=0.1)\n",
    " for ii in random.sample(range(len(eeg_combined_df)), 200)];\n",
    "ax.set_xticks([0, 1, 2]); ax.set_xlabel(\"Difficulty Index\");\n",
    "ax.set_ylabel(\"Group Average d\")\n",
    "ax.legend([make_line(\"C0\"), make_line(\"C1\")], [\"Young\", \"Old\"]);\n",
    "\n",
    "sns.violinplot(x=\"difficulty\", y=\"d\", hue=\"age_group\",\n",
    "               data=data, ax=axs[1], axlabel=False); axs[1].get_legend().remove();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice how the slope of the line from difficulty 0 to difficulty 2 looks slightly steeper\n",
    "for the yellow lines (the old age group)\n",
    "than for the blue lines (the young age group)?\n",
    "\n",
    "That suggests there is an interaction:\n",
    "one way to phrase it is that the harder tasks are even harder for the older age group\n",
    "than for the younger age group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "One thing that makes multi-way models harder is that the claims we are interested in\n",
    "are not directly present in the group means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, to get at the things we find interesting,\n",
    "we typically need to `apply` some Python functions to the entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then estimate the effects of factors from the entries of the `mu` array on each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def compute_grand_mean(mus):\n",
    "    # compute the \"mean of means\" with np.mean,\n",
    "    #  which by default averages _across rows and columns_\n",
    "    return np.mean(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grand_means = eeg_combined_df[\"mus\"].apply(compute_grand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(grand_means);  # for d, a value of 1 means chance performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_age_means(mus):\n",
    "    # use np.mean function, but only average across _rows_\n",
    "    age_means = np.mean(mus, axis=0)\n",
    "    return age_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "age_group_means = eeg_combined_df[\"mus\"].apply(compute_age_means)\n",
    "\n",
    "age_group_means.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We calculate a group mean for each age group on each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, to calculate the \"effect\" of the age variable,\n",
    "aka the average difference of the two group levels,\n",
    "we need to subtract one from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def age_factor_effect(age_group_means):\n",
    "    return age_group_means[1] - age_group_means[0]\n",
    "\n",
    "delta_ages = age_group_means.apply(age_factor_effect)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(delta_ages, axlabel=\"Old vs Young Factor Effect\");\n",
    "ax.set_xlim([-1.7, 1.7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_difficulty_group_means(mus):\n",
    "    return np.mean(mus, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "difficulty_group_means = eeg_combined_df[\"mus\"].apply(compute_difficulty_group_means)\n",
    "\n",
    "difficulty_group_means.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We calculate a group mean for each difficulty group on each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Because there are more than two difficulty groups,\n",
    "if we want to think about an \"effect\" we need to specify a difference between two groups.\n",
    "\n",
    "For example, the highest difficulty and the lowest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hard_vs_easy = difficulty_group_means.apply(\n",
    "    lambda difficulty_group_means: difficulty_group_means[2] - difficulty_group_means[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(hard_vs_easy, axlabel=\"Hard vs Easy Factor Effect\");\n",
    "ax.set_xlim([-1.7, 1.7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_interaction_effect(mus, diff_index, age_index):\n",
    "    prediction_from_separate = compute_difficulty_group_means(mus)[diff_index] \\\n",
    "        + compute_age_means(mus)[age_index]\\\n",
    "        - compute_grand_mean(mus)\n",
    "    \n",
    "    actually_observed_effect = mus[diff_index, age_index]\n",
    "    \n",
    "    return actually_observed_effect - prediction_from_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "interaction_effects_old_hard = eeg_combined_df[\"mus\"].apply(\n",
    "    compute_interaction_effect, diff_index=2, age_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(interaction_effects_old_hard,\n",
    "             axlabel=\"Interaction Effect Between\\nOld Age Group and Hard Task Difficulty\");\n",
    "ax.set_xlim([-1.7, 1.7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(interaction_effects_old_hard > 0).mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
