{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Over-Fitting and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)\n",
    "\n",
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def make_yerr(predictions, observations):\n",
    "    errors = predictions - observations\n",
    "    positive_errors = np.where(errors>0, errors, 0)\n",
    "    negative_errors = np.where(errors<0, -errors, 0)\n",
    "    return np.stack([positive_errors, negative_errors])\n",
    "\n",
    "\n",
    "def make_error_plot(params, observation_df, y=\"std_mpg\", x=\"std_weight\", featurizers=None):\n",
    "    f, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.scatter(observation_df[x], observation_df[y], s=144, label=\"observations\")\n",
    "    xs = np.linspace(-3, 3, num=1000)\n",
    "    ax.plot(xs, predict_linear_model(params, xs, featurizers),\n",
    "            lw=4, color=\"C1\", label=\"prediction function\");\n",
    "\n",
    "    predictions =  predict_linear_model(params, observation_df[x], featurizers)\n",
    "    yerr = make_yerr(predictions, observation_df[y])\n",
    "    ax.errorbar(observation_df[x], predictions,\n",
    "                yerr=yerr, ecolor=\"r\", elinewidth=4, ls=\"none\", zorder=0, label=\"errors\");\n",
    "    ax.set_ylim(-3, 3); ax.legend();\n",
    "    MSE = round(np.sum(np.square(yerr)) / len(observation_df), 1)\n",
    "    ax.set_title(f\"MSE = {MSE}\")\n",
    "\n",
    "    \n",
    "def preds_plot(x, y, data, model_results, use_step=False, **plot_kwargs):\n",
    "    \n",
    "    if \"color\" not in plot_kwargs:\n",
    "        plot_kwargs[\"color\"] = \"C1\"\n",
    "    if \"lw\" not in plot_kwargs:\n",
    "        plot_kwargs[\"lw\"] = 4\n",
    "    \n",
    "    xs = data[x]\n",
    "    model_predictions = model_results.model.predict(model_results.params)\n",
    "\n",
    "    sorted_xs = xs[np.argsort(xs)]\n",
    "    sorted_predictions = model_predictions[np.argsort(xs)]\n",
    "\n",
    "    sns.lmplot(x, y, data=data, lowess=True);\n",
    "    f, ax = plt.gcf(), plt.gca(); f.set_size_inches((12, 12))\n",
    "    if not use_step:\n",
    "        ax.plot(sorted_xs, sorted_predictions, **plot_kwargs)\n",
    "    else:\n",
    "        ax.step(sorted_xs, sorted_predictions, **plot_kwargs)\n",
    "\n",
    "        \n",
    "def ic_compare(ic_tables, ic_name=\"LOO\"):\n",
    "    f, ax = plt.subplots(figsize=(12, 6))\n",
    "    n = len(ic_tables)\n",
    "    ax.errorbar(ic_tables[ic_name], range(n), xerr=1 * ic_tables[\"SE\"], linestyle=\"none\", lw=4,\n",
    "                marker=\".\", markersize=24);\n",
    "    ax.set_yticks(range(n)); ax.set_yticklabels(ic_tables.index.values);\n",
    "    ax.set_xlabel(ic_name)\n",
    "\n",
    "    \n",
    "def plot_cross_validated_models(cv_results, MAP_result, data, featurizers=None,\n",
    "                                x=\"std_mpg\", y=\"std_weight\",\n",
    "                                x_range=(-2.5, 3), ylim=([-2, 2.25])):\n",
    "    f, ax = plt.subplots(figsize=(12, 12))\n",
    "    [ax.plot(np.linspace(*x_range),\n",
    "        predict_linear_model(pd.Series(result.params), np.linspace(*x_range), featurizers),\n",
    "        alpha=0.05, color=\"C1\", lw=4) for result in cv_results];\n",
    "    sns.regplot(x, y, data, lowess=True, ax=ax, scatter_kws={\"zorder\": 3})\n",
    "    ax.plot(np.linspace(*x_range, num=1000),\n",
    "        predict_linear_model(MAP_result.params, np.linspace(*x_range, num=1000), featurizers),\n",
    "        alpha=1, color=\"k\", lw=4, label=\"Prediction on Full Dataset\");\n",
    "    ax.set_ylim(ylim); ax.legend();\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def smf_fit(formula, data, regularizer=None):\n",
    "    model = smf.ols(formula, data=data)\n",
    "    if regularizer is not None:\n",
    "        if regularizer in [\"l1\", \"lasso\", \"laplace\"]:\n",
    "            results = model.fit_regularized(L1_wt=1)\n",
    "        elif regularizer == [\"l2\", \"ridge\", \"normal\"]:\n",
    "            results = model.fit_regularized(L1_wt=0)\n",
    "        elif 0 <= regularizer <= 1:\n",
    "            results = model.fit_regularized(L1_wt=regularizer)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown regularizer {regularizer}\")\n",
    "    else:\n",
    "        results = model.fit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def predict_linear_model(params, x, featurizers=None):\n",
    "    if featurizers is None:\n",
    "        featurizers = [lambda x: 1, lambda x: x]  # intercept and linear term\n",
    "    return sum(pd.Series(params.values) * pd.Series(f(x) for f in featurizers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today, we will consider how to evaluate and compare models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $R^2$ and similar criteria derived from the likelihood on observed data are insufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The $R^2$, or variance explained, was derived for models with a Normal likelihood term.\n",
    "It corresponds to a normalized version of the log-likelihood of the data.\n",
    "\n",
    "If we consider a different likelihood, e.g. Bernoulli,\n",
    "we get a different quantity for the log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## For these metrics, the MLE is always the winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$p(\\text{params}\\vert \\text{data}) \\propto p(\\text{data}\\vert \\text{params})\\cdot p(\\text{params})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "MAP methods maximize the posterior probability (on the left)\n",
    "while MLE maximizes the likelihood (first term on the right side of the $\\propto$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "So if we only care about log-likelihood,\n",
    "the MLE will always look like the best model,\n",
    "even though it doesn't incorporate the prior information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fundamentally, the MLE parameters &#8220;explain&#8221; the data as best as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "They make the observed data seem _minimally random_ or _minimally suprising_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Relative to all other choices of parameters,\n",
    "they make the outcomes we observed _maximally likely_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## But the goal of modeling isn't always just to explain data we've seen, it's to predict data we _haven't_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Put another way,\n",
    "you don't get any credit for coming up with some explanation after the fact\n",
    "that makes sense of everything you've observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In fact,\n",
    "if the explanation is too accurate,\n",
    "it might be overly-complicated or fixated on irrelevant details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Consider the following proverb, of\n",
    "[immemorial origin](https://en.wikipedia.org/wiki/For_Want_of_a_Nail):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For Want of a Nail\n",
    "For want of a nail the shoe was lost.\n",
    "\n",
    "For want of a shoe the horse was lost.\n",
    "\n",
    "For want of a horse the rider was lost.\n",
    "\n",
    "For want of a rider the message was lost.\n",
    "\n",
    "For want of a message the battle was lost.\n",
    "\n",
    "For want of a battle the kingdom was lost.\n",
    "\n",
    "And all for the want of a horseshoe nail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While it is certainly possible that a causal chain links the lost nail to the fall of the kingdom,\n",
    "it seems more plausible that facts about the kingdoms participating in the war\n",
    "are where the key causal factors lie --\n",
    "the ones that can be used to determine which kingdoms will fall in the future, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Or the below \"mind-map\"\n",
    "which purports to \"explain\" and connect\n",
    "everything from Hurricane Katrina (AD 2005) and the [First Council of Nicaea](https://en.wikipedia.org/wiki/First_Council_of_Nicaea) (AD 325)\n",
    "to the HIV crisis and [the sinking of the _Lusitania_](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Lusitania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Below is the QWorld map which took years in the making. The most important document you will ever come across. Please share &amp; spread awareness. It&#39;s time the people receive their deserved hidden truths. It&#39;s time to break free from tyranny &amp; enslavement. <a href=\"https://twitter.com/hashtag/Qanon?src=hash&amp;ref_src=twsrc%5Etfw\">#Qanon</a> <a href=\"https://twitter.com/hashtag/TheGreatAwakening?src=hash&amp;ref_src=twsrc%5Etfw\">#TheGreatAwakening</a> <a href=\"https://t.co/1KzyY9zwBk\">pic.twitter.com/1KzyY9zwBk</a></p>&mdash; QNN: Qanon News Network (@realQNN) <a href=\"https://twitter.com/realQNN/status/1035943634540081155?ref_src=twsrc%5Etfw\">September 1, 2018</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While this \"model\" does an admirable job of explaining many historical observations,\n",
    "it is not very useful for predicting either additional, unobserved historical data or the future.\n",
    "\n",
    "The map is based on the QAnon phenomenon,\n",
    "which centered on \"decoding\" the bizarre and cryptic internet posts of an individual known as Q,\n",
    "who claimed inside knowledge of a massive and bizarre conspiracy.\n",
    "\n",
    "Inevitably, these posts would generate fevered speculation when they appeared,\n",
    "then be used to \"explain\" major news events over the following days and weeks.\n",
    "But they were effectively useless for predicting those events before they occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The website\n",
    "[spurious correlations](https://www.tylervigen.com/spurious-correlations)\n",
    "collects examples of likelihood-maximizing linear models\n",
    "that seem to clearly \"miss the point\" in these (and other) ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The problem of explaining observed data &#8220;too well&#8221; is known as _over-fitting_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have fit, or explained, the data _so well_ that we've also explained\n",
    "meaningless fluctuations we'd rather ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## To adequately compare models, we must see how they perform on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Obtaining new data to measure a model's performance is known as _validation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The technique commonly used to \"fake\" validation,\n",
    "just as boot-strapping is used to \"fake\" resampling,\n",
    "is known as _cross-validation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Over-fitting and cross-validation will be the topics of these slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First, let's demonstrate over-fitting rigorously and quantitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We'll use the `mpg` dataset,\n",
    "which contains a bunch of measurements of cars produced in the 70s and 80s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpg_df = sns.load_dataset(\"mpg\", data_home=Path(\"..\") / \"..\" / \"shared\" / \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=mpg_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Not every relationship in this dataset can be modeled linearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For example, consider the relationship between weight and fuel efficiency (in _miles per gallon_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.scatterplot(x=\"weight\", y=\"mpg\", data=mpg_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These two factors don't appear unrelated,\n",
    "but they don't appear linearly related either.\n",
    "\n",
    "First, we'll fit a linear model to their ($z$-scored) values to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def zscore(vals):\n",
    "    return (vals - vals.mean()) / vals.std(ddof=1)\n",
    "\n",
    "mpg_df[\"std_weight\"] = zscore(mpg_df[\"weight\"])\n",
    "mpg_df[\"std_mpg\"] = zscore(mpg_df[\"mpg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For now,\n",
    "we'll just focus on maximum likelihood and maximum a posteriori methods,\n",
    "and so we'll use `statsmodels`,\n",
    "a Python library that allows us to write and \"fit\"\n",
    "models using the formula interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "weight_mpg_linear_ols_model = smf.ols(  # ordinary least squares, aka Normal likelhood, Flat priors\n",
    "    \"std_mpg ~ std_weight\", data=mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This formula says that the (standardized) fuel efficiency is Normally distributed\n",
    "around a line computed from the (standardized) weight\n",
    "with some slope and intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By running the `.fit()` method,\n",
    "we effectively execute `find_MAP`\n",
    "in the equivalent pyMC model.\n",
    "\n",
    "We also obtain some null hypothesis statistical tests\n",
    "on that model,\n",
    "checking whether the parameters are \"significantly\" different from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "weight_mpg_linear_ols_results = weight_mpg_linear_ols_model.fit()\n",
    "\n",
    "print(weight_mpg_linear_ols_results.rsquared)\n",
    "\n",
    "weight_mpg_linear_ols_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The output of this method is rich --\n",
    "it's intended for professional statisticians.\n",
    "\n",
    "We're focused only on the value of $R^2$,\n",
    "the cell **R-squared** in the top-right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The $R^2$ is high, relatively, but a high $R^2$ doesn't mean the job of prediction is done.\n",
    "\n",
    "Just as we should always view our data before we start doing modeling and statistics,\n",
    "we should always view the predictions of our model before we start drawing conclusions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = weight_mpg_linear_ols_results.params\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.regplot(\"std_weight\", \"std_mpg\", data=mpg_df, lowess=True, color=\"C0\",\n",
    "            scatter_kws={\"alpha\": 0.8}, line_kws={\"lw\": 4, \"label\": \"Smooth Prediction\", \"color\": \"k\"})\n",
    "ax.plot([-1.5, 2.5], params[\"std_weight\"] * pd.Series([-2.5, 2.5]) + params[\"Intercept\"],\n",
    "        color=\"C1\", lw=4, label=\"Best Linear Prediction\");\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The black line, labeled \"Smooth Prediction\", is produced by a method called LOWESS:\n",
    "[LOcally-WEighted Scatterplot Smoothing](https://www.statisticshowto.datasciencecentral.com/lowess-smoothing/).\n",
    "\n",
    "It can be used as a regression model,\n",
    "but it is more commonly used as a visualization tool:\n",
    "a way to visually estimate the (possibly non-linear) relationship between two variables,\n",
    "as it is being used here.\n",
    "\n",
    "It is closely related to the regression methods covered in data8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice how the linear predictions seem to be under-estimating the mileage for low and high weights,\n",
    "while over-estimating the mileage for intermediate weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This might be more visible in the plot below,\n",
    "which visualizes the prediction errors as red bars\n",
    "connecting the model prediction to the actual observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "make_error_plot(params, mpg_df.sample(frac=0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Alternatively,\n",
    "we might visualize our errors as a function of the independent variable,\n",
    "`std_weight`,\n",
    "to look for patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "errors = (params[\"Intercept\"] + params[\"std_weight\"] * mpg_df[\"std_weight\"]) - mpg_df[\"std_mpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(mpg_df[\"std_weight\"], errors); ax.set_ylim(-3, 3);\n",
    "ax.hlines(0, -3, 3, lw=4); ax.set_xlim(-3, 3)\n",
    "ax.set_xlabel(\"std_weight\"); ax.set_ylabel(\"Error Size\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For the low and high weights,\n",
    "the errors are primarily negative (under-estimation)\n",
    "while for intermediate weight, the errors are primarily positive (over-estimation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# One solution is to transform the data so that the relationship becomes linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is known as _linearization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A linearized model with Normal likelihood using\n",
    "functions `f` to transform the data looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "y \\sim \\text{Normal}\\left(\\sum\\text{slope}_i\\cdot \\texttt{f[i]}(x), \\sigma\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_linear_model(params, x, featurizers=None):\n",
    "    if featurizers is None:\n",
    "        featurizers = [lambda x: 1, lambda x: x]  # intercept and linear term\n",
    "    return sum(pd.Series(params.values) * pd.Series(f(x) for f in featurizers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While this freedom may seem strange,\n",
    "note that there's not necessarily anything \"natural\" about the form our data comes to us:\n",
    "we could've used \"gallons per mile\" instead of \"miles per gallon\",\n",
    "which would correspond to using `1/x` as our featurizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linearizing with Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've seen a version of data featurization with categorical linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often, a \"category\" or \"group\" is just a discretization of an underlying continuous value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The function `binify` below adds an extra column to a dataframe\n",
    "that has `nbins` different discrete category identities for the provided `column`.\n",
    "It uses a pandas function, `pd.cut`, to define the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def binify(df, nbins, column=\"weight\"):\n",
    "    raw_bin_column = column + \"_raw_bin\"\n",
    "    df[raw_bin_column] = pd.cut(df[column], bins=nbins)\n",
    "\n",
    "    mapper = {k:v for k, v in zip(sorted(df[raw_bin_column].unique()), range(nbins))}\n",
    "\n",
    "    df[column + \"_bin\"] = df[raw_bin_column].apply(lambda k: mapper[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we apply it to the `std_weight` column,\n",
    "we get a new categorical variable, `std_weight_bin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binify(mpg_df, nbins=25, column=\"std_weight\")\n",
    "\n",
    "mpg_df[[\"std_weight\", \"std_weight_raw_bin\", \"std_weight_bin\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can also visualize the resulting data,\n",
    "using `hue` to indicate the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax = sns.scatterplot(x=\"std_weight\", y=\"std_mpg\", hue=\"std_weight_bin\",\n",
    "               data=mpg_df, legend=False);\n",
    "ax.set_xlim([-3, 3]); ax.set_ylim([-3, 3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can then propose a model that applies a separate linear regression\n",
    "to each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bin_model = smf.ols(\"std_mpg ~ std_weight * C(std_weight_bin)\", data=mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We might alternatively propose a strictly categorical model for each bin.\n",
    "\n",
    "Uncomment and run the cell below to fit that model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# bin_model = smf.ols(\"std_mpg ~ (std_weight_bin)\", data=mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bin_model_results = bin_model.fit()\n",
    "\n",
    "print(bin_model_results.rsquared, weight_mpg_linear_ols_results.rsquared)\n",
    "\n",
    "bin_model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As the number of bins, and so the number of parameters, increases,\n",
    "the length of the output increases.\n",
    "But we remain only interested in `rsquared`.\n",
    "Increasing `nbins` increases `rsquared`.\n",
    "With a sufficient number of bins,\n",
    "we should always be able to outperform the baseline linear regression model,\n",
    "even if we use the pure cetegorical model.\n",
    "\n",
    "For technical reasons,\n",
    "keep `nbins` below ~30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For two or three bins,\n",
    "the predictions of the model look reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "preds_plot(\"std_weight\", \"std_mpg\", mpg_df, bin_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Go back and increase the value of `nbins` in `binify` to `25` (from the original `2`).\n",
    "\n",
    "`rsquared` will increase,\n",
    "but the predictions will become _less sensible_:\n",
    "like a conspiracy theorist, the maximum likelihood model\n",
    "sees complicated, intricate patterns that are probably not real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This method is known as _piecewise linear regression_:\n",
    "we fit a linear regression model to each \"piece\" of the input range.\n",
    "\n",
    "You might think of it as the \"regression version\" of a histogram.\n",
    "\n",
    "Where a histogram estimates a distribution by putting points into bins and then counting them up,\n",
    "this model estimates the relationship between two values by putting the inputs into bins\n",
    "and then fitting a regression model to the outputs inside each bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In the extreme, we might consider making a new bin for every value we observe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These kinds of models are known as _nearest neighbor_ models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The code below implements nearest neighbor prediction\n",
    "so that it can be used in concert with `statsmodels`\n",
    "and so that the connection to linear models is clear.\n",
    "\n",
    "Effectively,\n",
    "we are picking a very complex \"featurizer\" `f`,\n",
    "the function `nearest_neighbors`.\n",
    "It is essentially a\n",
    "[look-up table](https://en.wikipedia.org/wiki/Lookup_table)\n",
    "based on our observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def make_nn_formula(exemplars):\n",
    "    return \"std_mpg ~ \" + \"-1 + nearest_neighbors(std_weight)\"\n",
    "\n",
    "nn_formula = make_nn_formula(mpg_df[\"std_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# like a dictionary whose keys are weights and values are corresponding mpgs\n",
    "mapper = pd.Series(index=mpg_df[\"std_weight\"].values, data=mpg_df[\"std_mpg\"].values)\n",
    "\n",
    "neighbors = mpg_df[\"std_weight\"].values\n",
    "\n",
    "def nearest_neighbor_pred(x):\n",
    "    # how far is x from each point we observed?\n",
    "    squared_differences = np.square(neighbors - x)\n",
    "    # what are the indices of the closest points? (who are my \"nearest neighbors\"?)\n",
    "    nearest_value_indices = np.where(squared_differences == squared_differences.min())\n",
    "    # what are the values at those indices?\n",
    "    nearest_values = list(neighbors[nearest_value_indices])\n",
    "    # what are the y values for my neighbors?\n",
    "    neighbor_ys = mapper[nearest_values]\n",
    "    return np.mean(neighbor_ys)\n",
    "\n",
    "def nearest_neighbors(xs):\n",
    "    return pd.Series(nearest_neighbor_pred(x) for x in xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The result is a model that can beat the pants off of any other in terms of `rsquared`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nn_model = smf.ols(nn_formula, data=mpg_df)\n",
    "\n",
    "nn_model_results = nn_model.fit()\n",
    "\n",
    "print(nn_model_results.rsquared, weight_mpg_linear_ols_results.rsquared)\n",
    "\n",
    "nn_model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But if we look at the predictions, we can see an obvious problem:\n",
    "the model is designed to pass exactly through each point in the dataset, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "preds_plot(\"std_weight\", \"std_mpg\", mpg_df, nn_model_results, use_step=True,\n",
    "           zorder=0, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While this does a good job, by construction,\n",
    "predicting the values we observed,\n",
    "it does a terrible job of uncovering the true relationship between the variables.\n",
    "\n",
    "The model is a slave of the dataset, forced to recreate every single variation,\n",
    "even though we wouldn't expect to be able to perfectly predict the mileage of a car just from its weight.\n",
    "There are too many other contributing factors that we are ignoring.\n",
    "\n",
    "Pretending that those factors don't exist and that the input data\n",
    "has all the information we need and trying to force a model\n",
    "to achieve near-perfect performance on that data\n",
    "is a major cause of over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The categorization and nearest-neighbor models\n",
    "demonstrate the principle of over-fitting.\n",
    "\n",
    "Polynomial models are also commonly used to demonstrate over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Another Approach to Linearization: Polynomial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Any function can be approximated as a weighted sum of polynomial (power) functions:\n",
    "$$\n",
    "f(x) \\approx a + b\\cdot x + c\\cdot x^2 + d\\cdot x^3 \\dots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is known as a\n",
    "[Taylor Expansion](https://www.khanacademy.org/math/ap-calculus-bc/bc-series-new/bc-10-14/v/visualizing-taylor-series-approximations),\n",
    "which you might have come across in a calculus class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By incorporating polynomial functions into our formula,\n",
    "we can find the values for $a$, $b$, $c$ etc. that minimize the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_poly_formula(y, x, max_degree):\n",
    "    return y + \" ~ \" + \" + \".join(\n",
    "        [\"-1\"] + [f\"np.power({x}, {k})\" for k in range(max_degree + 1)])\n",
    "\n",
    "max_degree = 15  # largest power of x to include in data features\n",
    "polyformula = make_poly_formula(\"std_mpg\", \"std_weight\", max_degree)\n",
    "polyformula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_polynomial_featurizers(max_degree=1):\n",
    "    featurizers = []\n",
    "    for k in range(max_degree + 1):\n",
    "        def featurizer(x, k=k):\n",
    "            return np.power(x, k)\n",
    "        featurizers.append(featurizer)\n",
    "    return featurizers\n",
    "\n",
    "poly_featurizers = make_polynomial_featurizers(max_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We just need to pass the formula to `smf.ols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "poly_model = smf.ols(polyformula, data=mpg_df)\n",
    "\n",
    "poly_model_results = poly_model.fit()\n",
    "\n",
    "print(poly_model_results.rsquared, weight_mpg_linear_ols_results.rsquared)\n",
    "\n",
    "poly_model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that `rsquared` has gone up, relative to the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But the model isn't doing a much better job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "preds_plot(\"std_weight\", \"std_mpg\", mpg_df, poly_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For `max_degree=5`,\n",
    "notice the upwards curve all the way in the bottom right:\n",
    "It's extremely unlikely that the true relationship between weight and mileage\n",
    "includes that \"kink\",\n",
    "but because it is in the dataset and our model was able to \"predict\" it,\n",
    "it is included in our final prediction function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Increase `max_degree` to `30`\n",
    "(any higher and `smf.fit` starts to break down for numerical reasons).\n",
    "\n",
    "`rsquared` will increase a bit,\n",
    "but the prediction function will become even wonkier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $R^2$ is a flawed metric if measured on data the model got to observe before or during the fitting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's too easy to \"game\" this metric,\n",
    "unintentionally or intentionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to know how well a model performs for data it hasn't observed:\n",
    "_out-of-sample_ data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ideally, we'd go out and collect a bunch of new data once we finished fitting our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is called _validating_ the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But this isn't always practical:\n",
    "if we've run an experiment, we don't want to have to run it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One practical solution is to change our fitting process so that the model doesn't get to see all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### And the most common version of this is called _cross-validation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In cross-validation, the data is split into two pieces:\n",
    "one set for picking parameters with MLE/MAP or getting the posterior\n",
    "and the other set for checking $R^2$ (or a similar metric).\n",
    "\n",
    "These are called the _training_ and _testing_ sets:\n",
    "one is used to \"train\" the model,\n",
    "improving its performance, much like an athlete trains,\n",
    "while the other is used to \"test\" its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### While this isn't too hard to implement yourself, we'll use a pre-written version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It comes from the [`sklearn` (scikit-learn) library](https://scikit-learn.org/stable/),\n",
    "which is used to do maximum likelihood and maximum a posteriori fitting\n",
    "using the terminology and idiom of machine learning,\n",
    "just as `statsmodels` does the same\n",
    "using the terminology and idiom of frequentist linear modeling.\n",
    "Both of course do other things.\n",
    "\n",
    "scikit-learn is more fully fleshed out, in certain ways,\n",
    "than is `statsmodels`,\n",
    "since the audience for traditional methods\n",
    "is captured by the R statistical programming language,\n",
    "while the audience for machine learning skews towards Python.\n",
    "\n",
    "The [documentation](https://scikit-learn.org/stable/documentation.html)\n",
    "and [examples](https://scikit-learn.org/stable/auto_examples/index.html)\n",
    "for scikit-learn are a great resource for learning more about the machine learning side of data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The code cells below demonstrate the train/test split function on a small, simple dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "example_df = pd.DataFrame({\"x\":[1, 2, 3, 4, 5], \"y\":[\"A\", \"E\", \"I\", \"O\", \"U\"]})\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can change the size of the `test` set by changing the `test_size` argument.\n",
    "\n",
    "If `test_size` is an integer, it sets the total number of examples in the `test` set.\n",
    "If it's a float between 0 and 1, it sets the relative size of the `test` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train, test = sklearn.model_selection.train_test_split(example_df, test_size=2)\n",
    "print(\"TRAIN:\\n\", train)\n",
    "print(\"TEST:\\n\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cross-validation involves splitting the data into train and test sets many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We want to see how well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_splits = 1000\n",
    "\n",
    "cross_validation_splits = [sklearn.model_selection.train_test_split(mpg_df, test_size=100)\n",
    "                           for _ in range(num_splits)]\n",
    "training_sets, test_sets = zip(*cross_validation_splits)  # \"unzip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Technical note: `cross_validation_splits` is a list of tuples,\n",
    "where the first entry in the tuple is the training set,\n",
    "while the second is the test set.\n",
    "\n",
    "The last line above converts `cross_validation_splits` into a tuple of lists,\n",
    "where the first entry is a list of training sets, while the second is a list of test sets,\n",
    "and assigns them to appropriate names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The cell below shows what a subset of the test sets (gold) look like\n",
    "compared to their respective training sets (blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 4\n",
    "f, axs = plt.subplots(figsize=(12, 6), nrows=2, ncols=n_examples, sharex=True, sharey=True)\n",
    "\n",
    "axs[0, 0].set_ylabel(\"Training Sets\"); axs[1, 0].set_ylabel(\"Test Sets\")\n",
    "for ax, training_set in zip(axs[0, :], training_sets[:n_examples]):\n",
    "    ax.scatter(\"std_mpg\", \"std_weight\", data=training_set, alpha=0.25)\n",
    "for ax, test_set in zip(axs[1, :], test_sets[:n_examples]):\n",
    "    ax.scatter(\"std_mpg\", \"std_weight\", data=test_set, color=\"C1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Instead of thinking of this as a method for obtaining \"fake new data\",\n",
    "you might think of it as a way of disrupting certain patterns in the dataset.\n",
    "\n",
    "If you focus on the top row, the training sets,\n",
    "you'll see that for the intermediate values,\n",
    "the relationship between the two variables looks about the same every time.\n",
    "At the edges, where data is scarcer,\n",
    "the location of the best fit line changes from split to split.\n",
    "\n",
    "Similarly, if you focus on the bottom row, the test sets,\n",
    "you'll see that the patterns at the edges of the dataset vary greatly.\n",
    "A model that obtains high performance by over-fitting to a pattern present there in the training set\n",
    "may fail miserably when that pattern fails to appear in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We apply the same fitting procedure to each training set as though it were the original dataset we had observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv_results_poly = [smf_fit(polyformula, training_set) for training_set in training_sets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can then look at the predictions of each of the fitted models\n",
    "and compare them to each other and to the original datasaet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_cross_validated_models(cv_results_poly, poly_model_results, data=mpg_df, featurizers=poly_featurizers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "While the predictions remain fairly stable in the intermediate region\n",
    "across cross validation splits (gold, transparent),\n",
    "the predictions at the edges vary wildly.\n",
    "\n",
    "If you look closely, you'll see some predictions in that region that are wildly off:\n",
    "they don't even come close to the observed data.\n",
    "When the model is allowed to see the entire dataset,\n",
    "this is prevented by the Normal likelihood,\n",
    "which penalizes such large squared errors.\n",
    "\n",
    "But when the model is forced to work off of only what it observes in the training set,\n",
    "there is nothing to prevent these fluctuations.\n",
    "\n",
    "Put another way,\n",
    "one of the consequences of a model developing \"conspiracy theories\"\n",
    "about the data in order to fit it better\n",
    "is instability and poor performance on data it did not observe.\n",
    "The more complex patterns, though they match the observed data perfectly,\n",
    "make very poor predictions on unobserved values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Then, we take the fitted model parameters and evaluate $R^2$ on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Subsets of data withheld from the model, like the test sets above,\n",
    "are also known as _held-out_ datasets.\n",
    "\n",
    "This \"cross-validated $R^2$\" function is not any different from\n",
    "any other function for calculating $R^2$ --\n",
    "the only thing that is changed is the names of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cross_validated_r_squared(heldout_data, cv_result, featurizers=None):\n",
    "    heldout_x = heldout_data[\"std_weight\"]\n",
    "    heldout_y = heldout_data[\"std_mpg\"]\n",
    "    predictions_on_heldout = predict_linear_model(cv_result.params, heldout_x, featurizers)\n",
    "    \n",
    "    return 1 - ((predictions_on_heldout - heldout_y) ** 2).mean() / heldout_y.var(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv_r_squareds_poly = pd.Series([\n",
    "    cross_validated_r_squared(test_set, cv_result, featurizers=poly_featurizers)\n",
    "     for test_set, cv_result in zip(test_sets, cv_results_poly)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The $R^2$ values on the test sets confirm our concerns:\n",
    "the $R^2$ on unseen data may be negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(cv_r_squareds_poly, range=(-10, 1), # this distribution has a long negative tail\n",
    "        bins=100, label=\"High Degree Polynomial\", density=True);\n",
    "ax.set_xlabel(\"$R^2$ on Test\"); ax.set_xlim([-2, 1]); ax.legend();\n",
    "cv_r_squareds_poly.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The mean is printed to indicate the existence of the long negative tail:\n",
    "its value is typically to the left-most edge of the plotted region,\n",
    "even though the bulk of the values are close to the right-most edge.\n",
    "\n",
    "This means that there is a small number of very large negative values,\n",
    "pulling the average down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## If we examine the worst-performing models, we can see where the long tail comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "worst_performers = cv_r_squareds_poly.sort_values().head(10)  # which models had lowest R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "idx = worst_performers.index[-1]\n",
    "make_error_plot(cv_results_poly[idx].params, test_sets[idx], featurizers=poly_featurizers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "`run_cross_validation` below\n",
    "wraps the cross-validation process up into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(data, formula, num_folds=1000, test_size=100, featurizers=None):\n",
    "    # split the data into training and testing sets num_folds times\n",
    "    cross_validation_folds = [sklearn.model_selection.train_test_split(\n",
    "        data, test_size=test_size) for _ in range(num_folds)]\n",
    "    training_sets, test_sets = zip(*cross_validation_folds)\n",
    "    \n",
    "    # fit same model to each training set\n",
    "    results = [smf_fit(formula, training_set) for training_set in training_sets]\n",
    "    \n",
    "    # use corresponding test set to get r_squared for each model\n",
    "    r_squareds = pd.Series([\n",
    "        cross_validated_r_squared(test_set, result, featurizers=featurizers)\n",
    "        for test_set, result in zip(test_sets, results)\n",
    "    ])\n",
    "    return results, r_squareds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Models without the flexibility to over-fit will generally have less variability in their $R^2$ values on unobserved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv_results_linear, cv_r_squareds_linear = run_cross_validation(mpg_df, \"std_mpg ~ std_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_cross_validated_models(cv_results_linear, weight_mpg_linear_ols_results, data=mpg_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(cv_r_squareds_poly, range=(-10, 1), bins=100, label=\"High Degree Polynomial\",\n",
    "        density=True, histtype=\"step\", lw=4);\n",
    "ax.hist(cv_r_squareds_linear, bins=10, label=\"Linear\",\n",
    "        density=True, histtype=\"step\", lw=4);\n",
    "ax.set_xlabel(\"$R^2$ on Test\"); ax.set_xlim([-2, 1]); ax.legend(); cv_r_squareds_linear.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# We can easily perform a version of cross-validation with pyMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But note that Bayesian approaches to model comparison and cross-validation are still in their relative infancy.\n",
    "As with many things Bayesian,\n",
    "there is a rigorous answer on how to perform model comparsion,\n",
    "given by Bayes' rule,\n",
    "but it is onerous, even impractical, to compute,\n",
    "necessitating clever approximations.\n",
    "\n",
    "The approximate method in these slides was published in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But first,\n",
    "let's produce some models and posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As a baseline, just like in $R^2$, we choose the constant model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as constant_model_pymc:\n",
    "    pm.GLM.from_formula(\"std_mpg ~ 1\", mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with constant_model_pymc:\n",
    "    constant_model_trace = pm.sample()\n",
    "\n",
    "constant_model_posterior_df = shared_util.samples_to_dataframe(constant_model_trace)\n",
    "\n",
    "constant_model_MAP = pm.find_MAP(model=constant_model_pymc)\n",
    "\n",
    "constant_model_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We also do a plain linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as linear_model_pymc:\n",
    "    pm.GLM.from_formula(\"std_mpg ~ std_weight\", mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with linear_model_pymc:\n",
    "    linear_model_trace = pm.sample()\n",
    "\n",
    "linear_model_posterior_df = shared_util.samples_to_dataframe(linear_model_trace)\n",
    "\n",
    "linear_model_MAP = pm.find_MAP(model=linear_model_pymc)\n",
    "\n",
    "linear_model_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(linear_model_trace, figsize=(12, 12), text_size=16, ref_val=[0, 0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A polynomial model.\n",
    "\n",
    "If you try to increase the `max_degree` too much,\n",
    "e.g. to 10 or more,\n",
    "you'll find that sampling slows to a crawl and you start to see warnings from pyMC.\n",
    "\n",
    "This is an indication that the model is very bad:\n",
    "for the very high degree polynomial models,\n",
    "the posterior is a gnarly function.\n",
    "\n",
    "In some ways,\n",
    "this is a feature,\n",
    "rather than a bug,\n",
    "because it means that\n",
    "we are prevented from making a silly model\n",
    "like the super-high-degree polynomial.\n",
    "\n",
    "But not that this means that below,\n",
    "we won't be working with the same\n",
    "polynomial model to which we applied the over-fitting analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "polyformula = make_poly_formula(\"std_mpg\", \"std_weight\", max_degree=5)\n",
    "\n",
    "with pm.Model() as poly_model_pymc:\n",
    "    pm.GLM.from_formula(polyformula, mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with poly_model_pymc:\n",
    "    poly_model_trace = pm.sample()\n",
    "\n",
    "poly_model_posterior_df = shared_util.samples_to_dataframe(poly_model_trace)\n",
    "\n",
    "poly_model_MAP = pm.find_MAP(model=poly_model_pymc)\n",
    "\n",
    "poly_model_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_posterior(poly_model_trace, figsize=(8, 16), text_size=16, ref_val=[0] * 6 + [1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A piecewise linear-regression model.\n",
    "\n",
    "Again, we are held back from using too many bins\n",
    "by the fact that sampling will begin to fail.\n",
    "Again, this is somewhere in between a bug and a feature\n",
    "of Bayesian Monte Carlo methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "binify(mpg_df, nbins=5, column=\"std_weight\")\n",
    "\n",
    "with pm.Model() as bin_model_pymc:\n",
    "    pm.GLM.from_formula(\"std_mpg ~ std_weight*C(std_weight_bin)\", mpg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with bin_model_pymc:\n",
    "    bin_model_trace = pm.sample()\n",
    "\n",
    "bin_model_posterior_df = shared_util.samples_to_dataframe(bin_model_trace)\n",
    "\n",
    "bin_model_MAP = pm.find_MAP(model=bin_model_pymc)\n",
    "\n",
    "bin_model_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Once we've obtained a posterior, we can get an estimate of cross-validation performance effectively for free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What we'd naïvely need to do is perform a version of cross-validation\n",
    "where we'd apply `pm.sample` to the training set\n",
    "and then compute the average negative log-likelihood\n",
    "on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd need to then _also_ average this value over the posterior for the parameters,\n",
    "given the observations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This would take a very, very long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, the results can be easily estimated from the trace output by `pm.sample`,\n",
    "at least for the case where the test sets have size `1` (only a single datapoint is left out).\n",
    "\n",
    "The abbreviation for this type of cross-validation is `LOO`, or `L`eave `O`ne `O`ut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The details of how are unimportant and technical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, we need to organize our traces.\n",
    "\n",
    "The cell below gives each model a name and puts the models and traces into the format\n",
    "expected by pyMC's model comparison function, `compare`.\n",
    "\n",
    "It is a dictionary whose keys are the models and whose values are the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "constant_model_pymc.name = \"constant: y ~ 1\"\n",
    "linear_model_pymc.name = \"linear: y ~ 1 + x\"\n",
    "poly_model_pymc.name = \"poly: y ~ 1 + x + x^2 ...\"\n",
    "bin_model_pymc.name = \"bin: y ~ 1 + in_bin_0(x)*x + ...\"\n",
    "\n",
    "model_traces = {constant_model_pymc: constant_model_trace,\n",
    "               linear_model_pymc: linear_model_trace,\n",
    "               poly_model_pymc: poly_model_trace,\n",
    "               bin_model_pymc: bin_model_trace}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then we pass that dictionary to the `pm.compare` function.\n",
    "\n",
    "The `ic` keyword tells the function which criterion to use.\n",
    "Here, we choose the leave-one-out cross-validation criterion.\n",
    "\n",
    "Due to connections to information theory,\n",
    "these model comparison criteria are known as `i`nformation `c`riteria\n",
    "in the world of Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ics = pm.compare(model_traces, ic=\"LOO\")  # L(eave) O(ne) O(ut) Cross-Validation\n",
    "\n",
    "ics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Again, the output is quite rich,\n",
    "but we only care about a small subset of it.\n",
    "\n",
    "The `LOO` column is the estimate of the performance on unseen data.\n",
    "A lower value is better.\n",
    "\n",
    "The `SE` column indicates the uncertainty in that estimate,\n",
    "in terms of standard error.\n",
    "\n",
    "The `shape_warn` column will include a `1` if the approximation step\n",
    "failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The values are compared the same way\n",
    "we compare any other univariate value with an estimate and a standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ic_compare(ics, ic_name=\"LOO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Lower is better,\n",
    "and so we can conclude that the `poly`, `bin`, and `linear` models\n",
    "are better than the `constant` model.\n",
    "\n",
    "The high overlap of the standard errors indicates that there's not much evidence\n",
    "to favor any model among those three.\n",
    "\n",
    "In theory, these criteria take complexity into account,\n",
    "but they tend to be insufficiently conservative.\n",
    "Ockham's razor, then, would suggest using the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: the older alternative to LOO is called the\n",
    "[Weighted Akaike Information Criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion),\n",
    "or `WAIC`.\n",
    "If you look into Bayesian model comparison,\n",
    "you'll see more on the WAIC and its variants than on LOO,\n",
    "due to its relative novelty.\n",
    "\n",
    "If you change the `\"LOO\"` arguments above to `\"WAIC\"`,\n",
    "you'll see the results of comparing the models with `\"WAIC\"`.\n",
    "They are substantially similar,\n",
    "since the two are closely related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's return to the original problem.\n",
    "\n",
    "We wanted to see how fuel efficiency and weight related to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We measured fuel efficiency in miles per gallon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But weight should be _directly_ related to the gallons required to drive a mile,\n",
    "meaning it's _inversely_ related to the miles driven on a single gallon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpg_df[\"gpm\"] = 1 / mpg_df[\"mpg\"]  # gallons per mile is 1 / miles per gallon\n",
    "mpg_df[\"std_gpm\"] = zscore(mpg_df[\"gpm\"])  # standardize after transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "After we apply that transformation to our output,\n",
    "the relationship between the variables appears much more linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(y=\"std_gpm\", x=\"std_weight\", data=mpg_df, height=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we apply our Bayesian modeling and model comparison tools,\n",
    "we see that this model wins out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as inv_model_pymc:\n",
    "    pm.GLM.from_formula(\"std_gpm ~ std_weight\", mpg_df)\n",
    "\n",
    "with inv_model_pymc:\n",
    "    inv_model_trace = pm.sample()\n",
    "\n",
    "inv_model_posterior_df = shared_util.samples_to_dataframe(inv_model_trace)\n",
    "\n",
    "inv_model_MAP = pm.find_MAP(model=inv_model_pymc)\n",
    "\n",
    "inv_model_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inv_model_pymc.name = \"inverse: 1/y ~ x\"\n",
    "model_traces = {constant_model_pymc: constant_model_trace,\n",
    "               linear_model_pymc: linear_model_trace,\n",
    "               poly_model_pymc: poly_model_trace,\n",
    "               bin_model_pymc: bin_model_trace,\n",
    "               inv_model_pymc: inv_model_trace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ics = pm.compare(model_traces, ic=\"LOO\")  # L(eave) O(ne) O(ut) Cross-Validation\n",
    "\n",
    "ics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ic_compare(ics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There is still some overlap between the standard errors of the polynomial/bin models and the inverse model,\n",
    "indicating there's a small chance that those models have better out-of-sample performance.\n",
    "\n",
    "If we include our strong preference for simpler models, though,\n",
    "we can come down in favor of the inverse model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
