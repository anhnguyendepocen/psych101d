{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../../shared/img/slides_banner.svg\" width=2560></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Under the Hood of pyMC - Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from shared.src import quiet\n",
    "from shared.src import seed\n",
    "from shared.src import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import daft\n",
    "from IPython.display import HTML, Image, YouTubeVideo\n",
    "import matplotlib.patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from statsmodels.tsa import stattools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.7)\n",
    "\n",
    "import shared.src.utils.util as shared_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def autocorrplot(samples, nlags=40):\n",
    "    autocorrelation = stattools.acf(samples, nlags=nlags)\n",
    "    f, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.vlines(np.arange(nlags), 0, autocorrelation, lw=1);\n",
    "    ax.set_ylabel(\"Correlation\"); ax.set_xlabel(\"Steps Ahead\")\n",
    "    ax.hlines(0, 0, nlags, color=\"C0\", lw=2);\n",
    "\n",
    "    \n",
    "def plot_circle_sampler_trajectory(samples):\n",
    "    f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    square = matplotlib.patches.Rectangle((-1, -1), 2, 2)\n",
    "    circle = matplotlib.patches.Circle((0, 0), 1, color=\"C1\")\n",
    "\n",
    "    ax.add_patch(square); ax.add_patch(circle);\n",
    "    ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]);\n",
    "\n",
    "    ax.plot(samples[:, 0], samples[:, 1], lw=4, marker=\".\", color=\"C3\", markersize=24);\n",
    "\n",
    "    \n",
    "def plot_chain(samples, ax, **step_kwargs):\n",
    "    n_samples = len(samples)\n",
    "    ax.step(np.arange(n_samples), samples, **step_kwargs)\n",
    "\n",
    "    \n",
    "def plot_k_ahead(samples, k):\n",
    "    f, ax = plt.subplots(figsize=(12, 12))\n",
    "    current_xs, next_xs = k_ahead_samples(samples, k)\n",
    "    sns.regplot(current_xs, next_xs, ax=ax, line_kws={\"lw\": 4, \"color\": \"C1\"});\n",
    "    ax.set_xlabel(\"Current Value\"), ax.set_ylabel(f\"${k}$-Ahead Value\")\n",
    "    correlation, _ = scipy.stats.pearsonr(current_xs, next_xs)\n",
    "    ax.set_title(f\"Correlation is {round(correlation, 2)} at ${k}$ step(s) ahead\")\n",
    "\n",
    "    \n",
    "def make_markov_chain():\n",
    "    markov_chain = daft.PGM(shape=[12, 6])\n",
    "\n",
    "    past = daft.Node(\"past\", \"past\", 1, 3, scale=4)\n",
    "    present = daft.Node(\"present\", \"present\", 6, 3, scale=4)\n",
    "    future = daft.Node(\"future\", \"future\", 11, 3, scale=4)\n",
    "    [markov_chain.add_node(node) for node in [past, present, future]]\n",
    "    markov_chain.add_edge(\"past\", \"present\", lw=4, head_width=0.4)\n",
    "    markov_chain.add_edge(\"present\", \"future\", lw=4, head_width=0.4)\n",
    "    markov_chain.render()\n",
    "\n",
    "    \n",
    "def handle_scalars(proposal):   \n",
    "    # if output is size 0 array\n",
    "    if proposal.shape is ():  \n",
    "        # convert it to a scalar\n",
    "        proposal = np.asscalar(proposal)\n",
    "    return proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today, we will peek under the hood of pyMC and learn more about the mechanics of the modeling and inference approach we've been using this semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more, check out\n",
    "[this blog post](https://ericmjl.github.io/essays-on-data-science/machine-learning/computational-bayesian-stats/)\n",
    "covering some of the same material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For an even deeper dive under the hood,\n",
    "check out\n",
    "[Bayesian Method For Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers),\n",
    "especially Chapter 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Any method that uses samples to approximate distributions and averages is a _Monte Carlo_ method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Using samples to approximate a posterior or averages on a posterior is called Bayesian Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The method we use to draw samples is called _Markov Chain_ sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Using samples from a Markov Chain to approximate Bayesian posteriors is known as Bayesian Markov Chain Monte Carlo, or _Bayesian MCMC_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any approach to approximating a fixed quantity with a random quantity is a Monte Carlo method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we calculate $\\pi$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is no end to the digits of $\\pi$,\n",
    "and so if we tried to get it exactly, we'd keep on computing forever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One method is to use the same \"Taylor Expansion\" Method that gave us polynomial regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\pi = 16\\cdot\\texttt{atan}(1/5) - 4\\cdot\\texttt{atan}(1/239)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "but replace $\\texttt{atan}$ with $a + b\\cdot x + c\\cdot x^2 \\dots$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another method is to use optimization.\n",
    "\n",
    "We pick some function $f$ such that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\max(f(x)) = \\pi\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and then use methods closely related to `find_MAP` to get close to $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This class of methods is my personal favorite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $\\pi$ is a fixed value, but we can approximate it with the output of a random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a circle inscribed inside a square.\n",
    "\n",
    "$$\n",
    "\\frac{\\text{Area of Circle}}{\\text{Area of Square}} = \\frac{\\pi r^2}{(2r)^2} = \\frac{\\pi}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "square = matplotlib.patches.Rectangle((-1, -1), 2, 2)\n",
    "circle = matplotlib.patches.Circle((0, 0), 1, color=\"C1\")\n",
    "\n",
    "ax.add_patch(square); ax.add_patch(circle);\n",
    "ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we throw darts at the square and they have an equal chance of hitting at each point,\n",
    "then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{dart lands in circle}) = \\frac{\\text{Area of Circle}}{\\text{Area of Square}} = \\frac{\\pi}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "That is, the probability of landing in any given region\n",
    "is equal to the area of that region as a fraction of the total area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have frequently used samples from a probability distribution to approximate\n",
    "the actual distribution.\n",
    "\n",
    "In this case, we could simulate the \"dart-throwing\" process\n",
    "and then calculate the fraction of darts\n",
    "that are inside the circle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{dart lands in circle}) \\approx \\frac{1}{n}\\sum_{n \\text{ darts}} \\texttt{is_in_circle(}\\text{dart}\\texttt{)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def is_in_circle(xs, ys):\n",
    "    return np.sqrt((xs ** 2 + ys ** 2)) < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is known as an _indicator function_ in mathematical probability.\n",
    "It is a function that indicates whether an event occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And so the average value of this function on our samples is\n",
    "approximately the probability that a dart lands inside the circle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\frac{1}{n}\\sum_{n \\text{ darts}} \\texttt{is_in_circle(}\\text{dart}\\texttt{)} \\approx p(\\text{dart lands in circle}) = \\frac{\\pi}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "which we can slightly rearrange into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\frac{1}{n}\\sum_{n \\text{ darts}} 4\\cdot\\texttt{is_in_circle(}\\text{dart}\\texttt{)} \\approx \\pi\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And so we can approximate $\\pi$ just by drawing samples uniformly from a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_square(n=10000):\n",
    "    xs = pm.Uniform.dist(lower=-1, upper=1).random(size=n)\n",
    "    ys = pm.Uniform.dist(lower=-1, upper=1).random(size=n)\n",
    "    \n",
    "    return pd.Series(xs), pd.Series(ys)\n",
    "\n",
    "xs, ys = sample_from_square()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, we verify that this code actually draws samples approximately uniformly across the square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(xs, ys, alpha=0.1); ax.axis(\"equal\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then, we confirm that our `is_in_circle` function works as we'd hope it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "filtered_xs, filtered_ys = xs[is_in_circle(xs, ys)], ys[is_in_circle(xs, ys)]\n",
    "ax.scatter(xs, ys, alpha=0.1); ax.axis(\"equal\");\n",
    "ax.scatter(filtered_xs, filtered_ys, alpha=0.5, color=\"C1\"); ax.axis(\"equal\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that about 3/4ths of the samples are colored gold and inside the circle?\n",
    "\n",
    "The actual fraction should be close to $\\pi$/4ths,\n",
    "and the fraction will get closer as we draw more samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This Monte Carlo approach to approximating $\\pi$\n",
    "is encapsulated in the `monte_carlo_pi` function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def monte_carlo_pi(n=10000):\n",
    "    xs, ys = sample_from_square(n)\n",
    "    \n",
    "    in_circles = pd.Series(is_in_circle(xs, ys))\n",
    "    \n",
    "    approximate_pi = (4 * in_circles).mean()\n",
    "    \n",
    "    return approximate_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can compare our results to `math.pi`,\n",
    "the value of $\\pi$ used by Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "monte_carlo_pi(n=10000), math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As we increase the number of samples `n`,\n",
    "the approximation tends to get better and better.\n",
    "\n",
    "But at a cost:\n",
    "drawing more samples takes more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Monte Carlo methods rely on sampling, but sampling is not always easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our calculation of $\\pi$ relied on our ability to draw random points uniformly from square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What if we wanted to draw points uniformly from the _circle_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unlike the square, which can be sampled from easily\n",
    "by sampling two separate uniform distributions,\n",
    "it's not obvious how to sample the points inside a circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "As always with a problem this simple, there are a number of solutions.\n",
    "\n",
    "1. We might take our samples from the square and filter out only those that landed in the circle.\n",
    "2. We might sample the clockwise position and the distance from the center.\n",
    "\n",
    "We'll focus on a solution that generalizes more easily to more complex cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One suggestion comes from physical intuition about _diffusion_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The video below shows food coloring spreading through,\n",
    "or _diffusing into_,\n",
    "a dish of water.\n",
    "\n",
    "Even though all of the dye starts off somewhere close to the center,\n",
    "given enough time (about 20 minutes in real time),\n",
    "the dye ends up uniformly spread around the dish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"8raI-uX4WAI\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One of the mechanisms of this diffusion has been known for some time.\n",
    "\n",
    "Lucretius,\n",
    "one of the _atomists_,\n",
    "a school of philosophers of the Classical Era\n",
    "who believed everything to be made of small,\n",
    "indivisible particles,\n",
    "described an observation of diffusion in his poem\n",
    "_On the Nature of Things_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Watch carefully whenever shafts of streaming sunlight are allowed to penetrate a dark room. You will observe many minute particles mingling in many ways in every part of the space illuminated by the rays.\n",
    "...\n",
    "Such commotion implies the existence of movements of matter that are secret and imperceptible. For you will observe many of those particles, under the impulse of unseen blows, changing course and being forcibly turned back, now this way, now that way, in every direction.\n",
    "\n",
    "- Titus Lucretius Carus, _De Rerum Natura_, c. 60 BC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The molecules of dye are being battered about by each other and by the molecules of water:\n",
    "_unseen blows_ change their course, _now this way, now that way, in every direction_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We can mimic a diffusion process to draw uniform samples from the circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We start by \"dropping in our dye\" at some initial point.\n",
    "\n",
    "We imagine putting in just one dye molecule, for computational reasons.\n",
    "\n",
    "Then we start adding in our collisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On each step,\n",
    "we adjust the position of our dye molecule a small amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def collision_result(starting_point):\n",
    "    return starting_point + 0.2 * np.random.standard_normal(size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "All we need to do is make sure we don't leave the circle.\n",
    "\n",
    "We do this by staying put whenver a collision would take us outside the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def sample_from_circle_diffusion(circle_checker, init, collider, n):\n",
    "    assert is_in_circle(*init)  # make sure we start in the circle\n",
    "    current = init  # drop in the dye\n",
    "        \n",
    "    samples = [current]\n",
    "    for _ in range(n):\n",
    "        # simulate a collision\n",
    "        possible_next = collider(current)\n",
    "        # make sure the collision didn't take us outside the circle\n",
    "        if is_in_circle(*possible_next):\n",
    "            # and if it didn't, we've got our new current position\n",
    "            current = possible_next\n",
    "        samples.append(current)\n",
    "    \n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The cell below runs this process once, for `n` steps,\n",
    "and then plots the trajectory of our dye molecule as a red line on top of the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "circle_samples = sample_from_circle_diffusion(\n",
    "    is_in_circle, [0, 0], collision_result, n=30)\n",
    "\n",
    "plot_circle_sampler_trajectory(circle_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we run the cell multiple times,\n",
    "we will see different trajectories each time.\n",
    "\n",
    "They will share a starting point, in the center.\n",
    "\n",
    "They will also share some gross features:\n",
    "for example, sequential points will tend to be close to one another.\n",
    "\n",
    "At just 30 steps,\n",
    "it doesn't look like we're drawing uniform samples from the circle.\n",
    "Increase `n` to 300, then 3000.\n",
    "You should see the trajectories begin to explore the circle more uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The cell below draws 10,000 samples in the same fashion,\n",
    "then plots them as a scatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "circle_samples_MC = sample_from_circle_diffusion(\n",
    "    is_in_circle, [0, 0], collision_result, 10000)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(circle_samples_MC[:, 0], circle_samples_MC[:, 1], alpha=0.5, color=\"C1\");\n",
    "ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is effectively indistinguishable from a scatter plot of the samples that landed inside the circle\n",
    "in our Monte Carlo $\\pi$ experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "circle_samples_MC = sample_from_circle_diffusion(\n",
    "    is_in_circle, [0, 0], collision_result, 10000)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(filtered_xs, filtered_ys, alpha=0.5, color=\"C1\");\n",
    "ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The typical visualization of a sampler's trajectory\n",
    "focuses on one variable at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=2, sharex=True, sharey=True)\n",
    "\n",
    "plot_chain(pd.Series(circle_samples_MC[:1000, 0]), axs[0], lw=2)\n",
    "plot_chain(pd.Series(circle_samples_MC[:1000, 1]), axs[1], lw=2);\n",
    "axs[0].set_ylim([-1, 1]); axs[0].set_ylabel(\"x position\"); axs[1].set_ylabel(\"y position\");\n",
    "axs[1].set_xlabel(\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This view is what gave the name _trace_ to the outputs of pyMC:\n",
    "this is the path traced out by our simulated dye molecule.\n",
    "\n",
    "Notice the relatively slow motion of the particle:\n",
    "when it is at an extremely positive or negative value\n",
    "(close to -1 and 1),\n",
    "it will tend to stay near that value for tens of steps.\n",
    "This is visible as a \"waviness\" of the trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Change the first `Series` plotted to\n",
    "\n",
    "```python\n",
    "pd.Series(circle_samples_MC[:1000, 0]).sample(frac=1)\n",
    "```\n",
    "\n",
    "This will shuffle the values,\n",
    "removing the time dependence.\n",
    "\n",
    "The \"waves\" mostly disappear,\n",
    "and values at one extreme are sometimes followed by values at the other extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Alternatively, we could visualize the in-circle samples from our Monte Carlo $\\pi$ experiment,\n",
    "which also have no dependence on each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "independent_samples = np.array([filtered_xs, filtered_ys]).T\n",
    "plot_circle_sampler_trajectory(independent_samples[:30, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The samples are spread all around the circle,\n",
    "with successive points no more likely to be neighbors\n",
    "than points separated quite a bit in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(figsize=(12, 12), nrows=2, sharex=True, sharey=True)\n",
    "\n",
    "plot_chain(independent_samples[:1000, 0], axs[0], lw=2)\n",
    "plot_chain(independent_samples[:1000, 1], axs[1], lw=2)\n",
    "axs[0].set_ylim([-1, 1]); axs[0].set_ylabel(\"x position\"); axs[1].set_ylabel(\"y position\");\n",
    "axs[1].set_xlabel(\"time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This relationship can be roughly measured with _correlation_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, a code snippet to pull out samples at a given time lag from one another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def k_ahead_samples(samples, k=1):\n",
    "    current_xs = samples[:-k]\n",
    "    k_ahead_xs = samples[k:]\n",
    "    return current_xs, k_ahead_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_ahead_samples(circle_samples_MC[:10, 0], k=1)  # x positions at a time lag of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Then, we plot these samples as x,y pairs\n",
    "and look for a linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_k_ahead(circle_samples_MC[:, 0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For a single step ahead, the correlation is very high.\n",
    "\n",
    "That is, if you are currently at given position,\n",
    "the next sample is very likely to be at a nearby position.\n",
    "\n",
    "The correlation drops quite a bit if we go further out,\n",
    "e.g. to 10 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_k_ahead(circle_samples_MC[:, 0], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And at 50 steps, it has gone away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_k_ahead(circle_samples_MC[:, 0], k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The correlation between values as a function of the time-lag between them\n",
    "is known as the _autocorrelation_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "autocorrplot(circle_samples_MC[:, 0], nlags=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Auto-correlation is bad for a sampler:\n",
    "it can be shown that the higher this auto-correlation,\n",
    "the worse our Monte Carlo estimates will be.\n",
    "\n",
    "For example, the in-circle samples from our Monte Carlo $\\pi$ experiment\n",
    "are independent.\n",
    "\n",
    "Even at a time lag of one step, the correlation is low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_k_ahead(independent_samples[:, 0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is true for all time lags\n",
    "(except 0, where the correlation is 1,\n",
    "because we are correlating a value with itself),\n",
    "as we can see from the autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "autocorrplot(independent_samples[:, 0], nlags=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Diffusions are one kind of _Markov Chain_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# A Markov Chain is a sequence of random variables where future values are dependent on the past values, but only through the present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In our case,\n",
    "times far in the past\n",
    "(up to 20 or more steps back)\n",
    "were correlated with the next step.\n",
    "\n",
    "But if you look closely at the code for generating the samples,\n",
    "you'll see that there's only a direct dependence on the most recent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Every Markov Chain has the same graphical representation: a _chain_ of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "make_markov_chain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It is from Markov Chains that the \"chains\" in a pyMC trace get their name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following are examples of Markov Chains:\n",
    "\n",
    "- **The weather** is _approximately_ a Markov Chain. If it is sunny one day, it's likely to be sunny the next; if it is rainy one day, it is likely to be rainy the next.\n",
    "\n",
    "- The **position of a fly** buzzing around a room, wandering aimlessly. This is effectively a diffusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following are not examples of Markov Chains:\n",
    "\n",
    "- The **English language**. A word arbitrarily far in the past can impact the future without impacting the present.\n",
    "\n",
    "- **Video** streams and films. In a movie, the opening credits can often be used to predict the end credits, e.g. the name of the director, better than can the images that come in between. Or the movie might begin with a flashback that is referenced later in the film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In some sense, most things we encounter aren't _exactly_ Markov Chains,\n",
    "though many things can be closely modeled by Markov Chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The basic algorithm for Markov Chain Monte Carlo is a generalized version of the diffusion used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is called _Metropolis-Hastings_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Structurally, it looks very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def metropolis_hastings(\n",
    "    logp,  # where previously we had in_circle, we now have logp\n",
    "    init,\n",
    "    proposer,  # where previously we had a \"collider\", now we have a \"proposer\"\n",
    "    n):\n",
    "    \n",
    "    # we specify an initial point,\n",
    "    #  the equivalent of dropping in the dye\n",
    "    current = init \n",
    "    samples = [current]\n",
    "    for _ in range(n):\n",
    "        # then we propose the next value\n",
    "        proposal = proposer(current)\n",
    "        \n",
    "        # then we use a criterion to choose whether to keep it or not\n",
    "        #  and this criterion is based on the log-probability\n",
    "        current = metropolis_criterion(logp, current, proposal)\n",
    "        \n",
    "        samples.append(current)  \n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The biggest difference is that the acceptance criterion is soft, instead of hard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def metropolis_criterion(logp, current, proposal):\n",
    "    p_current = np.exp(logp(current))\n",
    "    p_proposal = np.exp(logp(proposal))\n",
    "    \n",
    "    # if the proposal has higher probability than the current,\n",
    "    #  or if it has a ratio of probabilities larger a random value,\n",
    "    #  accept\n",
    "    if (p_proposal / p_current) > pm.Uniform.dist().random():\n",
    "        return proposal\n",
    "    else:\n",
    "        return current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can even use the exact same method to generate proposed updates.\n",
    "\n",
    "The below is equivalent to the `collision_result` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_proposal(value, sd=0.05):\n",
    "    proposal = pm.Normal.dist(mu=value, sd=sd).random()  # normal with mean centered at value\n",
    "    proposal = handle_scalars(proposal)  # Unimportant details with shapes and types\n",
    "    return proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### With a little massaging, we can even recreate the diffusion sampler with Metropolis-Hastings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We have to cheat and use infinity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def circle_logp(xy):\n",
    "    # log-probability for uniform on circle\n",
    "    x, y = xy\n",
    "    if is_in_circle(x, y):\n",
    "        return np.log(1 / math.pi)\n",
    "    else:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Any two values that are in the circle will always evaluate to the same value,\n",
    "in the first branch of the `if`-`else`,\n",
    "and therefore the ratios of their probabilities will be 1,\n",
    "and the update will always be accepted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "metropolis_criterion(circle_logp, (0, 0), (0.5, 0.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Whereas if the proposal is outside of the circle,\n",
    "the ratio will be 0,\n",
    "and so the proposal will be rejected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "metropolis_criterion(circle_logp, (0, 0), (1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And so the results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "circle_samples_metropolis_hastings = metropolis_hastings(\n",
    "    circle_logp, [0, 0], gaussian_proposal, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_circle_sampler_trajectory(circle_samples_metropolis_hastings[:100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The trajectories look a bit different,\n",
    "because the standard deviation of the Normal\n",
    "in the proposal is different,\n",
    "but the qualitative features are the same.\n",
    "\n",
    "Namely,\n",
    "a large number of samples roughly uniformly cover the circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(circle_samples_metropolis_hastings[:, 0], circle_samples_metropolis_hastings[:, 1],\n",
    "           alpha=0.5, color=\"C1\");\n",
    "ax.set_xlim([-1, 1]); ax.set_ylim([-1, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "And from step to step, values are correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_k_ahead(circle_samples_metropolis_hastings[:, 0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metropolis-Hastings-type algorithms help us sample from posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The goal of Markov Chain Monte Carlo is not just to sample uniformly from simple shapes like the circle.\n",
    "\n",
    "Instead, the goal is to sample from interesting distributions that we can't write down,\n",
    "like the posterior of a complicated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the major benefits of the Metropolis-Hastings algorithm comes from the fact that it uses a _ratio_ of probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "First, consider the definition of the posterior from Bayes' Rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{params}\\vert\\text{data}) = \\frac{p(\\text{data}\\vert\\text{params}) p(\\text{params})}{p(\\text{data})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The troublesome part of this equation is the denominator.\n",
    "The numerator is part of our modeling process:\n",
    "it has the likelihood and the prior (in that order).\n",
    "\n",
    "Now let's consider comparing two possible values of the params, $A$ and $B$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{params = A}\\vert\\text{data}) = \\frac{p(\\text{data}\\vert\\text{params = A}) p(\\text{params = A})}{p(\\text{data})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "p(\\text{params = B}\\vert\\text{data}) = \\frac{p(\\text{data}\\vert\\text{params = B}) p(\\text{params = B})}{p(\\text{data})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we take the ratio of the probabilities,\n",
    "we get a complicated-looking expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\frac{p(\\text{params = A}\\vert\\text{data})}{p(\\text{params = B}\\vert\\text{data})} =\n",
    "\\frac{\\frac{p(\\text{data}\\vert\\text{params = A}) p(\\text{params = A})}{p(\\text{data})}}{\\frac{p(\\text{data}\\vert\\text{params = B}) p(\\text{params = B})}{p(\\text{data})}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "But it simplifies, because $p(\\text{data})$ is in the denominator of both the top and bottom:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\frac{p(\\text{params = A}\\vert\\text{data})}{p(\\text{params = B}\\vert\\text{data})} =\n",
    "\\frac{p(\\text{data}\\vert\\text{params = A}) p(\\text{params = A})}{p(\\text{data}\\vert\\text{params = B}) p(\\text{params = B)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is only in terms of the likelihood and prior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Metropolis-Hastings only needs a `logp` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### and that function only needs to give answers accurate up to a constant shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "pyMC models have just such a `logp` function for the posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as linear_signal_model:\n",
    "    signal = pm.Normal(\"signal\", mu=0, sd=1)\n",
    "    measurement = pm.Normal(\"measurement\", mu=signal, sd=0.1, observed=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lsm_logp = linear_signal_model.logp\n",
    "def lsm_logp_metropolis_hastings(value):\n",
    "    return lsm_logp({\"signal\": value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we evaluate this function on a bunch of points\n",
    "and then exponentiate, we get the posterior\n",
    "(up to a proportionality constant given by $p(\\text{data})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "signal_values = np.linspace(0, 1.6, num=1000)\n",
    "ax.plot(signal_values, [np.exp(lsm_logp_metropolis_hastings(x)) for x in signal_values], lw=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we hand that `logp` function to `metropolis_hastings`\n",
    "along with the `gaussian_proposal`,\n",
    "we will draw samples from the posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "posterior_samples_by_hand = metropolis_hastings(lsm_logp_metropolis_hastings, 0, gaussian_proposal, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.step(np.arange(len(posterior_samples_by_hand)), posterior_samples_by_hand);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Because our initial guess had low posterior probability,\n",
    "there was a brief period in which our samples were slightly \"off\".\n",
    "\n",
    "This period is known as the \"burn-in\" time of our sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "xs = np.linspace(-2, 2, num=1000)\n",
    "sns.distplot(posterior_samples_by_hand);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It results in a bias in our posterior,\n",
    "which we can remove by cutting out those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(signal_values, [np.exp(lsm_logp_metropolis_hastings(x)) for x in signal_values],\n",
    "        color=\"C1\", lw=2, label=\"exp(logp) Posterior\");\n",
    "sns.distplot(posterior_samples_by_hand[100:], label=\"Posterior Samples\"); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Notice that the posterior obtained from `logp` directly is off by a multiplicative factor!\n",
    "\n",
    "It has the right shape, but not quite the right heights.\n",
    "\n",
    "Note that our samples,\n",
    "though they are in aggregate drawn from the posterior,\n",
    "still have temporal dependencies on short time lags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "autocorrplot(posterior_samples_by_hand[100:], nlags=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# pyMC combines the model-specification API we've worked with throughout the semester with _very_ sophisticated versions of Metropolis-Hastings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The particular algorithm most commonly used under the hood in pyMC is called\n",
    "[*NUTS*](https://stats.stackexchange.com/questions/311813/can-somebody-explain-to-me-nuts-in-english),\n",
    "the \"No U-Turn Sampler\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with linear_signal_model:\n",
    "    posterior_samples = pm.sample(draws=5000, chains=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we compare these `posterior_samples` to the ones we obtained `by_hand`,\n",
    "we see a close agreement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.distplot(posterior_samples_by_hand[100:], label=\"By Hand\");\n",
    "sns.distplot(posterior_samples[\"signal\"], label=\"pyMC\"); ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The benefit of a library like pyMC is that the algorithms are much faster and more performant that anything we can write ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is the outcome of many researchers and programmers working together for years,\n",
    "and the results are both highly reliable and highly tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example,\n",
    "the autocorrelation is much, much lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.autocorrplot(posterior_samples, max_lag=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that this plot uses a pyMC function, `pm.autocorrplot`,\n",
    "that is the built-in equivalent of the `autocorrplot` function used for our homemade samplers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And so the samples, at least for this posterior, look _almost_ independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.step(np.arange(len(posterior_samples[\"signal\"])), posterior_samples[\"signal\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There is also no period of \"burn-in\" to worry about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "pyMC provides its own function for plotting trajectories: `traceplot`.\n",
    "\n",
    "It takes in a `trace` and plots the posterior on the left and the samples over time on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.traceplot(posterior_samples, figsize=(12, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This function is most useful when you have multiple chains in your trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with linear_signal_model:\n",
    "    multi_chain_posterior_samples = pm.sample(draws=1250,\n",
    "                                              chains=4)  # how many separate markov chains to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pm.traceplot(multi_chain_posterior_samples, figsize=(12, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The chains are separated by color in the plot above.\n",
    "\n",
    "Multiple chains tend to improve posterior sampling performance\n",
    "and the ability to test for computational problems.\n",
    "By default, pyMC uses two chains when sampling."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
